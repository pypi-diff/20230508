# Comparing `tmp/nucliadb-2.8.5.post247-py3-none-any.whl.zip` & `tmp/nucliadb-2.8.5.post249-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,296 +1,302 @@
-Zip file size: 506266 bytes, number of entries: 294
--rw-r--r--  2.0 unx      891 b- defN 23-May-08 15:32 nucliadb/__init__.py
--rw-r--r--  2.0 unx     1027 b- defN 23-May-08 15:32 nucliadb/app.py
--rw-r--r--  2.0 unx     4872 b- defN 23-May-08 15:32 nucliadb/config.py
--rw-r--r--  2.0 unx     1420 b- defN 23-May-08 15:32 nucliadb/purge.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-08 15:32 nucliadb/py.typed
--rw-r--r--  2.0 unx     2522 b- defN 23-May-08 15:32 nucliadb/run.py
--rw-r--r--  2.0 unx     1913 b- defN 23-May-08 15:32 nucliadb/settings.py
--rw-r--r--  2.0 unx     1011 b- defN 23-May-08 15:32 nucliadb/ingest/__init__.py
--rw-r--r--  2.0 unx     5581 b- defN 23-May-08 15:32 nucliadb/ingest/app.py
--rw-r--r--  2.0 unx      995 b- defN 23-May-08 15:32 nucliadb/ingest/cache.py
--rw-r--r--  2.0 unx     6567 b- defN 23-May-08 15:32 nucliadb/ingest/chitchat.py
--rw-r--r--  2.0 unx     2425 b- defN 23-May-08 15:32 nucliadb/ingest/partitions.py
--rw-r--r--  2.0 unx    15823 b- defN 23-May-08 15:32 nucliadb/ingest/processing.py
--rw-r--r--  2.0 unx     5336 b- defN 23-May-08 15:32 nucliadb/ingest/purge.py
--rw-r--r--  2.0 unx    18976 b- defN 23-May-08 15:32 nucliadb/ingest/serialize.py
--rw-r--r--  2.0 unx     2973 b- defN 23-May-08 15:32 nucliadb/ingest/settings.py
--rw-r--r--  2.0 unx     2531 b- defN 23-May-08 15:32 nucliadb/ingest/txn_utils.py
--rw-r--r--  2.0 unx     4917 b- defN 23-May-08 15:32 nucliadb/ingest/utils.py
--rw-r--r--  2.0 unx     1087 b- defN 23-May-08 15:32 nucliadb/ingest/consumer/__init__.py
--rw-r--r--  2.0 unx    18549 b- defN 23-May-08 15:32 nucliadb/ingest/consumer/pull.py
--rw-r--r--  2.0 unx     6425 b- defN 23-May-08 15:32 nucliadb/ingest/consumer/service.py
--rw-r--r--  2.0 unx      835 b- defN 23-May-08 15:32 nucliadb/ingest/fields/__init__.py
--rw-r--r--  2.0 unx    19273 b- defN 23-May-08 15:32 nucliadb/ingest/fields/base.py
--rw-r--r--  2.0 unx     6495 b- defN 23-May-08 15:32 nucliadb/ingest/fields/conversation.py
--rw-r--r--  2.0 unx     1223 b- defN 23-May-08 15:32 nucliadb/ingest/fields/date.py
--rw-r--r--  2.0 unx     1205 b- defN 23-May-08 15:32 nucliadb/ingest/fields/exceptions.py
--rw-r--r--  2.0 unx     5159 b- defN 23-May-08 15:32 nucliadb/ingest/fields/file.py
--rw-r--r--  2.0 unx     1523 b- defN 23-May-08 15:32 nucliadb/ingest/fields/generic.py
--rw-r--r--  2.0 unx     1235 b- defN 23-May-08 15:32 nucliadb/ingest/fields/keywordset.py
--rw-r--r--  2.0 unx     2250 b- defN 23-May-08 15:32 nucliadb/ingest/fields/layout.py
--rw-r--r--  2.0 unx     4084 b- defN 23-May-08 15:32 nucliadb/ingest/fields/link.py
--rw-r--r--  2.0 unx     1319 b- defN 23-May-08 15:32 nucliadb/ingest/fields/text.py
--rw-r--r--  2.0 unx      835 b- defN 23-May-08 15:32 nucliadb/ingest/maindb/__init__.py
--rw-r--r--  2.0 unx     3088 b- defN 23-May-08 15:32 nucliadb/ingest/maindb/driver.py
--rw-r--r--  2.0 unx      877 b- defN 23-May-08 15:32 nucliadb/ingest/maindb/exceptions.py
--rw-r--r--  2.0 unx      980 b- defN 23-May-08 15:32 nucliadb/ingest/maindb/keys.py
--rw-r--r--  2.0 unx     7713 b- defN 23-May-08 15:32 nucliadb/ingest/maindb/local.py
--rw-r--r--  2.0 unx     6115 b- defN 23-May-08 15:32 nucliadb/ingest/maindb/pg.py
--rw-r--r--  2.0 unx     6807 b- defN 23-May-08 15:32 nucliadb/ingest/maindb/redis.py
--rw-r--r--  2.0 unx     7020 b- defN 23-May-08 15:32 nucliadb/ingest/maindb/tikv.py
--rw-r--r--  2.0 unx     3495 b- defN 23-May-08 15:32 nucliadb/ingest/orm/__init__.py
--rw-r--r--  2.0 unx     6801 b- defN 23-May-08 15:32 nucliadb/ingest/orm/abc.py
--rw-r--r--  2.0 unx    20650 b- defN 23-May-08 15:32 nucliadb/ingest/orm/brain.py
--rw-r--r--  2.0 unx    15408 b- defN 23-May-08 15:32 nucliadb/ingest/orm/entities.py
--rw-r--r--  2.0 unx     1448 b- defN 23-May-08 15:32 nucliadb/ingest/orm/exceptions.py
--rw-r--r--  2.0 unx    12586 b- defN 23-May-08 15:32 nucliadb/ingest/orm/grpc_node_binding.py
--rw-r--r--  2.0 unx     4606 b- defN 23-May-08 15:32 nucliadb/ingest/orm/grpc_node_dummy.py
--rw-r--r--  2.0 unx    21289 b- defN 23-May-08 15:32 nucliadb/ingest/orm/knowledgebox.py
--rw-r--r--  2.0 unx     1730 b- defN 23-May-08 15:32 nucliadb/ingest/orm/labels.py
--rw-r--r--  2.0 unx     4291 b- defN 23-May-08 15:32 nucliadb/ingest/orm/local_node.py
--rw-r--r--  2.0 unx     2890 b- defN 23-May-08 15:32 nucliadb/ingest/orm/local_shard.py
--rw-r--r--  2.0 unx    11388 b- defN 23-May-08 15:32 nucliadb/ingest/orm/node.py
--rw-r--r--  2.0 unx     4312 b- defN 23-May-08 15:32 nucliadb/ingest/orm/nodes_manager.py
--rw-r--r--  2.0 unx    27970 b- defN 23-May-08 15:32 nucliadb/ingest/orm/processor.py
--rw-r--r--  2.0 unx    51379 b- defN 23-May-08 15:32 nucliadb/ingest/orm/resource.py
--rw-r--r--  2.0 unx     5115 b- defN 23-May-08 15:32 nucliadb/ingest/orm/shard.py
--rw-r--r--  2.0 unx     1739 b- defN 23-May-08 15:32 nucliadb/ingest/orm/synonyms.py
--rw-r--r--  2.0 unx     3340 b- defN 23-May-08 15:32 nucliadb/ingest/orm/utils.py
--rw-r--r--  2.0 unx     2817 b- defN 23-May-08 15:32 nucliadb/ingest/service/__init__.py
--rw-r--r--  2.0 unx      835 b- defN 23-May-08 15:32 nucliadb/ingest/service/exceptions.py
--rw-r--r--  2.0 unx    34672 b- defN 23-May-08 15:32 nucliadb/ingest/service/writer.py
--rw-r--r--  2.0 unx      835 b- defN 23-May-08 15:32 nucliadb/ingest/tests/__init__.py
--rw-r--r--  2.0 unx     1096 b- defN 23-May-08 15:32 nucliadb/ingest/tests/conftest.py
--rw-r--r--  2.0 unx    25062 b- defN 23-May-08 15:32 nucliadb/ingest/tests/fixtures.py
--rw-r--r--  2.0 unx     7549 b- defN 23-May-08 15:32 nucliadb/ingest/tests/tikv.py
--rw-r--r--  2.0 unx    62843 b- defN 23-May-08 15:32 nucliadb/ingest/tests/vectors.py
--rw-r--r--  2.0 unx      835 b- defN 23-May-08 15:32 nucliadb/ingest/tests/integration/__init__.py
--rw-r--r--  2.0 unx     1740 b- defN 23-May-08 15:32 nucliadb/ingest/tests/integration/test_chitchat.py
--rw-r--r--  2.0 unx      835 b- defN 23-May-08 15:32 nucliadb/ingest/tests/integration/ingest/__init__.py
--rw-r--r--  2.0 unx    27277 b- defN 23-May-08 15:32 nucliadb/ingest/tests/integration/ingest/test_ingest.py
--rw-r--r--  2.0 unx     2339 b- defN 23-May-08 15:32 nucliadb/ingest/tests/integration/ingest/test_processing_engine.py
--rw-r--r--  2.0 unx     8606 b- defN 23-May-08 15:32 nucliadb/ingest/tests/integration/ingest/test_relations.py
--rw-r--r--  2.0 unx      835 b- defN 23-May-08 15:32 nucliadb/ingest/tests/unit/__init__.py
--rw-r--r--  2.0 unx     1179 b- defN 23-May-08 15:32 nucliadb/ingest/tests/unit/test_cache.py
--rw-r--r--  2.0 unx     4246 b- defN 23-May-08 15:32 nucliadb/ingest/tests/unit/test_chitchat.py
--rw-r--r--  2.0 unx     1432 b- defN 23-May-08 15:32 nucliadb/ingest/tests/unit/test_partitions.py
--rw-r--r--  2.0 unx     5538 b- defN 23-May-08 15:32 nucliadb/ingest/tests/unit/test_processing.py
--rw-r--r--  2.0 unx     3414 b- defN 23-May-08 15:32 nucliadb/ingest/tests/unit/test_purge.py
--rw-r--r--  2.0 unx      978 b- defN 23-May-08 15:32 nucliadb/ingest/tests/unit/test_settings.py
--rw-r--r--  2.0 unx     1403 b- defN 23-May-08 15:32 nucliadb/ingest/tests/unit/test_txn_utils.py
--rw-r--r--  2.0 unx     2895 b- defN 23-May-08 15:32 nucliadb/ingest/tests/unit/test_utils.py
--rw-r--r--  2.0 unx      835 b- defN 23-May-08 15:32 nucliadb/ingest/tests/unit/orm/__init__.py
--rw-r--r--  2.0 unx     8991 b- defN 23-May-08 15:32 nucliadb/ingest/tests/unit/orm/test_brain.py
--rw-r--r--  2.0 unx     2706 b- defN 23-May-08 15:32 nucliadb/ingest/tests/unit/orm/test_cluster.py
--rw-r--r--  2.0 unx     4212 b- defN 23-May-08 15:32 nucliadb/ingest/tests/unit/orm/test_node.py
--rw-r--r--  2.0 unx     2812 b- defN 23-May-08 15:32 nucliadb/ingest/tests/unit/orm/test_processor.py
--rw-r--r--  2.0 unx     3772 b- defN 23-May-08 15:32 nucliadb/ingest/tests/unit/orm/test_resource.py
--rw-r--r--  2.0 unx     1401 b- defN 23-May-08 15:32 nucliadb/ingest/tests/unit/orm/test_shard.py
--rw-r--r--  2.0 unx      835 b- defN 23-May-08 15:32 nucliadb/models/__init__.py
--rw-r--r--  2.0 unx     1599 b- defN 23-May-08 15:32 nucliadb/models/responses.py
--rw-r--r--  2.0 unx      914 b- defN 23-May-08 15:32 nucliadb/one/__init__.py
--rw-r--r--  2.0 unx     3539 b- defN 23-May-08 15:32 nucliadb/one/app.py
--rw-r--r--  2.0 unx     2130 b- defN 23-May-08 15:32 nucliadb/one/lifecycle.py
--rw-r--r--  2.0 unx      835 b- defN 23-May-08 15:32 nucliadb/one/tests/__init__.py
--rw-r--r--  2.0 unx     1164 b- defN 23-May-08 15:32 nucliadb/one/tests/conftest.py
--rw-r--r--  2.0 unx     3665 b- defN 23-May-08 15:32 nucliadb/one/tests/fixtures.py
--rw-r--r--  2.0 unx     2561 b- defN 23-May-08 15:32 nucliadb/one/tests/test_basic.py
--rw-r--r--  2.0 unx     2492 b- defN 23-May-08 15:32 nucliadb/one/tests/test_delete_field.py
--rw-r--r--  2.0 unx     6087 b- defN 23-May-08 15:32 nucliadb/one/tests/test_fieldmetadata.py
--rw-r--r--  2.0 unx     4594 b- defN 23-May-08 15:32 nucliadb/one/tests/test_services.py
--rw-r--r--  2.0 unx     4067 b- defN 23-May-08 15:32 nucliadb/one/tests/test_upload_download.py
--rw-r--r--  2.0 unx     1328 b- defN 23-May-08 15:32 nucliadb/reader/__init__.py
--rw-r--r--  2.0 unx     3356 b- defN 23-May-08 15:32 nucliadb/reader/app.py
--rw-r--r--  2.0 unx     1366 b- defN 23-May-08 15:32 nucliadb/reader/lifecycle.py
--rw-r--r--  2.0 unx     2186 b- defN 23-May-08 15:32 nucliadb/reader/openapi.py
--rw-r--r--  2.0 unx     1365 b- defN 23-May-08 15:32 nucliadb/reader/run.py
--rw-r--r--  2.0 unx      872 b- defN 23-May-08 15:32 nucliadb/reader/api/__init__.py
--rw-r--r--  2.0 unx     2433 b- defN 23-May-08 15:32 nucliadb/reader/api/models.py
--rw-r--r--  2.0 unx      995 b- defN 23-May-08 15:32 nucliadb/reader/api/v1/__init__.py
--rw-r--r--  2.0 unx     9790 b- defN 23-May-08 15:32 nucliadb/reader/api/v1/download.py
--rw-r--r--  2.0 unx     3570 b- defN 23-May-08 15:32 nucliadb/reader/api/v1/knowledgebox.py
--rw-r--r--  2.0 unx    10721 b- defN 23-May-08 15:32 nucliadb/reader/api/v1/resource.py
--rw-r--r--  2.0 unx     1011 b- defN 23-May-08 15:32 nucliadb/reader/api/v1/router.py
--rw-r--r--  2.0 unx    10766 b- defN 23-May-08 15:32 nucliadb/reader/api/v1/services.py
--rw-r--r--  2.0 unx      835 b- defN 23-May-08 15:32 nucliadb/reader/tests/__init__.py
--rw-r--r--  2.0 unx     1101 b- defN 23-May-08 15:32 nucliadb/reader/tests/conftest.py
--rw-r--r--  2.0 unx     4635 b- defN 23-May-08 15:32 nucliadb/reader/tests/fixtures.py
--rw-r--r--  2.0 unx     2749 b- defN 23-May-08 15:32 nucliadb/reader/tests/test_list_resources.py
--rw-r--r--  2.0 unx     9946 b- defN 23-May-08 15:32 nucliadb/reader/tests/test_reader_file_download.py
--rw-r--r--  2.0 unx    11383 b- defN 23-May-08 15:32 nucliadb/reader/tests/test_reader_resource.py
--rw-r--r--  2.0 unx     6535 b- defN 23-May-08 15:32 nucliadb/reader/tests/test_reader_resource_field.py
--rw-r--r--  2.0 unx     1535 b- defN 23-May-08 15:32 nucliadb/search/__init__.py
--rw-r--r--  2.0 unx     4381 b- defN 23-May-08 15:32 nucliadb/search/app.py
--rw-r--r--  2.0 unx     2310 b- defN 23-May-08 15:32 nucliadb/search/lifecycle.py
--rw-r--r--  2.0 unx     2206 b- defN 23-May-08 15:32 nucliadb/search/openapi.py
--rw-r--r--  2.0 unx    11236 b- defN 23-May-08 15:32 nucliadb/search/predict.py
--rw-r--r--  2.0 unx     1366 b- defN 23-May-08 15:32 nucliadb/search/run.py
--rw-r--r--  2.0 unx     1108 b- defN 23-May-08 15:32 nucliadb/search/settings.py
--rw-r--r--  2.0 unx     1238 b- defN 23-May-08 15:32 nucliadb/search/utilities.py
--rw-r--r--  2.0 unx      835 b- defN 23-May-08 15:32 nucliadb/search/api/__init__.py
--rw-r--r--  2.0 unx     1077 b- defN 23-May-08 15:32 nucliadb/search/api/v1/__init__.py
--rw-r--r--  2.0 unx     6845 b- defN 23-May-08 15:32 nucliadb/search/api/v1/chat.py
--rw-r--r--  2.0 unx     1831 b- defN 23-May-08 15:32 nucliadb/search/api/v1/feedback.py
--rw-r--r--  2.0 unx     9436 b- defN 23-May-08 15:32 nucliadb/search/api/v1/find.py
--rw-r--r--  2.0 unx     6938 b- defN 23-May-08 15:32 nucliadb/search/api/v1/knowledgebox.py
--rw-r--r--  2.0 unx     4781 b- defN 23-May-08 15:32 nucliadb/search/api/v1/resource.py
--rw-r--r--  2.0 unx      980 b- defN 23-May-08 15:32 nucliadb/search/api/v1/router.py
--rw-r--r--  2.0 unx    11487 b- defN 23-May-08 15:32 nucliadb/search/api/v1/search.py
--rw-r--r--  2.0 unx     4212 b- defN 23-May-08 15:32 nucliadb/search/api/v1/suggest.py
--rw-r--r--  2.0 unx      833 b- defN 23-May-08 15:32 nucliadb/search/requesters/__init__.py
--rw-r--r--  2.0 unx     6752 b- defN 23-May-08 15:32 nucliadb/search/requesters/utils.py
--rw-r--r--  2.0 unx      835 b- defN 23-May-08 15:32 nucliadb/search/search/__init__.py
--rw-r--r--  2.0 unx     2408 b- defN 23-May-08 15:32 nucliadb/search/search/cache.py
--rw-r--r--  2.0 unx     5337 b- defN 23-May-08 15:32 nucliadb/search/search/fetch.py
--rw-r--r--  2.0 unx    13815 b- defN 23-May-08 15:32 nucliadb/search/search/find_merge.py
--rw-r--r--  2.0 unx    18899 b- defN 23-May-08 15:32 nucliadb/search/search/merge.py
--rw-r--r--  2.0 unx      947 b- defN 23-May-08 15:32 nucliadb/search/search/metrics.py
--rw-r--r--  2.0 unx    11002 b- defN 23-May-08 15:32 nucliadb/search/search/paragraphs.py
--rw-r--r--  2.0 unx     9905 b- defN 23-May-08 15:32 nucliadb/search/search/query.py
--rw-r--r--  2.0 unx     2647 b- defN 23-May-08 15:32 nucliadb/search/search/shards.py
--rw-r--r--  2.0 unx     2055 b- defN 23-May-08 15:32 nucliadb/search/search/synonyms.py
--rw-r--r--  2.0 unx     2410 b- defN 23-May-08 15:32 nucliadb/search/search/utils.py
--rw-r--r--  2.0 unx      835 b- defN 23-May-08 15:32 nucliadb/search/tests/__init__.py
--rw-r--r--  2.0 unx     1172 b- defN 23-May-08 15:32 nucliadb/search/tests/conftest.py
--rw-r--r--  2.0 unx     7895 b- defN 23-May-08 15:32 nucliadb/search/tests/fixtures.py
--rw-r--r--  2.0 unx    16291 b- defN 23-May-08 15:32 nucliadb/search/tests/node.py
--rw-r--r--  2.0 unx      833 b- defN 23-May-08 15:32 nucliadb/search/tests/unit/__init__.py
--rw-r--r--  2.0 unx     1560 b- defN 23-May-08 15:32 nucliadb/search/tests/unit/test_app.py
--rw-r--r--  2.0 unx     1776 b- defN 23-May-08 15:32 nucliadb/search/tests/unit/test_find_orderer.py
--rw-r--r--  2.0 unx     1329 b- defN 23-May-08 15:32 nucliadb/search/tests/unit/test_openapi.py
--rw-r--r--  2.0 unx     8495 b- defN 23-May-08 15:32 nucliadb/search/tests/unit/test_predict.py
--rw-r--r--  2.0 unx     1258 b- defN 23-May-08 15:32 nucliadb/search/tests/unit/test_run.py
--rw-r--r--  2.0 unx      833 b- defN 23-May-08 15:32 nucliadb/search/tests/unit/search/__init__.py
--rw-r--r--  2.0 unx     3736 b- defN 23-May-08 15:32 nucliadb/search/tests/unit/search/test_fetch.py
--rw-r--r--  2.0 unx     4596 b- defN 23-May-08 15:32 nucliadb/search/tests/unit/search/test_paragraphs.py
--rw-r--r--  2.0 unx     2512 b- defN 23-May-08 15:32 nucliadb/search/tests/unit/search/test_synonyms.py
--rw-r--r--  2.0 unx      833 b- defN 23-May-08 15:32 nucliadb/search/tests/unit/search/requesters/__init__.py
--rw-r--r--  2.0 unx     2528 b- defN 23-May-08 15:32 nucliadb/search/tests/unit/search/requesters/test_utils.py
--rw-r--r--  2.0 unx     2285 b- defN 23-May-08 15:32 nucliadb/static/favicon.ico
--rw-r--r--  2.0 unx     3833 b- defN 23-May-08 15:32 nucliadb/static/index.html
--rw-r--r--  2.0 unx     2639 b- defN 23-May-08 15:32 nucliadb/static/logo.svg
--rw-r--r--  2.0 unx      835 b- defN 23-May-08 15:32 nucliadb/tests/__init__.py
--rw-r--r--  2.0 unx     1000 b- defN 23-May-08 15:32 nucliadb/tests/conftest.py
--rw-r--r--  2.0 unx    11685 b- defN 23-May-08 15:32 nucliadb/tests/fixtures.py
--rw-r--r--  2.0 unx     7370 b- defN 23-May-08 15:32 nucliadb/tests/test_advanced_search.py
--rw-r--r--  2.0 unx    14764 b- defN 23-May-08 15:32 nucliadb/tests/test_api.py
--rw-r--r--  2.0 unx     1290 b- defN 23-May-08 15:32 nucliadb/tests/test_chat.py
--rw-r--r--  2.0 unx     3669 b- defN 23-May-08 15:32 nucliadb/tests/test_conversation.py
--rw-r--r--  2.0 unx     2052 b- defN 23-May-08 15:32 nucliadb/tests/test_counters.py
--rw-r--r--  2.0 unx    12302 b- defN 23-May-08 15:32 nucliadb/tests/test_entities.py
--rw-r--r--  2.0 unx    13274 b- defN 23-May-08 15:32 nucliadb/tests/test_entities_deprecated.py
--rw-r--r--  2.0 unx     3654 b- defN 23-May-08 15:32 nucliadb/tests/test_field_external_file.py
--rw-r--r--  2.0 unx     1487 b- defN 23-May-08 15:32 nucliadb/tests/test_field_ids.py
--rw-r--r--  2.0 unx     3591 b- defN 23-May-08 15:32 nucliadb/tests/test_find.py
--rw-r--r--  2.0 unx     1524 b- defN 23-May-08 15:32 nucliadb/tests/test_kb_slugs.py
--rw-r--r--  2.0 unx    11431 b- defN 23-May-08 15:32 nucliadb/tests/test_labels.py
--rw-r--r--  2.0 unx     6071 b- defN 23-May-08 15:32 nucliadb/tests/test_reindex.py
--rw-r--r--  2.0 unx     8516 b- defN 23-May-08 15:32 nucliadb/tests/test_relations.py
--rw-r--r--  2.0 unx     7072 b- defN 23-May-08 15:32 nucliadb/tests/test_resources.py
--rw-r--r--  2.0 unx    41877 b- defN 23-May-08 15:32 nucliadb/tests/test_search.py
--rw-r--r--  2.0 unx     9708 b- defN 23-May-08 15:32 nucliadb/tests/test_search_sorting.py
--rw-r--r--  2.0 unx     8918 b- defN 23-May-08 15:32 nucliadb/tests/test_suggest.py
--rw-r--r--  2.0 unx     6819 b- defN 23-May-08 15:32 nucliadb/tests/test_synonyms.py
--rw-r--r--  2.0 unx     2637 b- defN 23-May-08 15:32 nucliadb/tests/test_tokens.py
--rw-r--r--  2.0 unx     3159 b- defN 23-May-08 15:32 nucliadb/tests/test_upload.py
--rw-r--r--  2.0 unx     2585 b- defN 23-May-08 15:32 nucliadb/tests/test_usermetadata.py
--rw-r--r--  2.0 unx     8758 b- defN 23-May-08 15:32 nucliadb/tests/test_vectorset.py
--rw-r--r--  2.0 unx      919 b- defN 23-May-08 15:32 nucliadb/tests/knowledgeboxes/__init__.py
--rw-r--r--  2.0 unx     7049 b- defN 23-May-08 15:32 nucliadb/tests/knowledgeboxes/philosophy_books.py
--rw-r--r--  2.0 unx     3131 b- defN 23-May-08 15:32 nucliadb/tests/knowledgeboxes/ten_dummy_resources.py
--rw-r--r--  2.0 unx     2507 b- defN 23-May-08 15:32 nucliadb/tests/utils/__init__.py
--rw-r--r--  2.0 unx     2533 b- defN 23-May-08 15:32 nucliadb/tests/utils/entities.py
--rw-r--r--  2.0 unx     1325 b- defN 23-May-08 15:32 nucliadb/train/__init__.py
--rw-r--r--  2.0 unx     3340 b- defN 23-May-08 15:32 nucliadb/train/app.py
--rw-r--r--  2.0 unx     3832 b- defN 23-May-08 15:32 nucliadb/train/generator.py
--rw-r--r--  2.0 unx     1638 b- defN 23-May-08 15:32 nucliadb/train/lifecycle.py
--rw-r--r--  2.0 unx     1198 b- defN 23-May-08 15:32 nucliadb/train/models.py
--rw-r--r--  2.0 unx     8054 b- defN 23-May-08 15:32 nucliadb/train/nodes.py
--rw-r--r--  2.0 unx     1364 b- defN 23-May-08 15:32 nucliadb/train/run.py
--rw-r--r--  2.0 unx     5755 b- defN 23-May-08 15:32 nucliadb/train/servicer.py
--rw-r--r--  2.0 unx     1415 b- defN 23-May-08 15:32 nucliadb/train/settings.py
--rw-r--r--  2.0 unx     3271 b- defN 23-May-08 15:32 nucliadb/train/upload.py
--rw-r--r--  2.0 unx     6531 b- defN 23-May-08 15:32 nucliadb/train/uploader.py
--rw-r--r--  2.0 unx     3077 b- defN 23-May-08 15:32 nucliadb/train/utils.py
--rw-r--r--  2.0 unx      835 b- defN 23-May-08 15:32 nucliadb/train/api/__init__.py
--rw-r--r--  2.0 unx      958 b- defN 23-May-08 15:32 nucliadb/train/api/models.py
--rw-r--r--  2.0 unx     1479 b- defN 23-May-08 15:32 nucliadb/train/api/utils.py
--rw-r--r--  2.0 unx      928 b- defN 23-May-08 15:32 nucliadb/train/api/v1/__init__.py
--rw-r--r--  2.0 unx     2066 b- defN 23-May-08 15:32 nucliadb/train/api/v1/check.py
--rw-r--r--  2.0 unx      910 b- defN 23-May-08 15:32 nucliadb/train/api/v1/router.py
--rw-r--r--  2.0 unx     1905 b- defN 23-May-08 15:32 nucliadb/train/api/v1/shards.py
--rw-r--r--  2.0 unx     1825 b- defN 23-May-08 15:32 nucliadb/train/api/v1/trainset.py
--rw-r--r--  2.0 unx      835 b- defN 23-May-08 15:32 nucliadb/train/generators/__init__.py
--rw-r--r--  2.0 unx     3289 b- defN 23-May-08 15:32 nucliadb/train/generators/field_classifier.py
--rw-r--r--  2.0 unx     3594 b- defN 23-May-08 15:32 nucliadb/train/generators/paragraph_classifier.py
--rw-r--r--  2.0 unx     4767 b- defN 23-May-08 15:32 nucliadb/train/generators/sentence_classifier.py
--rw-r--r--  2.0 unx    10256 b- defN 23-May-08 15:32 nucliadb/train/generators/token_classifier.py
--rw-r--r--  2.0 unx     2144 b- defN 23-May-08 15:32 nucliadb/train/generators/utils.py
--rw-r--r--  2.0 unx      835 b- defN 23-May-08 15:32 nucliadb/train/tests/__init__.py
--rw-r--r--  2.0 unx     1088 b- defN 23-May-08 15:32 nucliadb/train/tests/conftest.py
--rw-r--r--  2.0 unx     9050 b- defN 23-May-08 15:32 nucliadb/train/tests/fixtures.py
--rw-r--r--  2.0 unx     8132 b- defN 23-May-08 15:32 nucliadb/train/tests/test_field_classification.py
--rw-r--r--  2.0 unx     2729 b- defN 23-May-08 15:32 nucliadb/train/tests/test_get_entities.py
--rw-r--r--  2.0 unx     1660 b- defN 23-May-08 15:32 nucliadb/train/tests/test_get_info.py
--rw-r--r--  2.0 unx     1382 b- defN 23-May-08 15:32 nucliadb/train/tests/test_get_ontology.py
--rw-r--r--  2.0 unx     2201 b- defN 23-May-08 15:32 nucliadb/train/tests/test_get_ontology_count.py
--rw-r--r--  2.0 unx     1416 b- defN 23-May-08 15:32 nucliadb/train/tests/test_list_fields.py
--rw-r--r--  2.0 unx     2944 b- defN 23-May-08 15:32 nucliadb/train/tests/test_list_paragraphs.py
--rw-r--r--  2.0 unx     1423 b- defN 23-May-08 15:32 nucliadb/train/tests/test_list_resources.py
--rw-r--r--  2.0 unx     2863 b- defN 23-May-08 15:32 nucliadb/train/tests/test_list_sentences.py
--rw-r--r--  2.0 unx     8129 b- defN 23-May-08 15:32 nucliadb/train/tests/test_paragraph_classification.py
--rw-r--r--  2.0 unx     8349 b- defN 23-May-08 15:32 nucliadb/train/tests/test_sentence_classification.py
--rw-r--r--  2.0 unx    10122 b- defN 23-May-08 15:32 nucliadb/train/tests/test_token_classification.py
--rw-r--r--  2.0 unx     1328 b- defN 23-May-08 15:32 nucliadb/writer/__init__.py
--rw-r--r--  2.0 unx     3331 b- defN 23-May-08 15:32 nucliadb/writer/app.py
--rw-r--r--  2.0 unx      972 b- defN 23-May-08 15:32 nucliadb/writer/exceptions.py
--rw-r--r--  2.0 unx     2832 b- defN 23-May-08 15:32 nucliadb/writer/lifecycle.py
--rw-r--r--  2.0 unx     2186 b- defN 23-May-08 15:32 nucliadb/writer/openapi.py
--rw-r--r--  2.0 unx     1366 b- defN 23-May-08 15:32 nucliadb/writer/run.py
--rw-r--r--  2.0 unx     1062 b- defN 23-May-08 15:32 nucliadb/writer/settings.py
--rw-r--r--  2.0 unx     1036 b- defN 23-May-08 15:32 nucliadb/writer/utilities.py
--rw-r--r--  2.0 unx      835 b- defN 23-May-08 15:32 nucliadb/writer/api/__init__.py
--rw-r--r--  2.0 unx     1021 b- defN 23-May-08 15:32 nucliadb/writer/api/v1/__init__.py
--rw-r--r--  2.0 unx    22313 b- defN 23-May-08 15:32 nucliadb/writer/api/v1/field.py
--rw-r--r--  2.0 unx     5395 b- defN 23-May-08 15:32 nucliadb/writer/api/v1/knowledgebox.py
--rw-r--r--  2.0 unx    15253 b- defN 23-May-08 15:32 nucliadb/writer/api/v1/resource.py
--rw-r--r--  2.0 unx     1034 b- defN 23-May-08 15:32 nucliadb/writer/api/v1/router.py
--rw-r--r--  2.0 unx    14210 b- defN 23-May-08 15:32 nucliadb/writer/api/v1/services.py
--rw-r--r--  2.0 unx    25744 b- defN 23-May-08 15:32 nucliadb/writer/api/v1/upload.py
--rw-r--r--  2.0 unx     1618 b- defN 23-May-08 15:32 nucliadb/writer/layouts/__init__.py
--rw-r--r--  2.0 unx     2115 b- defN 23-May-08 15:32 nucliadb/writer/layouts/v1.py
--rw-r--r--  2.0 unx      835 b- defN 23-May-08 15:32 nucliadb/writer/resource/__init__.py
--rw-r--r--  2.0 unx     1425 b- defN 23-May-08 15:32 nucliadb/writer/resource/audit.py
--rw-r--r--  2.0 unx     9324 b- defN 23-May-08 15:32 nucliadb/writer/resource/basic.py
--rw-r--r--  2.0 unx    15875 b- defN 23-May-08 15:32 nucliadb/writer/resource/field.py
--rw-r--r--  2.0 unx     1708 b- defN 23-May-08 15:32 nucliadb/writer/resource/origin.py
--rw-r--r--  2.0 unx     1151 b- defN 23-May-08 15:32 nucliadb/writer/resource/slug.py
--rw-r--r--  2.0 unx     4991 b- defN 23-May-08 15:32 nucliadb/writer/resource/vectors.py
--rw-r--r--  2.0 unx      835 b- defN 23-May-08 15:32 nucliadb/writer/tests/__init__.py
--rw-r--r--  2.0 unx     1144 b- defN 23-May-08 15:32 nucliadb/writer/tests/conftest.py
--rw-r--r--  2.0 unx     4204 b- defN 23-May-08 15:32 nucliadb/writer/tests/fixtures.py
--rw-r--r--  2.0 unx    15962 b- defN 23-May-08 15:32 nucliadb/writer/tests/test_fields.py
--rw-r--r--  2.0 unx    22233 b- defN 23-May-08 15:32 nucliadb/writer/tests/test_files.py
--rw-r--r--  2.0 unx     1932 b- defN 23-May-08 15:32 nucliadb/writer/tests/test_knowledgebox.py
--rw-r--r--  2.0 unx     4623 b- defN 23-May-08 15:32 nucliadb/writer/tests/test_reprocess_file_field.py
--rw-r--r--  2.0 unx    19059 b- defN 23-May-08 15:32 nucliadb/writer/tests/test_resources.py
--rw-r--r--  2.0 unx     5345 b- defN 23-May-08 15:32 nucliadb/writer/tests/test_service.py
--rw-r--r--  2.0 unx     3596 b- defN 23-May-08 15:32 nucliadb/writer/tests/test_tus.py
--rw-r--r--  2.0 unx     2028 b- defN 23-May-08 15:32 nucliadb/writer/tests/tus.py
--rw-r--r--  2.0 unx     1287 b- defN 23-May-08 15:32 nucliadb/writer/tests/utils.py
--rw-r--r--  2.0 unx     4772 b- defN 23-May-08 15:32 nucliadb/writer/tus/__init__.py
--rw-r--r--  2.0 unx     4757 b- defN 23-May-08 15:32 nucliadb/writer/tus/dm.py
--rw-r--r--  2.0 unx     2186 b- defN 23-May-08 15:32 nucliadb/writer/tus/exceptions.py
--rw-r--r--  2.0 unx    13818 b- defN 23-May-08 15:32 nucliadb/writer/tus/gcs.py
--rw-r--r--  2.0 unx     5811 b- defN 23-May-08 15:32 nucliadb/writer/tus/local.py
--rw-r--r--  2.0 unx     8571 b- defN 23-May-08 15:32 nucliadb/writer/tus/s3.py
--rw-r--r--  2.0 unx     4682 b- defN 23-May-08 15:32 nucliadb/writer/tus/storage.py
--rw-r--r--  2.0 unx     2580 b- defN 23-May-08 15:32 nucliadb/writer/tus/utils.py
--rw-r--r--  2.0 unx     2913 b- defN 23-May-08 15:33 nucliadb-2.8.5.post247.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-May-08 15:33 nucliadb-2.8.5.post247.dist-info/WHEEL
--rw-r--r--  2.0 unx      710 b- defN 23-May-08 15:33 nucliadb-2.8.5.post247.dist-info/entry_points.txt
--rw-r--r--  2.0 unx        9 b- defN 23-May-08 15:33 nucliadb-2.8.5.post247.dist-info/top_level.txt
--rw-r--r--  2.0 unx        1 b- defN 23-May-08 15:33 nucliadb-2.8.5.post247.dist-info/zip-safe
--rw-rw-r--  2.0 unx    26613 b- defN 23-May-08 15:33 nucliadb-2.8.5.post247.dist-info/RECORD
-294 files, 1596439 bytes uncompressed, 464060 bytes compressed:  70.9%
+Zip file size: 513056 bytes, number of entries: 300
+-rw-r--r--  2.0 unx      891 b- defN 23-May-08 19:19 nucliadb/__init__.py
+-rw-r--r--  2.0 unx     1027 b- defN 23-May-08 19:19 nucliadb/app.py
+-rw-r--r--  2.0 unx     4846 b- defN 23-May-08 19:19 nucliadb/config.py
+-rw-r--r--  2.0 unx     1420 b- defN 23-May-08 19:19 nucliadb/purge.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-08 19:19 nucliadb/py.typed
+-rw-r--r--  2.0 unx     2522 b- defN 23-May-08 19:19 nucliadb/run.py
+-rw-r--r--  2.0 unx     1913 b- defN 23-May-08 19:19 nucliadb/settings.py
+-rw-r--r--  2.0 unx     1011 b- defN 23-May-08 19:19 nucliadb/ingest/__init__.py
+-rw-r--r--  2.0 unx     6021 b- defN 23-May-08 19:19 nucliadb/ingest/app.py
+-rw-r--r--  2.0 unx      995 b- defN 23-May-08 19:19 nucliadb/ingest/cache.py
+-rw-r--r--  2.0 unx     6567 b- defN 23-May-08 19:19 nucliadb/ingest/chitchat.py
+-rw-r--r--  2.0 unx     2425 b- defN 23-May-08 19:19 nucliadb/ingest/partitions.py
+-rw-r--r--  2.0 unx    15823 b- defN 23-May-08 19:19 nucliadb/ingest/processing.py
+-rw-r--r--  2.0 unx     5308 b- defN 23-May-08 19:19 nucliadb/ingest/purge.py
+-rw-r--r--  2.0 unx    18976 b- defN 23-May-08 19:19 nucliadb/ingest/serialize.py
+-rw-r--r--  2.0 unx     3025 b- defN 23-May-08 19:19 nucliadb/ingest/settings.py
+-rw-r--r--  2.0 unx     2531 b- defN 23-May-08 19:19 nucliadb/ingest/txn_utils.py
+-rw-r--r--  2.0 unx     4917 b- defN 23-May-08 19:19 nucliadb/ingest/utils.py
+-rw-r--r--  2.0 unx      835 b- defN 23-May-08 19:19 nucliadb/ingest/consumer/__init__.py
+-rw-r--r--  2.0 unx    10672 b- defN 23-May-08 19:19 nucliadb/ingest/consumer/consumer.py
+-rw-r--r--  2.0 unx     9055 b- defN 23-May-08 19:19 nucliadb/ingest/consumer/pull.py
+-rw-r--r--  2.0 unx     5358 b- defN 23-May-08 19:19 nucliadb/ingest/consumer/service.py
+-rw-r--r--  2.0 unx      835 b- defN 23-May-08 19:19 nucliadb/ingest/fields/__init__.py
+-rw-r--r--  2.0 unx    19273 b- defN 23-May-08 19:19 nucliadb/ingest/fields/base.py
+-rw-r--r--  2.0 unx     6495 b- defN 23-May-08 19:19 nucliadb/ingest/fields/conversation.py
+-rw-r--r--  2.0 unx     1223 b- defN 23-May-08 19:19 nucliadb/ingest/fields/date.py
+-rw-r--r--  2.0 unx     1205 b- defN 23-May-08 19:19 nucliadb/ingest/fields/exceptions.py
+-rw-r--r--  2.0 unx     5159 b- defN 23-May-08 19:19 nucliadb/ingest/fields/file.py
+-rw-r--r--  2.0 unx     1523 b- defN 23-May-08 19:19 nucliadb/ingest/fields/generic.py
+-rw-r--r--  2.0 unx     1235 b- defN 23-May-08 19:19 nucliadb/ingest/fields/keywordset.py
+-rw-r--r--  2.0 unx     2250 b- defN 23-May-08 19:19 nucliadb/ingest/fields/layout.py
+-rw-r--r--  2.0 unx     4084 b- defN 23-May-08 19:19 nucliadb/ingest/fields/link.py
+-rw-r--r--  2.0 unx     1319 b- defN 23-May-08 19:19 nucliadb/ingest/fields/text.py
+-rw-r--r--  2.0 unx      835 b- defN 23-May-08 19:19 nucliadb/ingest/maindb/__init__.py
+-rw-r--r--  2.0 unx     2631 b- defN 23-May-08 19:19 nucliadb/ingest/maindb/driver.py
+-rw-r--r--  2.0 unx      980 b- defN 23-May-08 19:19 nucliadb/ingest/maindb/keys.py
+-rw-r--r--  2.0 unx     7076 b- defN 23-May-08 19:19 nucliadb/ingest/maindb/local.py
+-rw-r--r--  2.0 unx     5400 b- defN 23-May-08 19:19 nucliadb/ingest/maindb/pg.py
+-rw-r--r--  2.0 unx     6146 b- defN 23-May-08 19:19 nucliadb/ingest/maindb/redis.py
+-rw-r--r--  2.0 unx     6313 b- defN 23-May-08 19:19 nucliadb/ingest/maindb/tikv.py
+-rw-r--r--  2.0 unx     3495 b- defN 23-May-08 19:19 nucliadb/ingest/orm/__init__.py
+-rw-r--r--  2.0 unx     6801 b- defN 23-May-08 19:19 nucliadb/ingest/orm/abc.py
+-rw-r--r--  2.0 unx    20650 b- defN 23-May-08 19:19 nucliadb/ingest/orm/brain.py
+-rw-r--r--  2.0 unx    15408 b- defN 23-May-08 19:19 nucliadb/ingest/orm/entities.py
+-rw-r--r--  2.0 unx     1448 b- defN 23-May-08 19:19 nucliadb/ingest/orm/exceptions.py
+-rw-r--r--  2.0 unx    12586 b- defN 23-May-08 19:19 nucliadb/ingest/orm/grpc_node_binding.py
+-rw-r--r--  2.0 unx     4606 b- defN 23-May-08 19:19 nucliadb/ingest/orm/grpc_node_dummy.py
+-rw-r--r--  2.0 unx    21247 b- defN 23-May-08 19:19 nucliadb/ingest/orm/knowledgebox.py
+-rw-r--r--  2.0 unx     1730 b- defN 23-May-08 19:19 nucliadb/ingest/orm/labels.py
+-rw-r--r--  2.0 unx     4291 b- defN 23-May-08 19:19 nucliadb/ingest/orm/local_node.py
+-rw-r--r--  2.0 unx     2890 b- defN 23-May-08 19:19 nucliadb/ingest/orm/local_shard.py
+-rw-r--r--  2.0 unx    11388 b- defN 23-May-08 19:19 nucliadb/ingest/orm/node.py
+-rw-r--r--  2.0 unx     4312 b- defN 23-May-08 19:19 nucliadb/ingest/orm/nodes_manager.py
+-rw-r--r--  2.0 unx    51379 b- defN 23-May-08 19:19 nucliadb/ingest/orm/resource.py
+-rw-r--r--  2.0 unx     5115 b- defN 23-May-08 19:19 nucliadb/ingest/orm/shard.py
+-rw-r--r--  2.0 unx     1739 b- defN 23-May-08 19:19 nucliadb/ingest/orm/synonyms.py
+-rw-r--r--  2.0 unx     3340 b- defN 23-May-08 19:19 nucliadb/ingest/orm/utils.py
+-rw-r--r--  2.0 unx    28888 b- defN 23-May-08 19:19 nucliadb/ingest/orm/processor/__init__.py
+-rw-r--r--  2.0 unx     1694 b- defN 23-May-08 19:19 nucliadb/ingest/orm/processor/sequence_manager.py
+-rw-r--r--  2.0 unx     3113 b- defN 23-May-08 19:19 nucliadb/ingest/service/__init__.py
+-rw-r--r--  2.0 unx      835 b- defN 23-May-08 19:19 nucliadb/ingest/service/exceptions.py
+-rw-r--r--  2.0 unx    34487 b- defN 23-May-08 19:19 nucliadb/ingest/service/writer.py
+-rw-r--r--  2.0 unx      835 b- defN 23-May-08 19:19 nucliadb/ingest/tests/__init__.py
+-rw-r--r--  2.0 unx     1096 b- defN 23-May-08 19:19 nucliadb/ingest/tests/conftest.py
+-rw-r--r--  2.0 unx    25857 b- defN 23-May-08 19:19 nucliadb/ingest/tests/fixtures.py
+-rw-r--r--  2.0 unx     7549 b- defN 23-May-08 19:19 nucliadb/ingest/tests/tikv.py
+-rw-r--r--  2.0 unx    62843 b- defN 23-May-08 19:19 nucliadb/ingest/tests/vectors.py
+-rw-r--r--  2.0 unx      835 b- defN 23-May-08 19:19 nucliadb/ingest/tests/integration/__init__.py
+-rw-r--r--  2.0 unx     1740 b- defN 23-May-08 19:19 nucliadb/ingest/tests/integration/test_chitchat.py
+-rw-r--r--  2.0 unx      833 b- defN 23-May-08 19:19 nucliadb/ingest/tests/integration/consumer/__init__.py
+-rw-r--r--  2.0 unx     5206 b- defN 23-May-08 19:19 nucliadb/ingest/tests/integration/consumer/test_pull.py
+-rw-r--r--  2.0 unx     2751 b- defN 23-May-08 19:19 nucliadb/ingest/tests/integration/consumer/test_service.py
+-rw-r--r--  2.0 unx      835 b- defN 23-May-08 19:19 nucliadb/ingest/tests/integration/ingest/__init__.py
+-rw-r--r--  2.0 unx    27277 b- defN 23-May-08 19:19 nucliadb/ingest/tests/integration/ingest/test_ingest.py
+-rw-r--r--  2.0 unx     2339 b- defN 23-May-08 19:19 nucliadb/ingest/tests/integration/ingest/test_processing_engine.py
+-rw-r--r--  2.0 unx     8606 b- defN 23-May-08 19:19 nucliadb/ingest/tests/integration/ingest/test_relations.py
+-rw-r--r--  2.0 unx      835 b- defN 23-May-08 19:19 nucliadb/ingest/tests/unit/__init__.py
+-rw-r--r--  2.0 unx     1179 b- defN 23-May-08 19:19 nucliadb/ingest/tests/unit/test_cache.py
+-rw-r--r--  2.0 unx     4246 b- defN 23-May-08 19:19 nucliadb/ingest/tests/unit/test_chitchat.py
+-rw-r--r--  2.0 unx     1432 b- defN 23-May-08 19:19 nucliadb/ingest/tests/unit/test_partitions.py
+-rw-r--r--  2.0 unx     5538 b- defN 23-May-08 19:19 nucliadb/ingest/tests/unit/test_processing.py
+-rw-r--r--  2.0 unx     3414 b- defN 23-May-08 19:19 nucliadb/ingest/tests/unit/test_purge.py
+-rw-r--r--  2.0 unx      978 b- defN 23-May-08 19:19 nucliadb/ingest/tests/unit/test_settings.py
+-rw-r--r--  2.0 unx     1403 b- defN 23-May-08 19:19 nucliadb/ingest/tests/unit/test_txn_utils.py
+-rw-r--r--  2.0 unx     2895 b- defN 23-May-08 19:19 nucliadb/ingest/tests/unit/test_utils.py
+-rw-r--r--  2.0 unx      833 b- defN 23-May-08 19:19 nucliadb/ingest/tests/unit/consumer/__init__.py
+-rw-r--r--  2.0 unx     2528 b- defN 23-May-08 19:19 nucliadb/ingest/tests/unit/consumer/test_pull.py
+-rw-r--r--  2.0 unx      835 b- defN 23-May-08 19:19 nucliadb/ingest/tests/unit/orm/__init__.py
+-rw-r--r--  2.0 unx     8991 b- defN 23-May-08 19:19 nucliadb/ingest/tests/unit/orm/test_brain.py
+-rw-r--r--  2.0 unx     2706 b- defN 23-May-08 19:19 nucliadb/ingest/tests/unit/orm/test_cluster.py
+-rw-r--r--  2.0 unx     4212 b- defN 23-May-08 19:19 nucliadb/ingest/tests/unit/orm/test_node.py
+-rw-r--r--  2.0 unx     2812 b- defN 23-May-08 19:19 nucliadb/ingest/tests/unit/orm/test_processor.py
+-rw-r--r--  2.0 unx     3772 b- defN 23-May-08 19:19 nucliadb/ingest/tests/unit/orm/test_resource.py
+-rw-r--r--  2.0 unx     1401 b- defN 23-May-08 19:19 nucliadb/ingest/tests/unit/orm/test_shard.py
+-rw-r--r--  2.0 unx      835 b- defN 23-May-08 19:19 nucliadb/models/__init__.py
+-rw-r--r--  2.0 unx     1599 b- defN 23-May-08 19:19 nucliadb/models/responses.py
+-rw-r--r--  2.0 unx      914 b- defN 23-May-08 19:19 nucliadb/one/__init__.py
+-rw-r--r--  2.0 unx     3539 b- defN 23-May-08 19:19 nucliadb/one/app.py
+-rw-r--r--  2.0 unx     2359 b- defN 23-May-08 19:19 nucliadb/one/lifecycle.py
+-rw-r--r--  2.0 unx      835 b- defN 23-May-08 19:19 nucliadb/one/tests/__init__.py
+-rw-r--r--  2.0 unx     1164 b- defN 23-May-08 19:19 nucliadb/one/tests/conftest.py
+-rw-r--r--  2.0 unx     3762 b- defN 23-May-08 19:19 nucliadb/one/tests/fixtures.py
+-rw-r--r--  2.0 unx     2561 b- defN 23-May-08 19:19 nucliadb/one/tests/test_basic.py
+-rw-r--r--  2.0 unx     2492 b- defN 23-May-08 19:19 nucliadb/one/tests/test_delete_field.py
+-rw-r--r--  2.0 unx     6087 b- defN 23-May-08 19:19 nucliadb/one/tests/test_fieldmetadata.py
+-rw-r--r--  2.0 unx     4594 b- defN 23-May-08 19:19 nucliadb/one/tests/test_services.py
+-rw-r--r--  2.0 unx     4067 b- defN 23-May-08 19:19 nucliadb/one/tests/test_upload_download.py
+-rw-r--r--  2.0 unx     1328 b- defN 23-May-08 19:19 nucliadb/reader/__init__.py
+-rw-r--r--  2.0 unx     3356 b- defN 23-May-08 19:19 nucliadb/reader/app.py
+-rw-r--r--  2.0 unx     1366 b- defN 23-May-08 19:19 nucliadb/reader/lifecycle.py
+-rw-r--r--  2.0 unx     2186 b- defN 23-May-08 19:19 nucliadb/reader/openapi.py
+-rw-r--r--  2.0 unx     1365 b- defN 23-May-08 19:19 nucliadb/reader/run.py
+-rw-r--r--  2.0 unx      872 b- defN 23-May-08 19:19 nucliadb/reader/api/__init__.py
+-rw-r--r--  2.0 unx     2433 b- defN 23-May-08 19:19 nucliadb/reader/api/models.py
+-rw-r--r--  2.0 unx      995 b- defN 23-May-08 19:19 nucliadb/reader/api/v1/__init__.py
+-rw-r--r--  2.0 unx     9790 b- defN 23-May-08 19:19 nucliadb/reader/api/v1/download.py
+-rw-r--r--  2.0 unx     3570 b- defN 23-May-08 19:19 nucliadb/reader/api/v1/knowledgebox.py
+-rw-r--r--  2.0 unx    10721 b- defN 23-May-08 19:19 nucliadb/reader/api/v1/resource.py
+-rw-r--r--  2.0 unx     1011 b- defN 23-May-08 19:19 nucliadb/reader/api/v1/router.py
+-rw-r--r--  2.0 unx    10766 b- defN 23-May-08 19:19 nucliadb/reader/api/v1/services.py
+-rw-r--r--  2.0 unx      835 b- defN 23-May-08 19:19 nucliadb/reader/tests/__init__.py
+-rw-r--r--  2.0 unx     1101 b- defN 23-May-08 19:19 nucliadb/reader/tests/conftest.py
+-rw-r--r--  2.0 unx     4635 b- defN 23-May-08 19:19 nucliadb/reader/tests/fixtures.py
+-rw-r--r--  2.0 unx     2749 b- defN 23-May-08 19:19 nucliadb/reader/tests/test_list_resources.py
+-rw-r--r--  2.0 unx     9946 b- defN 23-May-08 19:19 nucliadb/reader/tests/test_reader_file_download.py
+-rw-r--r--  2.0 unx    11383 b- defN 23-May-08 19:19 nucliadb/reader/tests/test_reader_resource.py
+-rw-r--r--  2.0 unx     6535 b- defN 23-May-08 19:19 nucliadb/reader/tests/test_reader_resource_field.py
+-rw-r--r--  2.0 unx     1535 b- defN 23-May-08 19:19 nucliadb/search/__init__.py
+-rw-r--r--  2.0 unx     4381 b- defN 23-May-08 19:19 nucliadb/search/app.py
+-rw-r--r--  2.0 unx     2310 b- defN 23-May-08 19:19 nucliadb/search/lifecycle.py
+-rw-r--r--  2.0 unx     2206 b- defN 23-May-08 19:19 nucliadb/search/openapi.py
+-rw-r--r--  2.0 unx    11236 b- defN 23-May-08 19:19 nucliadb/search/predict.py
+-rw-r--r--  2.0 unx     1366 b- defN 23-May-08 19:19 nucliadb/search/run.py
+-rw-r--r--  2.0 unx     1108 b- defN 23-May-08 19:19 nucliadb/search/settings.py
+-rw-r--r--  2.0 unx     1238 b- defN 23-May-08 19:19 nucliadb/search/utilities.py
+-rw-r--r--  2.0 unx      835 b- defN 23-May-08 19:19 nucliadb/search/api/__init__.py
+-rw-r--r--  2.0 unx     1077 b- defN 23-May-08 19:19 nucliadb/search/api/v1/__init__.py
+-rw-r--r--  2.0 unx     6845 b- defN 23-May-08 19:19 nucliadb/search/api/v1/chat.py
+-rw-r--r--  2.0 unx     1831 b- defN 23-May-08 19:19 nucliadb/search/api/v1/feedback.py
+-rw-r--r--  2.0 unx     9436 b- defN 23-May-08 19:19 nucliadb/search/api/v1/find.py
+-rw-r--r--  2.0 unx     6938 b- defN 23-May-08 19:19 nucliadb/search/api/v1/knowledgebox.py
+-rw-r--r--  2.0 unx     4781 b- defN 23-May-08 19:19 nucliadb/search/api/v1/resource.py
+-rw-r--r--  2.0 unx      980 b- defN 23-May-08 19:19 nucliadb/search/api/v1/router.py
+-rw-r--r--  2.0 unx    11487 b- defN 23-May-08 19:19 nucliadb/search/api/v1/search.py
+-rw-r--r--  2.0 unx     4212 b- defN 23-May-08 19:19 nucliadb/search/api/v1/suggest.py
+-rw-r--r--  2.0 unx      833 b- defN 23-May-08 19:19 nucliadb/search/requesters/__init__.py
+-rw-r--r--  2.0 unx     6752 b- defN 23-May-08 19:19 nucliadb/search/requesters/utils.py
+-rw-r--r--  2.0 unx      835 b- defN 23-May-08 19:19 nucliadb/search/search/__init__.py
+-rw-r--r--  2.0 unx     2408 b- defN 23-May-08 19:19 nucliadb/search/search/cache.py
+-rw-r--r--  2.0 unx     5337 b- defN 23-May-08 19:19 nucliadb/search/search/fetch.py
+-rw-r--r--  2.0 unx    13815 b- defN 23-May-08 19:19 nucliadb/search/search/find_merge.py
+-rw-r--r--  2.0 unx    18899 b- defN 23-May-08 19:19 nucliadb/search/search/merge.py
+-rw-r--r--  2.0 unx      947 b- defN 23-May-08 19:19 nucliadb/search/search/metrics.py
+-rw-r--r--  2.0 unx    11002 b- defN 23-May-08 19:19 nucliadb/search/search/paragraphs.py
+-rw-r--r--  2.0 unx     9905 b- defN 23-May-08 19:19 nucliadb/search/search/query.py
+-rw-r--r--  2.0 unx     2647 b- defN 23-May-08 19:19 nucliadb/search/search/shards.py
+-rw-r--r--  2.0 unx     2055 b- defN 23-May-08 19:19 nucliadb/search/search/synonyms.py
+-rw-r--r--  2.0 unx     2410 b- defN 23-May-08 19:19 nucliadb/search/search/utils.py
+-rw-r--r--  2.0 unx      835 b- defN 23-May-08 19:19 nucliadb/search/tests/__init__.py
+-rw-r--r--  2.0 unx     1172 b- defN 23-May-08 19:19 nucliadb/search/tests/conftest.py
+-rw-r--r--  2.0 unx     7759 b- defN 23-May-08 19:19 nucliadb/search/tests/fixtures.py
+-rw-r--r--  2.0 unx    15809 b- defN 23-May-08 19:19 nucliadb/search/tests/node.py
+-rw-r--r--  2.0 unx      833 b- defN 23-May-08 19:19 nucliadb/search/tests/unit/__init__.py
+-rw-r--r--  2.0 unx     1560 b- defN 23-May-08 19:19 nucliadb/search/tests/unit/test_app.py
+-rw-r--r--  2.0 unx     1776 b- defN 23-May-08 19:19 nucliadb/search/tests/unit/test_find_orderer.py
+-rw-r--r--  2.0 unx     1329 b- defN 23-May-08 19:19 nucliadb/search/tests/unit/test_openapi.py
+-rw-r--r--  2.0 unx     8495 b- defN 23-May-08 19:19 nucliadb/search/tests/unit/test_predict.py
+-rw-r--r--  2.0 unx     1258 b- defN 23-May-08 19:19 nucliadb/search/tests/unit/test_run.py
+-rw-r--r--  2.0 unx      833 b- defN 23-May-08 19:19 nucliadb/search/tests/unit/search/__init__.py
+-rw-r--r--  2.0 unx     3736 b- defN 23-May-08 19:19 nucliadb/search/tests/unit/search/test_fetch.py
+-rw-r--r--  2.0 unx     4596 b- defN 23-May-08 19:19 nucliadb/search/tests/unit/search/test_paragraphs.py
+-rw-r--r--  2.0 unx     2512 b- defN 23-May-08 19:19 nucliadb/search/tests/unit/search/test_synonyms.py
+-rw-r--r--  2.0 unx      833 b- defN 23-May-08 19:19 nucliadb/search/tests/unit/search/requesters/__init__.py
+-rw-r--r--  2.0 unx     2528 b- defN 23-May-08 19:19 nucliadb/search/tests/unit/search/requesters/test_utils.py
+-rw-r--r--  2.0 unx     2285 b- defN 23-May-08 19:19 nucliadb/static/favicon.ico
+-rw-r--r--  2.0 unx     3833 b- defN 23-May-08 19:19 nucliadb/static/index.html
+-rw-r--r--  2.0 unx     2639 b- defN 23-May-08 19:19 nucliadb/static/logo.svg
+-rw-r--r--  2.0 unx      835 b- defN 23-May-08 19:19 nucliadb/tests/__init__.py
+-rw-r--r--  2.0 unx     1000 b- defN 23-May-08 19:19 nucliadb/tests/conftest.py
+-rw-r--r--  2.0 unx    11567 b- defN 23-May-08 19:19 nucliadb/tests/fixtures.py
+-rw-r--r--  2.0 unx     7370 b- defN 23-May-08 19:19 nucliadb/tests/test_advanced_search.py
+-rw-r--r--  2.0 unx    14764 b- defN 23-May-08 19:19 nucliadb/tests/test_api.py
+-rw-r--r--  2.0 unx     1290 b- defN 23-May-08 19:19 nucliadb/tests/test_chat.py
+-rw-r--r--  2.0 unx     3669 b- defN 23-May-08 19:19 nucliadb/tests/test_conversation.py
+-rw-r--r--  2.0 unx     2052 b- defN 23-May-08 19:19 nucliadb/tests/test_counters.py
+-rw-r--r--  2.0 unx    12302 b- defN 23-May-08 19:19 nucliadb/tests/test_entities.py
+-rw-r--r--  2.0 unx    13274 b- defN 23-May-08 19:19 nucliadb/tests/test_entities_deprecated.py
+-rw-r--r--  2.0 unx     3654 b- defN 23-May-08 19:19 nucliadb/tests/test_field_external_file.py
+-rw-r--r--  2.0 unx     1487 b- defN 23-May-08 19:19 nucliadb/tests/test_field_ids.py
+-rw-r--r--  2.0 unx     3591 b- defN 23-May-08 19:19 nucliadb/tests/test_find.py
+-rw-r--r--  2.0 unx     1524 b- defN 23-May-08 19:19 nucliadb/tests/test_kb_slugs.py
+-rw-r--r--  2.0 unx    11431 b- defN 23-May-08 19:19 nucliadb/tests/test_labels.py
+-rw-r--r--  2.0 unx     6071 b- defN 23-May-08 19:19 nucliadb/tests/test_reindex.py
+-rw-r--r--  2.0 unx     8516 b- defN 23-May-08 19:19 nucliadb/tests/test_relations.py
+-rw-r--r--  2.0 unx     7072 b- defN 23-May-08 19:19 nucliadb/tests/test_resources.py
+-rw-r--r--  2.0 unx    41877 b- defN 23-May-08 19:19 nucliadb/tests/test_search.py
+-rw-r--r--  2.0 unx     9708 b- defN 23-May-08 19:19 nucliadb/tests/test_search_sorting.py
+-rw-r--r--  2.0 unx     8918 b- defN 23-May-08 19:19 nucliadb/tests/test_suggest.py
+-rw-r--r--  2.0 unx     6819 b- defN 23-May-08 19:19 nucliadb/tests/test_synonyms.py
+-rw-r--r--  2.0 unx     2637 b- defN 23-May-08 19:19 nucliadb/tests/test_tokens.py
+-rw-r--r--  2.0 unx     3159 b- defN 23-May-08 19:19 nucliadb/tests/test_upload.py
+-rw-r--r--  2.0 unx     2585 b- defN 23-May-08 19:19 nucliadb/tests/test_usermetadata.py
+-rw-r--r--  2.0 unx     8758 b- defN 23-May-08 19:19 nucliadb/tests/test_vectorset.py
+-rw-r--r--  2.0 unx      919 b- defN 23-May-08 19:19 nucliadb/tests/knowledgeboxes/__init__.py
+-rw-r--r--  2.0 unx     7049 b- defN 23-May-08 19:19 nucliadb/tests/knowledgeboxes/philosophy_books.py
+-rw-r--r--  2.0 unx     3131 b- defN 23-May-08 19:19 nucliadb/tests/knowledgeboxes/ten_dummy_resources.py
+-rw-r--r--  2.0 unx     2507 b- defN 23-May-08 19:19 nucliadb/tests/utils/__init__.py
+-rw-r--r--  2.0 unx     2533 b- defN 23-May-08 19:19 nucliadb/tests/utils/entities.py
+-rw-r--r--  2.0 unx     1325 b- defN 23-May-08 19:19 nucliadb/train/__init__.py
+-rw-r--r--  2.0 unx     3340 b- defN 23-May-08 19:19 nucliadb/train/app.py
+-rw-r--r--  2.0 unx     3832 b- defN 23-May-08 19:19 nucliadb/train/generator.py
+-rw-r--r--  2.0 unx     1638 b- defN 23-May-08 19:19 nucliadb/train/lifecycle.py
+-rw-r--r--  2.0 unx     1198 b- defN 23-May-08 19:19 nucliadb/train/models.py
+-rw-r--r--  2.0 unx     8054 b- defN 23-May-08 19:19 nucliadb/train/nodes.py
+-rw-r--r--  2.0 unx     1364 b- defN 23-May-08 19:19 nucliadb/train/run.py
+-rw-r--r--  2.0 unx     5755 b- defN 23-May-08 19:19 nucliadb/train/servicer.py
+-rw-r--r--  2.0 unx     1415 b- defN 23-May-08 19:19 nucliadb/train/settings.py
+-rw-r--r--  2.0 unx     3271 b- defN 23-May-08 19:19 nucliadb/train/upload.py
+-rw-r--r--  2.0 unx     6471 b- defN 23-May-08 19:19 nucliadb/train/uploader.py
+-rw-r--r--  2.0 unx     3077 b- defN 23-May-08 19:19 nucliadb/train/utils.py
+-rw-r--r--  2.0 unx      835 b- defN 23-May-08 19:19 nucliadb/train/api/__init__.py
+-rw-r--r--  2.0 unx      958 b- defN 23-May-08 19:19 nucliadb/train/api/models.py
+-rw-r--r--  2.0 unx     1479 b- defN 23-May-08 19:19 nucliadb/train/api/utils.py
+-rw-r--r--  2.0 unx      928 b- defN 23-May-08 19:19 nucliadb/train/api/v1/__init__.py
+-rw-r--r--  2.0 unx     2066 b- defN 23-May-08 19:19 nucliadb/train/api/v1/check.py
+-rw-r--r--  2.0 unx      910 b- defN 23-May-08 19:19 nucliadb/train/api/v1/router.py
+-rw-r--r--  2.0 unx     1905 b- defN 23-May-08 19:19 nucliadb/train/api/v1/shards.py
+-rw-r--r--  2.0 unx     1825 b- defN 23-May-08 19:19 nucliadb/train/api/v1/trainset.py
+-rw-r--r--  2.0 unx      835 b- defN 23-May-08 19:19 nucliadb/train/generators/__init__.py
+-rw-r--r--  2.0 unx     3289 b- defN 23-May-08 19:19 nucliadb/train/generators/field_classifier.py
+-rw-r--r--  2.0 unx     3594 b- defN 23-May-08 19:19 nucliadb/train/generators/paragraph_classifier.py
+-rw-r--r--  2.0 unx     4767 b- defN 23-May-08 19:19 nucliadb/train/generators/sentence_classifier.py
+-rw-r--r--  2.0 unx    10256 b- defN 23-May-08 19:19 nucliadb/train/generators/token_classifier.py
+-rw-r--r--  2.0 unx     2144 b- defN 23-May-08 19:19 nucliadb/train/generators/utils.py
+-rw-r--r--  2.0 unx      835 b- defN 23-May-08 19:19 nucliadb/train/tests/__init__.py
+-rw-r--r--  2.0 unx     1088 b- defN 23-May-08 19:19 nucliadb/train/tests/conftest.py
+-rw-r--r--  2.0 unx     8951 b- defN 23-May-08 19:19 nucliadb/train/tests/fixtures.py
+-rw-r--r--  2.0 unx     8132 b- defN 23-May-08 19:19 nucliadb/train/tests/test_field_classification.py
+-rw-r--r--  2.0 unx     2729 b- defN 23-May-08 19:19 nucliadb/train/tests/test_get_entities.py
+-rw-r--r--  2.0 unx     1660 b- defN 23-May-08 19:19 nucliadb/train/tests/test_get_info.py
+-rw-r--r--  2.0 unx     1382 b- defN 23-May-08 19:19 nucliadb/train/tests/test_get_ontology.py
+-rw-r--r--  2.0 unx     2201 b- defN 23-May-08 19:19 nucliadb/train/tests/test_get_ontology_count.py
+-rw-r--r--  2.0 unx     1416 b- defN 23-May-08 19:19 nucliadb/train/tests/test_list_fields.py
+-rw-r--r--  2.0 unx     2944 b- defN 23-May-08 19:19 nucliadb/train/tests/test_list_paragraphs.py
+-rw-r--r--  2.0 unx     1423 b- defN 23-May-08 19:19 nucliadb/train/tests/test_list_resources.py
+-rw-r--r--  2.0 unx     2863 b- defN 23-May-08 19:19 nucliadb/train/tests/test_list_sentences.py
+-rw-r--r--  2.0 unx     8129 b- defN 23-May-08 19:19 nucliadb/train/tests/test_paragraph_classification.py
+-rw-r--r--  2.0 unx     8349 b- defN 23-May-08 19:19 nucliadb/train/tests/test_sentence_classification.py
+-rw-r--r--  2.0 unx    10122 b- defN 23-May-08 19:19 nucliadb/train/tests/test_token_classification.py
+-rw-r--r--  2.0 unx     1328 b- defN 23-May-08 19:19 nucliadb/writer/__init__.py
+-rw-r--r--  2.0 unx     3331 b- defN 23-May-08 19:19 nucliadb/writer/app.py
+-rw-r--r--  2.0 unx      972 b- defN 23-May-08 19:19 nucliadb/writer/exceptions.py
+-rw-r--r--  2.0 unx     2219 b- defN 23-May-08 19:19 nucliadb/writer/lifecycle.py
+-rw-r--r--  2.0 unx     2186 b- defN 23-May-08 19:19 nucliadb/writer/openapi.py
+-rw-r--r--  2.0 unx     1366 b- defN 23-May-08 19:19 nucliadb/writer/run.py
+-rw-r--r--  2.0 unx     1062 b- defN 23-May-08 19:19 nucliadb/writer/settings.py
+-rw-r--r--  2.0 unx     1036 b- defN 23-May-08 19:19 nucliadb/writer/utilities.py
+-rw-r--r--  2.0 unx      835 b- defN 23-May-08 19:19 nucliadb/writer/api/__init__.py
+-rw-r--r--  2.0 unx     1021 b- defN 23-May-08 19:19 nucliadb/writer/api/v1/__init__.py
+-rw-r--r--  2.0 unx    22313 b- defN 23-May-08 19:19 nucliadb/writer/api/v1/field.py
+-rw-r--r--  2.0 unx     5395 b- defN 23-May-08 19:19 nucliadb/writer/api/v1/knowledgebox.py
+-rw-r--r--  2.0 unx    15253 b- defN 23-May-08 19:19 nucliadb/writer/api/v1/resource.py
+-rw-r--r--  2.0 unx     1034 b- defN 23-May-08 19:19 nucliadb/writer/api/v1/router.py
+-rw-r--r--  2.0 unx    14210 b- defN 23-May-08 19:19 nucliadb/writer/api/v1/services.py
+-rw-r--r--  2.0 unx    25744 b- defN 23-May-08 19:19 nucliadb/writer/api/v1/upload.py
+-rw-r--r--  2.0 unx     1618 b- defN 23-May-08 19:19 nucliadb/writer/layouts/__init__.py
+-rw-r--r--  2.0 unx     2115 b- defN 23-May-08 19:19 nucliadb/writer/layouts/v1.py
+-rw-r--r--  2.0 unx      835 b- defN 23-May-08 19:19 nucliadb/writer/resource/__init__.py
+-rw-r--r--  2.0 unx     1425 b- defN 23-May-08 19:19 nucliadb/writer/resource/audit.py
+-rw-r--r--  2.0 unx     9324 b- defN 23-May-08 19:19 nucliadb/writer/resource/basic.py
+-rw-r--r--  2.0 unx    15875 b- defN 23-May-08 19:19 nucliadb/writer/resource/field.py
+-rw-r--r--  2.0 unx     1708 b- defN 23-May-08 19:19 nucliadb/writer/resource/origin.py
+-rw-r--r--  2.0 unx     1151 b- defN 23-May-08 19:19 nucliadb/writer/resource/slug.py
+-rw-r--r--  2.0 unx     4991 b- defN 23-May-08 19:19 nucliadb/writer/resource/vectors.py
+-rw-r--r--  2.0 unx      835 b- defN 23-May-08 19:19 nucliadb/writer/tests/__init__.py
+-rw-r--r--  2.0 unx     1144 b- defN 23-May-08 19:19 nucliadb/writer/tests/conftest.py
+-rw-r--r--  2.0 unx     4204 b- defN 23-May-08 19:19 nucliadb/writer/tests/fixtures.py
+-rw-r--r--  2.0 unx    15962 b- defN 23-May-08 19:19 nucliadb/writer/tests/test_fields.py
+-rw-r--r--  2.0 unx    22630 b- defN 23-May-08 19:19 nucliadb/writer/tests/test_files.py
+-rw-r--r--  2.0 unx     1932 b- defN 23-May-08 19:19 nucliadb/writer/tests/test_knowledgebox.py
+-rw-r--r--  2.0 unx     4623 b- defN 23-May-08 19:19 nucliadb/writer/tests/test_reprocess_file_field.py
+-rw-r--r--  2.0 unx    19059 b- defN 23-May-08 19:19 nucliadb/writer/tests/test_resources.py
+-rw-r--r--  2.0 unx     5345 b- defN 23-May-08 19:19 nucliadb/writer/tests/test_service.py
+-rw-r--r--  2.0 unx     3596 b- defN 23-May-08 19:19 nucliadb/writer/tests/test_tus.py
+-rw-r--r--  2.0 unx     2028 b- defN 23-May-08 19:19 nucliadb/writer/tests/tus.py
+-rw-r--r--  2.0 unx     1287 b- defN 23-May-08 19:19 nucliadb/writer/tests/utils.py
+-rw-r--r--  2.0 unx     4772 b- defN 23-May-08 19:19 nucliadb/writer/tus/__init__.py
+-rw-r--r--  2.0 unx     4757 b- defN 23-May-08 19:19 nucliadb/writer/tus/dm.py
+-rw-r--r--  2.0 unx     2186 b- defN 23-May-08 19:19 nucliadb/writer/tus/exceptions.py
+-rw-r--r--  2.0 unx    13818 b- defN 23-May-08 19:19 nucliadb/writer/tus/gcs.py
+-rw-r--r--  2.0 unx     5811 b- defN 23-May-08 19:19 nucliadb/writer/tus/local.py
+-rw-r--r--  2.0 unx     8571 b- defN 23-May-08 19:19 nucliadb/writer/tus/s3.py
+-rw-r--r--  2.0 unx     4682 b- defN 23-May-08 19:19 nucliadb/writer/tus/storage.py
+-rw-r--r--  2.0 unx     2580 b- defN 23-May-08 19:19 nucliadb/writer/tus/utils.py
+-rw-r--r--  2.0 unx     2913 b- defN 23-May-08 19:21 nucliadb-2.8.5.post249.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-May-08 19:21 nucliadb-2.8.5.post249.dist-info/WHEEL
+-rw-r--r--  2.0 unx      790 b- defN 23-May-08 19:21 nucliadb-2.8.5.post249.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx        9 b- defN 23-May-08 19:21 nucliadb-2.8.5.post249.dist-info/top_level.txt
+-rw-r--r--  2.0 unx        1 b- defN 23-May-08 19:21 nucliadb-2.8.5.post249.dist-info/zip-safe
+-rw-rw-r--  2.0 unx    27273 b- defN 23-May-08 19:21 nucliadb-2.8.5.post249.dist-info/RECORD
+300 files, 1608264 bytes uncompressed, 469754 bytes compressed:  70.8%
```

## zipnote {}

```diff
@@ -51,14 +51,17 @@
 
 Filename: nucliadb/ingest/utils.py
 Comment: 
 
 Filename: nucliadb/ingest/consumer/__init__.py
 Comment: 
 
+Filename: nucliadb/ingest/consumer/consumer.py
+Comment: 
+
 Filename: nucliadb/ingest/consumer/pull.py
 Comment: 
 
 Filename: nucliadb/ingest/consumer/service.py
 Comment: 
 
 Filename: nucliadb/ingest/fields/__init__.py
@@ -96,17 +99,14 @@
 
 Filename: nucliadb/ingest/maindb/__init__.py
 Comment: 
 
 Filename: nucliadb/ingest/maindb/driver.py
 Comment: 
 
-Filename: nucliadb/ingest/maindb/exceptions.py
-Comment: 
-
 Filename: nucliadb/ingest/maindb/keys.py
 Comment: 
 
 Filename: nucliadb/ingest/maindb/local.py
 Comment: 
 
 Filename: nucliadb/ingest/maindb/pg.py
@@ -153,29 +153,32 @@
 
 Filename: nucliadb/ingest/orm/node.py
 Comment: 
 
 Filename: nucliadb/ingest/orm/nodes_manager.py
 Comment: 
 
-Filename: nucliadb/ingest/orm/processor.py
-Comment: 
-
 Filename: nucliadb/ingest/orm/resource.py
 Comment: 
 
 Filename: nucliadb/ingest/orm/shard.py
 Comment: 
 
 Filename: nucliadb/ingest/orm/synonyms.py
 Comment: 
 
 Filename: nucliadb/ingest/orm/utils.py
 Comment: 
 
+Filename: nucliadb/ingest/orm/processor/__init__.py
+Comment: 
+
+Filename: nucliadb/ingest/orm/processor/sequence_manager.py
+Comment: 
+
 Filename: nucliadb/ingest/service/__init__.py
 Comment: 
 
 Filename: nucliadb/ingest/service/exceptions.py
 Comment: 
 
 Filename: nucliadb/ingest/service/writer.py
@@ -198,14 +201,23 @@
 
 Filename: nucliadb/ingest/tests/integration/__init__.py
 Comment: 
 
 Filename: nucliadb/ingest/tests/integration/test_chitchat.py
 Comment: 
 
+Filename: nucliadb/ingest/tests/integration/consumer/__init__.py
+Comment: 
+
+Filename: nucliadb/ingest/tests/integration/consumer/test_pull.py
+Comment: 
+
+Filename: nucliadb/ingest/tests/integration/consumer/test_service.py
+Comment: 
+
 Filename: nucliadb/ingest/tests/integration/ingest/__init__.py
 Comment: 
 
 Filename: nucliadb/ingest/tests/integration/ingest/test_ingest.py
 Comment: 
 
 Filename: nucliadb/ingest/tests/integration/ingest/test_processing_engine.py
@@ -237,14 +249,20 @@
 
 Filename: nucliadb/ingest/tests/unit/test_txn_utils.py
 Comment: 
 
 Filename: nucliadb/ingest/tests/unit/test_utils.py
 Comment: 
 
+Filename: nucliadb/ingest/tests/unit/consumer/__init__.py
+Comment: 
+
+Filename: nucliadb/ingest/tests/unit/consumer/test_pull.py
+Comment: 
+
 Filename: nucliadb/ingest/tests/unit/orm/__init__.py
 Comment: 
 
 Filename: nucliadb/ingest/tests/unit/orm/test_brain.py
 Comment: 
 
 Filename: nucliadb/ingest/tests/unit/orm/test_cluster.py
@@ -858,26 +876,26 @@
 
 Filename: nucliadb/writer/tus/storage.py
 Comment: 
 
 Filename: nucliadb/writer/tus/utils.py
 Comment: 
 
-Filename: nucliadb-2.8.5.post247.dist-info/METADATA
+Filename: nucliadb-2.8.5.post249.dist-info/METADATA
 Comment: 
 
-Filename: nucliadb-2.8.5.post247.dist-info/WHEEL
+Filename: nucliadb-2.8.5.post249.dist-info/WHEEL
 Comment: 
 
-Filename: nucliadb-2.8.5.post247.dist-info/entry_points.txt
+Filename: nucliadb-2.8.5.post249.dist-info/entry_points.txt
 Comment: 
 
-Filename: nucliadb-2.8.5.post247.dist-info/top_level.txt
+Filename: nucliadb-2.8.5.post249.dist-info/top_level.txt
 Comment: 
 
-Filename: nucliadb-2.8.5.post247.dist-info/zip-safe
+Filename: nucliadb-2.8.5.post249.dist-info/zip-safe
 Comment: 
 
-Filename: nucliadb-2.8.5.post247.dist-info/RECORD
+Filename: nucliadb-2.8.5.post249.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## nucliadb/config.py

```diff
@@ -113,17 +113,16 @@
     train_settings.grpc_port = nucliadb_args.train_grpc_port
     ingest_settings.grpc_port = nucliadb_args.ingest_grpc_port
 
     config_standalone_driver(nucliadb_args)
 
     if nucliadb_args.nua_api_key:
         nuclia_settings.nuclia_service_account = nucliadb_args.nua_api_key
-        ingest_settings.pull_time = 60
     else:
-        ingest_settings.pull_time = 0
+        ingest_settings.disable_pull_worker = True
         nuclia_settings.dummy_processing = True
         nuclia_settings.dummy_predict = True
 
     if nucliadb_args.zone is not None:
         nuclia_settings.nuclia_zone = nucliadb_args.zone
     elif os.environ.get("NUA_ZONE"):
         nuclia_settings.nuclia_zone = os.environ.get("NUA_ZONE", "dev")
```

## nucliadb/ingest/app.py

```diff
@@ -14,132 +14,147 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
 # GNU Affero General Public License for more details.
 #
 # You should have received a copy of the GNU Affero General Public License
 # along with this program. If not, see <http://www.gnu.org/licenses/>.
 #
 import asyncio
-from typing import Awaitable, Callable, Optional, Union
+from typing import Awaitable, Callable, Optional
 
 import pkg_resources
 
 from nucliadb.ingest import SERVICE_NAME
 from nucliadb.ingest.chitchat import start_chitchat, stop_chitchat
-from nucliadb.ingest.consumer import start_consumer
+from nucliadb.ingest.consumer import service as consumer_service
 from nucliadb.ingest.partitions import assign_partitions
 from nucliadb.ingest.service import start_grpc
 from nucliadb.ingest.settings import settings
 from nucliadb_telemetry import errors
 from nucliadb_telemetry.logs import setup_logging
 from nucliadb_telemetry.utils import setup_telemetry
 from nucliadb_utils.fastapi.run import serve_metrics
 from nucliadb_utils.indexing import IndexingUtility
 from nucliadb_utils.run import run_until_exit
 from nucliadb_utils.settings import indexing_settings, transaction_settings
-from nucliadb_utils.transaction import LocalTransactionUtility, TransactionUtility
 from nucliadb_utils.utilities import (
     Utility,
     clean_utility,
     get_indexing,
-    get_transaction_utility,
     set_utility,
     start_audit_utility,
+    start_nats_manager,
+    start_transaction_utility,
     stop_audit_utility,
+    stop_nats_manager,
+    stop_transaction_utility,
 )
 
 
-async def start_transaction_utility(service_name: Optional[str] = None):
-    if transaction_settings.transaction_local:
-        transaction_utility: Union[
-            LocalTransactionUtility, TransactionUtility
-        ] = LocalTransactionUtility()
-    elif (
-        transaction_settings.transaction_jetstream_servers is not None
-        and transaction_settings.transaction_jetstream_target is not None
-    ):
-        transaction_utility = TransactionUtility(
-            nats_creds=transaction_settings.transaction_jetstream_auth,
-            nats_servers=transaction_settings.transaction_jetstream_servers,
-            nats_target=transaction_settings.transaction_jetstream_target,
-        )
-        await transaction_utility.initialize(service_name)
-    set_utility(Utility.TRANSACTION, transaction_utility)
-
-
 async def start_indexing_utility(service_name: Optional[str] = None):
     if (
         not indexing_settings.index_local
         and indexing_settings.index_jetstream_servers is not None
-        and indexing_settings.index_jetstream_target is not None
     ):
         indexing_utility = IndexingUtility(
             nats_creds=indexing_settings.index_jetstream_auth,
             nats_servers=indexing_settings.index_jetstream_servers,
-            nats_target=indexing_settings.index_jetstream_target,
         )
         await indexing_utility.initialize(service_name)
         set_utility(Utility.INDEXING, indexing_utility)
 
 
-async def stop_transaction_utility():
-    transaction_utility = get_transaction_utility()
-    if transaction_utility:
-        await transaction_utility.finalize()
-        clean_utility(Utility.TRANSACTION)
-
-
 async def stop_indexing_utility():
     indexing_utility = get_indexing()
     if indexing_utility:
         await indexing_utility.finalize()
         clean_utility(Utility.INDEXING)
 
 
 async def initialize() -> list[Callable[[], Awaitable[None]]]:
     await setup_telemetry(SERVICE_NAME)
 
-    chitchat = await start_chitchat(SERVICE_NAME)
-
     await start_transaction_utility(SERVICE_NAME)
     await start_indexing_utility(SERVICE_NAME)
     await start_audit_utility(SERVICE_NAME)
-    metrics_server = await serve_metrics()
 
     finalizers = [
-        metrics_server.shutdown,
         stop_transaction_utility,
         stop_indexing_utility,
         stop_audit_utility,
-        stop_chitchat,
     ]
 
-    if chitchat is not None:
-        finalizers.append(chitchat.finalize)
+    if not transaction_settings.transaction_local:
+        # if we're running in standalone, we do not
+        # want these services
+        await start_nats_manager(
+            SERVICE_NAME,
+            transaction_settings.transaction_jetstream_servers,
+            transaction_settings.transaction_jetstream_auth,
+        )
+        finalizers.append(stop_nats_manager)
+
+        await start_chitchat(SERVICE_NAME)
+        finalizers.append(stop_chitchat)
 
     return finalizers
 
 
-async def initialize_consumer_and_grpc() -> list[Callable[[], Awaitable[None]]]:
+async def initialize_pull_workers() -> list[Callable[[], Awaitable[None]]]:
+    finalizers = await initialize()
+
+    grpc_finalizer = await start_grpc(SERVICE_NAME)
+    pull_workers = await consumer_service.start_pull_workers(SERVICE_NAME)
+
+    return [grpc_finalizer, pull_workers] + finalizers
+
+
+async def initialize_grpc() -> list[Callable[[], Awaitable[None]]]:
     finalizers = await initialize()
 
     grpc_finalizer = await start_grpc(SERVICE_NAME)
-    consumer_finalizer = await start_consumer(SERVICE_NAME)
 
-    return [grpc_finalizer, consumer_finalizer] + finalizers
+    return [grpc_finalizer] + finalizers
 
 
 async def main_consumer():  # pragma: no cover
-    finalizers = await initialize_consumer_and_grpc()
-    await run_until_exit(finalizers)
+    finalizers = await initialize()
+    metrics_server = await serve_metrics()
+
+    # grpc service here for legacy but can be removed
+    # useful part is the health check
+    grpc_finalizer = await start_grpc(SERVICE_NAME)
+
+    # pull workers could be pulled out into it's own deployment
+    pull_workers = await consumer_service.start_pull_workers(SERVICE_NAME)
+    ingest_consumers = await consumer_service.start_ingest_consumers(SERVICE_NAME)
+
+    await run_until_exit(
+        [grpc_finalizer, pull_workers, ingest_consumers, metrics_server.shutdown]
+        + finalizers
+    )
 
 
 async def main_orm_grpc():  # pragma: no cover
+    finalizers = await initialize_grpc()
+    metrics_server = await serve_metrics()
+    await run_until_exit([metrics_server.shutdown] + finalizers)
+
+
+async def main_ingest_processed_consumer():  # pragma: no cover
     finalizers = await initialize()
+
+    metrics_server = await serve_metrics()
+
+    # grpc service here for legacy but can be removed(sans health check)
     grpc_finalizer = await start_grpc(SERVICE_NAME)
-    await run_until_exit([grpc_finalizer] + finalizers)
+    consumer = await consumer_service.start_ingest_processed_consumer(SERVICE_NAME)
+
+    await run_until_exit(
+        [grpc_finalizer, consumer, metrics_server.shutdown] + finalizers
+    )
 
 
 def setup_configuration():  # pragma: no cover
     setup_logging()
 
     assign_partitions(settings)
 
@@ -159,7 +174,15 @@
 
 def run_orm_grpc() -> None:  # pragma: no cover
     """
     Run the ingest GRPC service
     """
     setup_configuration()
     asyncio.run(main_orm_grpc())
+
+
+def run_processed_consumer() -> None:  # pragma: no cover
+    """
+    Run the consumer + GRPC ingest service
+    """
+    setup_configuration()
+    asyncio.run(main_ingest_processed_consumer())
```

## nucliadb/ingest/purge.py

```diff
@@ -73,15 +73,15 @@
             continue
 
         # Now delete the tikv delete mark
         try:
             txn = await driver.begin()
             key_to_purge = KB_TO_DELETE.format(kbid=kbid)
             await txn.delete(key_to_purge)
-            await txn.commit(resource=False)
+            await txn.commit()
             logger.info(f"   Deleted {key_to_purge}")
         except Exception as exc:
             errors.capture_exception(exc)
             logger.info(f"  X Error while deleting key {key_to_purge}")
             await txn.abort()
     logger.info("END PURGING KB")
 
@@ -122,15 +122,15 @@
                 await txn.delete(key)
                 logger.info(f"   Deleted storage deletion marker {key}")
             except Exception as exc:
                 errors.capture_exception(exc)
                 logger.info(f"  X Error while deleting key {key}")
                 await txn.abort()
             else:
-                await txn.commit(resource=False)
+                await txn.commit()
 
     logger.info("FINISH PURGING KB STORAGE")
 
 
 async def main():
     # Clean up all kb marked to delete
     driver = await get_driver()
```

## nucliadb/ingest/settings.py

```diff
@@ -49,15 +49,16 @@
 
 
 class Settings(DriverSettings):
     grpc_port: int = 8030
 
     partitions: List[str] = ["1"]
 
-    pull_time: int = 100
+    pull_time_error_backoff: int = 100
+    disable_pull_worker: bool = False
 
     replica_number: int = -1
     total_replicas: int = 1
     nuclia_partitions: int = 50
 
     # NODE INFORMATION
```

## nucliadb/ingest/consumer/__init__.py

```diff
@@ -13,17 +13,7 @@
 # but WITHOUT ANY WARRANTY; without even the implied warranty of
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
 # GNU Affero General Public License for more details.
 #
 # You should have received a copy of the GNU Affero General Public License
 # along with this program. If not, see <http://www.gnu.org/licenses/>.
 #
-from typing import Optional
-
-from nucliadb.ingest.consumer.service import ConsumerService
-
-
-async def start_consumer(service_name: Optional[str] = None):
-    consumer = ConsumerService()
-    await consumer.start(service_name)
-
-    return consumer.stop
```

## nucliadb/ingest/consumer/pull.py

```diff
@@ -15,326 +15,112 @@
 # GNU Affero General Public License for more details.
 #
 # You should have received a copy of the GNU Affero General Public License
 # along with this program. If not, see <http://www.gnu.org/licenses/>.
 #
 import asyncio
 import base64
-import logging
-import time
 from typing import List, Optional
 
 import aiohttp
 import nats
 from aiohttp.client_exceptions import ClientConnectorError
 from aiohttp.web import Response
-from nats.aio.client import Msg
 from nats.aio.subscription import Subscription
 from nucliadb_protos.writer_pb2 import BrokerMessage
 
-from nucliadb.ingest import SERVICE_NAME, logger, logger_activity
+from nucliadb.ingest import logger, logger_activity
 from nucliadb.ingest.maindb.driver import Driver
-from nucliadb.ingest.orm.exceptions import (
-    DeadletteredError,
-    ReallyStopPulling,
-    SequenceOrderViolation,
-)
+from nucliadb.ingest.orm.exceptions import ReallyStopPulling
 from nucliadb.ingest.orm.processor import Processor
-from nucliadb_telemetry import errors, metrics
-from nucliadb_telemetry.utils import set_info_on_span
+from nucliadb_telemetry import errors
+from nucliadb_utils import const
 from nucliadb_utils.audit.audit import AuditStorage
-from nucliadb_utils.cache import KB_COUNTER_CACHE
 from nucliadb_utils.cache.utility import Cache
-from nucliadb_utils.exceptions import ShardsNotFound
-from nucliadb_utils.nats import get_traced_jetstream
 from nucliadb_utils.storages.storage import Storage
-from nucliadb_utils.utilities import get_transaction_utility
-
-consumer_observer = metrics.Observer(
-    "message_processor",
-    labels={"source": ""},
-    buckets=[
-        0.01,
-        0.025,
-        0.05,
-        0.1,
-        0.5,
-        1.0,
-        2.5,
-        5.0,
-        7.5,
-        10.0,
-        30.0,
-        60.0,
-        120.0,
-        float("inf"),
-    ],
-    error_mappings={"deadlettered": DeadletteredError, "shardnotfound": ShardsNotFound},
-)
+from nucliadb_utils.utilities import get_transaction_utility, has_feature
 
 
 class PullWorker:
+    """
+    The pull worker is responsible for pulling messages from the pull processing
+    http endpoint and injecting them into the processing write queue.
+
+    The processing pull endpoint is also described as the "processing proxy" at times.
+    """
+
     subscriptions: List[Subscription]
 
     def __init__(
         self,
         driver: Driver,
         partition: str,
         storage: Storage,
-        pull_time: int,
+        pull_time_error_backoff: int,
         zone: str,
         nuclia_cluster_url: str,
         nuclia_public_url: str,
         audit: Optional[AuditStorage],
-        target: str,
-        group: str,
-        stream: str,
         onprem: bool,
         cache: Optional[Cache] = None,
-        service_name: Optional[str] = None,
-        nats_creds: Optional[str] = None,
-        nats_servers: Optional[List[str]] = None,
         creds: Optional[str] = None,
         local_subscriber: bool = False,
+        pull_time_empty_backoff: float = 5.0,
     ):
         self.driver = driver
         self.partition = partition
         self.storage = storage
-        self.pull_time = pull_time
+        self.pull_time_error_backoff = pull_time_error_backoff
+        self.pull_time_empty_backoff = pull_time_empty_backoff
         self.audit = audit
         self.zone = zone
         self.nuclia_cluster_url = nuclia_cluster_url
         self.nuclia_public_url = nuclia_public_url
         self.local_subscriber = local_subscriber
-        self.nats_subscriber = not local_subscriber
         self.creds = creds
         self.cache = cache
-        self.nats_creds = nats_creds
-        self.nats_servers = nats_servers or []
-        self.target = target
-        self.group = group
-        self.stream = stream
         self.onprem = onprem
-        self.service_name = service_name
-        self.idle_heartbeat = 5 * 1_000_000_000
-        self.ack_wait = 10 * 60
         self.nc = None
-        self.js = None
-        self.initialized = False
-
-        self.subscriptions = []
 
         self.lock = asyncio.Lock()
         self.processor = Processor(driver, storage, audit, cache, partition)
 
-    async def disconnected_cb(self):
-        logger.info(
-            f"PullWorker[partition={self.partition}]: Got disconnected from NATS!"
-        )
-
-    async def reconnected_cb(self):
-        # See who we are connected to on reconnect.
-        logger.warning(
-            f"PullWorker[partition={self.partition}]: \
-                Got reconnected to NATS {self.nc.connected_url.netloc}. Attempting to re-subscribe."
-        )
-        await self.drain_subscriptions()
-        await self.setup_nats_subscription()
-
-    async def error_cb(self, e):
-        msg = f"PullWorker[partition={self.partition}]: There was an error on consumer: {e}"
-        logger.error(msg, exc_info=True)
-
-    async def closed_cb(self):
-        logger.info(
-            f"PullWorker[partition={self.partition}]: Connection is closed on NATS"
-        )
-
-    async def initialize(self):
-        await self.processor.initialize()
-
-        if self.nats_subscriber:
-            options = {
-                "error_cb": self.error_cb,
-                "closed_cb": self.closed_cb,
-                "reconnected_cb": self.reconnected_cb,
-            }
-
-            if self.nats_creds is not None:
-                options["user_credentials"] = self.nats_creds
-
-            if len(self.nats_servers) > 0:
-                options["servers"] = self.nats_servers
-
-            try:
-                self.nc = await nats.connect(**options)
-            except Exception:
-                pass
-
-            if self.nc is not None:
-                self.js = get_traced_jetstream(self.nc, SERVICE_NAME)
-                await self.setup_nats_subscription()
-
-        self.initialized = True
-
-    async def setup_nats_subscription(self):
-        last_seqid = await self.processor.driver.last_seqid(self.partition)
-        if last_seqid is None:
-            last_seqid = 1
-        self.subscriptions.append(
-            await self.js.subscribe(
-                subject=self.target.format(partition=self.partition),
-                queue=self.group.format(partition=self.partition),
-                stream=self.stream,
-                flow_control=True,
-                cb=self.subscription_worker,
-                config=nats.js.api.ConsumerConfig(
-                    deliver_policy=nats.js.api.DeliverPolicy.BY_START_SEQUENCE,
-                    opt_start_seq=last_seqid,
-                    ack_policy=nats.js.api.AckPolicy.EXPLICIT,
-                    max_ack_pending=1,
-                    max_deliver=10000,
-                    ack_wait=self.ack_wait,
-                    idle_heartbeat=5.0,
-                ),
+    async def handle_message(self, payload: bytes):
+        pb = BrokerMessage()
+        pb.ParseFromString(base64.b64decode(payload))
+
+        logger.debug(
+            f"Resource: {pb.uuid} KB: {pb.kbid} ProcessingID: {pb.processing_id}"
+        )
+
+        if not self.local_subscriber:
+            transaction_utility = get_transaction_utility()
+            if transaction_utility is None:
+                raise Exception("No transaction utility defined")
+            subject = None
+            if has_feature(const.Features.SEPARATE_PROCESSED_MESSAGE_WRITES):
+                # send messsages to queue that is managed by separated consumer
+                subject = const.Streams.INGEST_PROCESSED.subject
+            await transaction_utility.commit(
+                writer=pb, partition=int(self.partition), target_subject=subject
+            )
+        else:
+            # No nats defined == monolitic nucliadb
+            await self.processor.process(
+                pb,
+                0,  # Fake sequence id as in local mode there's no transactions
+                partition=self.partition,
+                transaction_check=False,
             )
-        )
-        logger.info(
-            f"Subscribed to {self.target.format(partition=self.partition)} \
-                        on stream {self.stream} from {last_seqid}"
-        )
-
-    async def drain_subscriptions(self) -> None:
-        for subscription in self.subscriptions:
-            try:
-                await subscription.drain()
-            except nats.errors.ConnectionClosedError:
-                pass
-        self.subscriptions = []
-
-    async def finalize(self):
-        await self.drain_subscriptions()
-        if self.nats_subscriber and self.nc is not None:
-            try:
-                await self.nc.drain()
-            except nats.errors.ConnectionClosedError:
-                pass
-            await self.nc.close()
-
-    async def subscription_worker(self, msg: Msg):
-        subject = msg.subject
-        reply = msg.reply
-        seqid = int(reply.split(".")[5])
-        logger.info(
-            f"Message received: subject:{subject}, seqid: {seqid}, reply: {reply}"
-        )
-        message_source = "<msg source not set>"
-        start = time.monotonic()
-
-        async with self.lock:
-            try:
-                pb = BrokerMessage()
-                pb.ParseFromString(msg.data)
-                if pb.source == pb.MessageSource.PROCESSOR:
-                    message_source = "processing"
-                elif pb.source == pb.MessageSource.WRITER:
-                    message_source = "writer"
-                if pb.HasField("audit"):
-                    audit_time = pb.audit.when.ToDatetime().isoformat()
-                else:
-                    audit_time = ""
-
-                logger.debug(
-                    f"Received from {message_source} on {pb.kbid}/{pb.uuid} seq {seqid} partition {self.partition} at {time}"  # noqa
-                )
-                set_info_on_span({"nuclia.kbid": pb.kbid, "nuclia.rid": pb.uuid})
-
-                try:
-                    with consumer_observer(
-                        {
-                            "source": "writer"
-                            if pb.source == pb.MessageSource.WRITER
-                            else "processor"
-                        }
-                    ):
-                        await self.processor.process(pb, seqid, self.partition)
-                except SequenceOrderViolation as err:
-                    log_func = logger.error
-                    if seqid == err.last_seqid:  # pragma: no cover
-                        # Occasional retries of the last processed message may happen
-                        log_func = logger.warning
-                    log_func(
-                        f"Old txn: DISCARD (nucliadb seqid: {seqid}, partition: {self.partition}). Current seqid: {err.last_seqid}"  # noqa
-                    )
-                else:
-                    message_type_name = pb.MessageType.Name(pb.type)
-                    time_to_process = time.monotonic() - start
-                    log_level = (
-                        logging.INFO if time_to_process < 10 else logging.WARNING
-                    )
-                    logger.log(
-                        log_level,
-                        f"Successfully processed {message_type_name} message from \
-                            {message_source}. kb: {pb.kbid}, resource: {pb.uuid}, \
-                                nucliadb seqid: {seqid}, partition: {self.partition} as {audit_time}, \
-                                    total time: {time_to_process:.2f}s",
-                    )
-                    if self.cache is not None:
-                        await self.cache.delete(
-                            KB_COUNTER_CACHE.format(kbid=pb.kbid), invalidate=True
-                        )
-            except DeadletteredError as e:
-                # Messages that have been sent to deadletter at some point
-                # We don't want to process it again so it's ack'd
-                errors.capture_exception(e)
-                logger.info(
-                    f"An error happend while processing a message from {message_source}. "
-                    f"A copy of the message has been stored on {self.processor.storage.deadletter_bucket}. "
-                    f"Check sentry for more details: {str(e)}"
-                )
-                await msg.ack()
-            except (ShardsNotFound,) as e:
-                # Any messages that for some unexpected inconsistency have failed and won't be tried again
-                # as we cannot do anything about it
-                # - ShardsNotFound: /kb/{id}/shards key or the whole /kb/{kbid} is missing
-                errors.capture_exception(e)
-                logger.info(
-                    f"An error happend while processing a message from {message_source}. "
-                    f"This message has been dropped and won't be retried again"
-                    f"Check sentry for more details: {str(e)}"
-                )
-                await msg.ack()
-            except Exception as e:
-                # Unhandled exceptions that need to be retried after a small delay
-                errors.capture_exception(e)
-                logger.info(
-                    f"An error happend while processing a message from {message_source}. "
-                    "Message has not been ACKd and will be retried. "
-                    f"Check sentry for more details: {str(e)}"
-                )
-                await asyncio.sleep(2)
-                raise e
-            else:
-                # Successful processing
-                await msg.ack()
 
     async def loop(self):
-        while self.initialized is False:
-            try:
-                await self.initialize()
-            except Exception as e:
-                errors.capture_exception(e)
-                logger.exception("Exception on initializing worker", exc_info=e)
-                await asyncio.sleep(10)
+        """
+        Run this forever
+        """
 
-        if self.pull_time == 0:
-            logger.debug("Not pulling data from Nuclia")
-            return
-
-        # Lets do pooling from NUA
         while True:
             try:
                 await self._loop()
             except ReallyStopPulling:
                 logger.info("Exiting...")
                 break
             except Exception as e:
@@ -384,77 +170,56 @@
                         if data.get("status") == "ok":
                             check_proxy_telemetry_headers(resp)
                             logger.info(
                                 f"Message received from proxy, partition: {self.partition}"
                             )
                             async with self.lock:
                                 try:
-                                    transaction_utility = get_transaction_utility()
-                                    if transaction_utility is None:
-                                        raise Exception(
-                                            "No transaction utility defined"
-                                        )
-
-                                    pb = BrokerMessage()
-                                    pb.ParseFromString(
-                                        base64.b64decode(data["payload"])
-                                    )
-
-                                    logger.debug(
-                                        f"Resource: {pb.uuid} KB: {pb.kbid} ProcessingID: {pb.processing_id}"
-                                    )
-
-                                    if self.nats_subscriber:
-                                        await transaction_utility.commit(
-                                            writer=pb, partition=self.partition
-                                        )
-                                    else:
-                                        # No nats defined == monolitic nucliadb
-                                        await self.processor.process(
-                                            pb,
-                                            0,  # Fake sequence id as in local mode there's no transactions
-                                            partition=self.partition,
-                                            transaction_check=False,
-                                        )
+                                    await self.handle_message(data["payload"])
                                 except Exception as e:
                                     errors.capture_exception(e)
                                     logger.exception(
                                         "Error while pulling and forwarding proxy message to nucliadb nats"
                                     )
                                     raise e
                         elif data.get("status") == "empty":
                             logger_activity.debug(
                                 f"No messages waiting in partition #{self.partition}"
                             )
-                            await asyncio.sleep(self.pull_time)
+                            await asyncio.sleep(self.pull_time_empty_backoff)
                         else:
                             logger.info(f"Proxy pull answered with error: {data}")
-                            await asyncio.sleep(self.pull_time)
-                except asyncio.exceptions.CancelledError:
+                            await asyncio.sleep(self.pull_time_error_backoff)
+                except (
+                    asyncio.exceptions.CancelledError,
+                    RuntimeError,
+                    KeyboardInterrupt,
+                    SystemExit,
+                ):
                     logger.info(
                         f"Pull task for partition #{self.partition} was canceled, exiting"
                     )
                     raise ReallyStopPulling()
 
                 except ClientConnectorError:
                     logger.error(
                         f"Could not connect to {url}, verify your internet connection"
                     )
-                    await asyncio.sleep(self.pull_time)
+                    await asyncio.sleep(self.pull_time_error_backoff)
 
                 except nats.errors.MaxPayloadError as e:
                     if data is not None:
                         logger.error(
                             f"Message too big to transaction: {len(data['payload'])}"
                         )
                     raise e
 
                 except Exception:
                     logger.exception("Gathering changes")
-                    await asyncio.sleep(self.pull_time)
+                    await asyncio.sleep(self.pull_time_error_backoff)
 
 
 class TelemetryHeadersMissing(Exception):
     pass
 
 
 def check_proxy_telemetry_headers(resp: Response):
```

## nucliadb/ingest/consumer/service.py

```diff
@@ -14,166 +14,141 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
 # GNU Affero General Public License for more details.
 #
 # You should have received a copy of the GNU Affero General Public License
 # along with this program. If not, see <http://www.gnu.org/licenses/>.
 #
 import asyncio
-from typing import Dict, List, Optional
+import sys
+from functools import partial
+from typing import Awaitable, Callable, Optional
 
 from nucliadb.ingest import SERVICE_NAME, logger
+from nucliadb.ingest.consumer.consumer import IngestConsumer, IngestProcessedConsumer
 from nucliadb.ingest.consumer.pull import PullWorker
-from nucliadb.ingest.maindb.driver import Driver
 from nucliadb.ingest.orm import NODES
 from nucliadb.ingest.settings import settings
 from nucliadb.ingest.utils import get_driver
+from nucliadb_utils.exceptions import ConfigurationError
 from nucliadb_utils.settings import (
     nuclia_settings,
     running_settings,
     transaction_settings,
 )
-from nucliadb_utils.storages.storage import Storage
-from nucliadb_utils.utilities import get_audit, get_cache, get_storage
+from nucliadb_utils.utilities import get_audit, get_cache, get_nats_manager, get_storage
 
 
-class ConsumerService:
-    pull_workers_task: Dict[str, asyncio.Task]
-    pull_workers: Dict[str, PullWorker]
-    driver: Driver
-    storage: Storage
-
-    def __init__(
-        self,
-        partitions: Optional[List[str]] = None,
-        pull_time: Optional[int] = None,
-        zone: Optional[str] = None,
-        creds: Optional[str] = None,
-        nuclia_cluster_url: Optional[str] = None,
-        nuclia_public_url: Optional[str] = None,
-        nats_servers: Optional[List[str]] = None,
-        nats_auth: Optional[str] = None,
-        nats_target: Optional[str] = None,
-        nats_group: Optional[str] = None,
-        nats_stream: Optional[str] = None,
-        onprem: Optional[bool] = None,
-    ):
-        if partitions is not None:
-            self.partitions: List[str] = partitions
-        else:
-            self.partitions = settings.partitions
-
-        if pull_time is not None:
-            self.pull_time: int = pull_time
-        else:
-            self.pull_time = settings.pull_time
-
-        if zone is not None:
-            self.zone: str = zone
-        else:
-            self.zone = nuclia_settings.nuclia_zone
-
-        if creds is not None:
-            self.nuclia_creds: Optional[str] = creds
-        else:
-            self.nuclia_creds = nuclia_settings.nuclia_service_account
-
-        if nuclia_cluster_url is not None:
-            self.nuclia_cluster_url: str = nuclia_cluster_url
-        else:
-            self.nuclia_cluster_url = nuclia_settings.nuclia_cluster_url
-
-        self.nuclia_public_url = (
-            nuclia_public_url
-            if nuclia_public_url
-            else nuclia_settings.nuclia_public_url
+def _handle_task_result(task: asyncio.Task) -> None:
+    e = task.exception()
+    if e:
+        logger.exception(
+            "Loop stopped by exception. This should not happen. Exiting.", exc_info=e
         )
+        sys.exit(1)
 
-        self.nats_auth = (
-            nats_auth if nats_auth else transaction_settings.transaction_jetstream_auth
-        )
-        self.nats_url = (
-            nats_servers
-            if nats_servers is not None and len(nats_servers) > 0
-            else transaction_settings.transaction_jetstream_servers
+
+async def _exit_tasks(tasks: list[asyncio.Task]) -> None:
+    for task in tasks:
+        task.cancel()
+    await asyncio.gather(*tasks, return_exceptions=True)
+
+
+async def start_pull_workers(
+    service_name: Optional[str] = None,
+) -> Callable[[], Awaitable[None]]:
+    driver = await get_driver()
+    cache = await get_cache()
+    storage = await get_storage(service_name=service_name or SERVICE_NAME)
+    audit = get_audit()
+    tasks = []
+    for partition in settings.partitions:
+        worker = PullWorker(
+            driver=driver,
+            partition=partition,
+            storage=storage,
+            pull_time_error_backoff=settings.pull_time_error_backoff,
+            zone=nuclia_settings.nuclia_zone,
+            cache=cache,
+            audit=audit,
+            creds=nuclia_settings.nuclia_service_account,
+            nuclia_cluster_url=nuclia_settings.nuclia_cluster_url,
+            nuclia_public_url=nuclia_settings.nuclia_public_url,
+            onprem=nuclia_settings.onprem,
+            local_subscriber=transaction_settings.transaction_local,
         )
+        task = asyncio.create_task(worker.loop())
+        task.add_done_callback(_handle_task_result)
+        tasks.append(task)
+
+    return partial(_exit_tasks, tasks)
+
+
+async def start_ingest_consumers(
+    service_name: Optional[str] = None,
+) -> Callable[[], Awaitable[None]]:
+    if transaction_settings.transaction_local:
+        raise ConfigurationError("Can not start ingest consumers in local mode")
+
+    while len(NODES) == 0 and running_settings.running_environment not in (
+        "local",
+        "test",
+    ):
+        logger.warning("Initializion delayed 1s to receive some Nodes on the cluster")
+        await asyncio.sleep(1)
 
-        if nats_target is not None:
-            self.nats_target: str = nats_target
-        else:
-            self.nats_target = transaction_settings.transaction_jetstream_target
-
-        if nats_group is not None:
-            self.nats_group: str = nats_group
-        else:
-            self.nats_group = transaction_settings.transaction_jetstream_group
-
-        if nats_stream is not None:
-            self.nats_stream: str = nats_stream
-        else:
-            self.nats_stream = transaction_settings.transaction_jetstream_stream
-
-        self.local_subscriber = transaction_settings.transaction_local
-        self.onprem = onprem if onprem is not None else nuclia_settings.onprem
-        self.pull_workers_task = {}
-        self.pull_workers = {}
-        self.audit = get_audit()
-
-    async def run(self, service_name: Optional[str] = None):
-        logger.info(
-            f"Ingest txn from zone '{self.zone}' & partitions: {','.join(self.partitions)}"
+    driver = await get_driver()
+    cache = await get_cache()
+    storage = await get_storage(service_name=service_name or SERVICE_NAME)
+    audit = get_audit()
+    nats_connection_manager = get_nats_manager()
+
+    for partition in settings.partitions:
+        consumer = IngestConsumer(
+            driver=driver,
+            partition=partition,
+            storage=storage,
+            cache=cache,
+            audit=audit,
+            nats_connection_manager=nats_connection_manager,
         )
+        await consumer.initialize()
+
+    return nats_connection_manager.finalize
+
+
+async def start_ingest_processed_consumer(
+    service_name: Optional[str] = None,
+) -> Callable[[], Awaitable[None]]:
+    """
+    This is not meant to be deployed with a stateful set like the other consumers.
+
+    We are not maintaining transactionability based on the nats sequence id from this
+    consumer and we will start off by not separating writes by partition AND
+    allowing NATS to manage the queue group for us.
+    """
+    if transaction_settings.transaction_local:
+        raise ConfigurationError("Can not start ingest consumers in local mode")
+
+    while len(NODES) == 0 and running_settings.running_environment not in (
+        "local",
+        "test",
+    ):
+        logger.warning("Initializion delayed 1s to receive some Nodes on the cluster")
+        await asyncio.sleep(1)
+
+    driver = await get_driver()
+    cache = await get_cache()
+    storage = await get_storage(service_name=service_name or SERVICE_NAME)
+    audit = get_audit()
+    nats_connection_manager = get_nats_manager()
+
+    consumer = IngestProcessedConsumer(
+        driver=driver,
+        partition="-1",
+        storage=storage,
+        cache=cache,
+        audit=audit,
+        nats_connection_manager=nats_connection_manager,
+    )
+    await consumer.initialize()
 
-        while len(NODES) == 0 and running_settings.running_environment not in (
-            "local",
-            "test",
-        ):
-            logger.warning(
-                "Initializion delayed 1s to receive some Nodes on the cluster"
-            )
-            await asyncio.sleep(1)
-
-        for partition in self.partitions:
-            self.pull_workers[partition] = PullWorker(
-                driver=self.driver,
-                partition=partition,
-                storage=self.storage,
-                pull_time=self.pull_time,
-                zone=self.zone,
-                cache=self.cache,
-                audit=self.audit,
-                creds=self.nuclia_creds,
-                nuclia_cluster_url=self.nuclia_cluster_url,
-                nuclia_public_url=self.nuclia_public_url,
-                target=self.nats_target,
-                group=self.nats_group,
-                stream=self.nats_stream,
-                onprem=self.onprem,
-                nats_creds=self.nats_auth,
-                nats_servers=self.nats_url,
-                local_subscriber=self.local_subscriber,
-                service_name=service_name,
-            )
-            self.pull_workers_task[partition] = asyncio.create_task(
-                self.pull_workers[partition].loop()
-            )
-            self.pull_workers_task[partition].add_done_callback(
-                self._handle_task_result
-            )
-
-    async def start(self, service_name: Optional[str] = None):
-        self.driver = await get_driver()
-        self.cache = await get_cache()
-        self.storage = await get_storage(service_name=SERVICE_NAME)
-
-        # Start consummer coroutine
-        await self.run(service_name)
-
-    async def stop(self):
-        for value in self.pull_workers.values():
-            await value.finalize()
-        for value in self.pull_workers_task.values():
-            value.cancel()
-
-    def _handle_task_result(self, task: asyncio.Task) -> None:
-        e = task.exception()
-        if e:
-            logger.exception("Consumer loop stopped by exception", exc_info=e)
+    return nats_connection_manager.finalize
```

## nucliadb/ingest/maindb/driver.py

```diff
@@ -18,32 +18,26 @@
 # along with this program. If not, see <http://www.gnu.org/licenses/>.
 #
 from __future__ import annotations
 
 from contextlib import asynccontextmanager
 from typing import AsyncGenerator, List, Optional
 
-TXNID = "/internal/worker/{worker}"
 DEFAULT_SCAN_LIMIT = 10
 DEFAULT_BATCH_SCAN_LIMIT = 100
 
 
 class Transaction:
     driver: Driver
     open: bool
 
     async def abort(self):
         raise NotImplementedError()
 
-    async def commit(
-        self,
-        worker: Optional[str] = None,
-        tid: Optional[int] = None,
-        resource: bool = True,
-    ):
+    async def commit(self):
         raise NotImplementedError()
 
     async def batch_get(self, keys: List[str]):
         raise NotImplementedError()
 
     async def get(self, key: str) -> Optional[bytes]:
         raise NotImplementedError()
@@ -59,24 +53,14 @@
     ) -> AsyncGenerator[str, None]:
         raise NotImplementedError()
 
 
 class Driver:
     initialized = False
 
-    async def last_seqid(self, worker: str) -> Optional[int]:
-        txn = await self.begin()
-        key = TXNID.format(worker=worker)
-        last_seq = await txn.get(key)
-        await txn.abort()
-        if last_seq is None:
-            return None
-        else:
-            return int(last_seq)
-
     async def initialize(self):
         raise NotImplementedError()
 
     async def finalize(self):
         raise NotImplementedError()
 
     async def begin(self) -> Transaction:
```

## nucliadb/ingest/maindb/local.py

```diff
@@ -20,19 +20,17 @@
 import glob
 import os
 from typing import Dict, List, Optional
 
 from nucliadb.ingest.maindb.driver import (
     DEFAULT_BATCH_SCAN_LIMIT,
     DEFAULT_SCAN_LIMIT,
-    TXNID,
     Driver,
     Transaction,
 )
-from nucliadb.ingest.maindb.exceptions import NoWorkerCommit
 
 try:
     import aiofiles
 
     FILES = True
 except ImportError:  # pragma: no cover
     FILES = False
@@ -86,42 +84,28 @@
         except FileNotFoundError:
             return None
         except IsADirectoryError:
             return None
         except NotADirectoryError:
             return None
 
-    async def commit(
-        self,
-        worker: Optional[str] = None,
-        tid: Optional[int] = None,
-        resource: bool = True,
-    ):
+    async def commit(self):
         if len(self.modified_keys) == 0 and len(self.deleted_keys) == 0:
             self.clean()
             return
 
         not_to_check = []
         count = 0
         for key, value in self.modified_keys.items():
             await self.save(key, value)
             count += 1
         for key in self.deleted_keys:
             await self.remove(key)
             not_to_check.append(count)
             count += 1
-        if resource:
-            if worker is None or tid is None:
-                raise NoWorkerCommit()
-            if tid != -1:
-                # If tid == -1 means we are injecting a resource via gRPC. We don't
-                # want to save the tid in this case, as it would break the next
-                # transactionability check.
-                key = TXNID.format(worker=worker)
-                await self.save(key, f"{tid}".encode())
         self.clean()
         self.open = False
 
     async def batch_get(self, keys: List[str]):
         results = []
         for key in keys:
             if key in self.deleted_keys:
```

## nucliadb/ingest/maindb/pg.py

```diff
@@ -20,16 +20,15 @@
 from __future__ import annotations
 
 import asyncio
 from typing import Any, AsyncGenerator, List, Optional
 
 import asyncpg
 
-from nucliadb.ingest.maindb.driver import DEFAULT_SCAN_LIMIT, TXNID, Driver, Transaction
-from nucliadb.ingest.maindb.exceptions import NoWorkerCommit
+from nucliadb.ingest.maindb.driver import DEFAULT_SCAN_LIMIT, Driver, Transaction
 
 CREATE_TABLE = """
 CREATE TABLE IF NOT EXISTS resources (
     key TEXT PRIMARY KEY,
     value BYTEA
 );
 """
@@ -102,31 +101,17 @@
             if self.open:
                 try:
                     await self.txn.rollback()
                 finally:
                     self.open = False
                     await self.connection.close()
 
-    async def commit(
-        self,
-        worker: Optional[str] = None,
-        tid: Optional[int] = None,
-        resource: bool = True,
-    ):
+    async def commit(self):
         async with self._lock:
             try:
-                if resource:
-                    if worker is None or tid is None:
-                        raise NoWorkerCommit()
-                    if tid != -1:
-                        # If tid == -1 means we are injecting a resource via gRPC. We don't
-                        # want to save the tid in this case, as it would break the next
-                        # transactionability check.
-                        key = TXNID.format(worker=worker)
-                        await self.data_layer.set(key, str(tid).encode())
                 await self.txn.commit()
             except Exception:
                 await self.txn.rollback()
                 raise
             finally:
                 self.open = False
                 await self.connection.close()
```

## nucliadb/ingest/maindb/redis.py

```diff
@@ -18,19 +18,17 @@
 # along with this program. If not, see <http://www.gnu.org/licenses/>.
 #
 from typing import Any, Dict, List, Optional
 
 from nucliadb.ingest.maindb.driver import (
     DEFAULT_BATCH_SCAN_LIMIT,
     DEFAULT_SCAN_LIMIT,
-    TXNID,
     Driver,
     Transaction,
 )
-from nucliadb.ingest.maindb.exceptions import NoWorkerCommit
 
 try:
     from redis import asyncio as aioredis
 
     REDIS = True
 except ImportError:  # pragma: no cover
     REDIS = False
@@ -54,43 +52,29 @@
         self.visited_keys.clear()
         self.deleted_keys.clear()
 
     async def abort(self):
         self.clean()
         self.open = False
 
-    async def commit(
-        self,
-        worker: Optional[str] = None,
-        tid: Optional[int] = None,
-        resource: bool = True,
-    ):
+    async def commit(self):
         if len(self.modified_keys) == 0 and len(self.deleted_keys) == 0:
             self.clean()
             return
 
         not_to_check = []
         async with self.redis.pipeline(transaction=True) as pipe:
             count = 0
             for key, value in self.modified_keys.items():
                 pipe = pipe.set(key.encode(), value)
                 count += 1
             for key in self.deleted_keys:
                 pipe = pipe.delete(key.encode())
                 not_to_check.append(count)
                 count += 1
-            if resource:
-                if worker is None or tid is None:
-                    raise NoWorkerCommit()
-                if tid != -1:
-                    # If tid == -1 means we are injecting a resource via gRPC. We don't
-                    # want to save the tid in this case, as it would break the next
-                    # transactionability check.
-                    key = TXNID.format(worker=worker)
-                    pipe.set(key.encode(), tid)
             oks = await pipe.execute()
 
         for index, ok in enumerate(oks):
             # We do no check deleted if its already deleted
             if index not in not_to_check:
                 assert ok
         self.clean()
```

## nucliadb/ingest/maindb/tikv.py

```diff
@@ -20,19 +20,17 @@
 from __future__ import annotations
 
 from typing import Any, List, Optional
 
 from nucliadb.ingest.maindb.driver import (
     DEFAULT_BATCH_SCAN_LIMIT,
     DEFAULT_SCAN_LIMIT,
-    TXNID,
     Driver,
     Transaction,
 )
-from nucliadb.ingest.maindb.exceptions import NoWorkerCommit
 from nucliadb_telemetry import metrics
 
 try:
     from tikv_client.asynchronous import TransactionClient  # type: ignore
 
     TiKV = True
 except ImportError:  # pragma: no cover
@@ -53,31 +51,15 @@
         if not self.open:
             return
 
         with tikv_observer({"type": "rollback"}):
             await self.txn.rollback()
         self.open = False
 
-    async def commit(
-        self,
-        worker: Optional[str] = None,
-        tid: Optional[int] = None,
-        resource: bool = True,
-    ):
-        if resource:
-            if worker is None or tid is None:
-                raise NoWorkerCommit()
-            if tid != -1:
-                # If tid == -1 means we are injecting a resource via gRPC. We don't
-                # want to save the tid in this case, as it would break the next
-                # transactionability check.
-                key = TXNID.format(worker=worker)
-                with tikv_observer({"type": "put"}):
-                    await self.txn.put(key.encode(), str(tid).encode())
-
+    async def commit(self):
         with tikv_observer({"type": "commit"}):
             await self.txn.commit()
         self.open = False
 
     async def batch_get(self, keys: List[str]):
         bytes_keys: List[bytes] = [x.encode() for x in keys]
         with tikv_observer({"type": "batch_get"}):
```

## nucliadb/ingest/orm/knowledgebox.py

```diff
@@ -145,15 +145,15 @@
         # Delete main anchor
         subtxn = await txn.driver.begin()
         key_match = KB_SLUGS.format(slug=slug)
         await subtxn.delete(key_match)
 
         when = datetime.now().isoformat()
         await subtxn.set(KB_TO_DELETE.format(kbid=kbid), when.encode())
-        await subtxn.commit(resource=False)
+        await subtxn.commit()
 
         audit_util = get_audit()
         if audit_util is not None:
             await audit_util.delete_kb(kbid)
         return kbid
 
     @classmethod
@@ -409,15 +409,15 @@
                         )
                     except AioRpcError as exc:
                         if exc.code() == StatusCode.NOT_FOUND:
                             continue
                         await txn.abort()
                         raise ShardNotFound(f"{exc.details()} @ {node.address}")
 
-        await txn.commit(resource=False)
+        await txn.commit()
         await cls.delete_all_kb_keys(driver, kbid)
 
     @classmethod
     async def delete_all_kb_keys(
         cls, driver: Driver, kbid: str, chunk_size: int = 1_000
     ):
         prefix = KB_KEYS.format(kbid=kbid)
@@ -431,15 +431,15 @@
 
             # We commit deletions in chunks because otherwise
             # tikv complains if there is too much data to commit
             for chunk_of_keys in chunker(all_keys, chunk_size):
                 txn = await driver.begin()
                 for key in chunk_of_keys:
                     await txn.delete(key)
-                await txn.commit(resource=False)
+                await txn.commit()
 
     async def get_resource_shard(self, shard_id: str, node_klass) -> Optional[Shard]:
         pb = await self.get_shards_object()
         for shard in pb.shards:
             if shard.shard == shard_id:
                 return node_klass.create_shard_klass(shard_id, shard)
         return None
```

## nucliadb/ingest/service/__init__.py

```diff
@@ -26,24 +26,30 @@
 from nucliadb.ingest import logger
 from nucliadb.ingest.orm import NODES
 from nucliadb.ingest.service.writer import WriterServicer
 from nucliadb.ingest.settings import DriverConfig, settings
 from nucliadb_protos import writer_pb2_grpc
 from nucliadb_telemetry.utils import setup_telemetry
 from nucliadb_utils.grpc import get_traced_grpc_server
+from nucliadb_utils.utilities import get_nats_manager
 
 
 async def health_check(health_servicer):
     while True:
+        nats_manager = get_nats_manager()
         if len(NODES) == 0 and settings.driver != DriverConfig.LOCAL:
             await health_servicer.set("", health_pb2.HealthCheckResponse.NOT_SERVING)
+        elif nats_manager is not None and not nats_manager.healthy():
+            # validate nats manager health
+            await health_servicer.set("", health_pb2.HealthCheckResponse.NOT_SERVING)
         else:
             await health_servicer.set("", health_pb2.HealthCheckResponse.SERVING)
+
         try:
-            await asyncio.sleep(1)
+            await asyncio.sleep(2)
         except (
             asyncio.CancelledError,
             asyncio.TimeoutError,
             KeyboardInterrupt,
         ):
             return
```

## nucliadb/ingest/service/writer.py

```diff
@@ -95,15 +95,15 @@
     EntitiesGroupNotFound,
     KnowledgeBoxConflict,
     KnowledgeBoxNotFound,
 )
 from nucliadb.ingest.orm.knowledgebox import KnowledgeBox as KnowledgeBoxORM
 from nucliadb.ingest.orm.knowledgebox import KnowledgeBox as KnowledgeBoxObj
 from nucliadb.ingest.orm.node import Node
-from nucliadb.ingest.orm.processor import Processor
+from nucliadb.ingest.orm.processor import Processor, sequence_manager
 from nucliadb.ingest.orm.resource import Resource as ResourceORM
 from nucliadb.ingest.orm.shard import Shard
 from nucliadb.ingest.orm.utils import get_node_klass
 from nucliadb.ingest.settings import settings
 from nucliadb.ingest.utils import get_driver
 from nucliadb_protos import writer_pb2_grpc
 from nucliadb_telemetry import errors
@@ -125,18 +125,17 @@
 
     async def initialize(self):
         storage = await get_storage(service_name=SERVICE_NAME)
         audit = get_audit()
         driver = await get_driver()
         cache = await get_cache()
         self.proc = Processor(driver=driver, storage=storage, audit=audit, cache=cache)
-        await self.proc.initialize()
 
     async def finalize(self):
-        await self.proc.finalize()
+        ...
 
     async def GetKnowledgeBox(self, request: KnowledgeBoxID, context=None) -> KnowledgeBox:  # type: ignore
         response: KnowledgeBox = await self.proc.get_kb(
             slug=request.slug, uuid=request.uuid
         )
         return response
 
@@ -157,15 +156,15 @@
                 for replica_id, shard_cleaned in replicas_cleaned.items():
                     update_shards_with_updated_replica(
                         updated_shards, replica_id, shard_cleaned
                     )
 
             key = KB_SHARDS.format(kbid=request.uuid)
             await txn.set(key, updated_shards.SerializeToString())
-            await txn.commit(resource=False)
+            await txn.commit()
             return CleanedKnowledgeBoxResponse()
         except Exception as e:
             errors.capture_exception(e)
             logger.error("Error in ingest gRPC servicer", exc_info=True)
             await txn.abort()
             raise
 
@@ -193,15 +192,15 @@
         evw = ExtractedVectorsWrapper()
         evw.field.CopyFrom(request.field)
         evw.vectors.CopyFrom(request.vectors)
         logger.debug(f"Setting {len(request.vectors.vectors.vectors)} vectors")
 
         try:
             await field.set_vectors(evw)
-            await txn.commit(resource=False)
+            await txn.commit()
         except Exception as e:
             errors.capture_exception(e)
             logger.error("Error in ingest gRPC servicer", exc_info=True)
             await txn.abort()
 
         return response
 
@@ -288,15 +287,15 @@
     async def SetLabels(self, request: SetLabelsRequest, context=None) -> OpStatusWriter:  # type: ignore
         txn = await self.proc.driver.begin()
         kbobj = await self.proc.get_kb_obj(txn, request.kb)
         response = OpStatusWriter()
         if kbobj is not None:
             try:
                 await kbobj.set_labelset(request.id, request.labelset)
-                await txn.commit(resource=False)
+                await txn.commit()
                 response.status = OpStatusWriter.Status.OK
             except Exception as e:
                 errors.capture_exception(e)
                 logger.error("Error in ingest gRPC servicer", exc_info=True)
                 response.status = OpStatusWriter.Status.ERROR
                 await txn.abort()
         else:
@@ -307,15 +306,15 @@
     async def DelLabels(self, request: DelLabelsRequest, context=None) -> OpStatusWriter:  # type: ignore
         txn = await self.proc.driver.begin()
         kbobj = await self.proc.get_kb_obj(txn, request.kb)
         response = OpStatusWriter()
         if kbobj is not None:
             try:
                 await kbobj.del_labelset(request.id)
-                await txn.commit(resource=False)
+                await txn.commit()
                 response.status = OpStatusWriter.Status.OK
             except Exception as e:
                 errors.capture_exception(e)
                 logger.error("Error in ingest gRPC servicer", exc_info=True)
                 response.status = OpStatusWriter.Status.ERROR
                 await txn.abort()
         else:
@@ -376,29 +375,29 @@
     ) -> OpStatusWriter:
         txn = await self.proc.driver.begin()
         kbobj = await self.proc.get_kb_obj(txn, request.kb)
         response = OpStatusWriter()
         if kbobj is not None:
             await kbobj.del_vectorset(request.vectorset)
             response.status = OpStatusWriter.Status.OK
-        await txn.commit(resource=False)
+        await txn.commit()
         if kbobj is None:
             response.status = OpStatusWriter.Status.NOTFOUND
         return response
 
     async def SetVectorSet(  # type: ignore
         self, request: SetVectorSetRequest, context=None
     ) -> OpStatusWriter:
         txn = await self.proc.driver.begin()
         kbobj = await self.proc.get_kb_obj(txn, request.kb)
         response = OpStatusWriter()
         if kbobj is not None:
             await kbobj.set_vectorset(request.id, request.vectorset)
             response.status = OpStatusWriter.Status.OK
-        await txn.commit(resource=False)
+        await txn.commit()
         if kbobj is None:
             response.status = OpStatusWriter.Status.NOTFOUND
         return response
 
     async def NewEntitiesGroup(  # type: ignore
         self, request: NewEntitiesGroupRequest, context=None
     ) -> NewEntitiesGroupResponse:
@@ -414,15 +413,15 @@
                 await entities_manager.create_entities_group(
                     request.group, request.entities
                 )
             except AlreadyExists:
                 response.status = NewEntitiesGroupResponse.Status.ALREADY_EXISTS
                 return response
 
-            await txn.commit(resource=False)
+            await txn.commit()
             response.status = NewEntitiesGroupResponse.Status.OK
             return response
 
     async def GetEntities(  # type: ignore
         self, request: GetEntitiesRequest, context=None
     ) -> GetEntitiesResponse:
         response = GetEntitiesResponse()
@@ -517,15 +516,15 @@
                 )
             except Exception as e:
                 errors.capture_exception(e)
                 logger.error("Error in ingest gRPC servicer", exc_info=True)
                 response.status = OpStatusWriter.Status.ERROR
             else:
                 response.status = OpStatusWriter.Status.OK
-                await txn.commit(resource=False)
+                await txn.commit()
             return response
 
     async def UpdateEntitiesGroup(  # type: ignore
         self, request: UpdateEntitiesGroupRequest, context=None
     ) -> UpdateEntitiesGroupResponse:
         response = UpdateEntitiesGroupResponse()
         async with self.proc.driver.transaction() as txn:
@@ -547,15 +546,15 @@
                 await entities_manager.delete_entities(request.group, request.delete)  # type: ignore
             except EntitiesGroupNotFound:
                 response.status = (
                     UpdateEntitiesGroupResponse.Status.ENTITIES_GROUP_NOT_FOUND
                 )
                 return response
 
-            await txn.commit(resource=False)
+            await txn.commit()
             response.status = UpdateEntitiesGroupResponse.Status.OK
             return response
 
     async def DelEntities(self, request: DelEntitiesRequest, context=None) -> OpStatusWriter:  # type: ignore
         response = OpStatusWriter()
         async with self.proc.driver.transaction() as txn:
             kbobj = await self.proc.get_kb_obj(txn, request.kb)
@@ -567,15 +566,15 @@
             try:
                 await entities_manager.delete_entities_group(request.group)
             except Exception as e:
                 errors.capture_exception(e)
                 logger.error("Error in ingest gRPC servicer", exc_info=True)
                 response.status = OpStatusWriter.Status.ERROR
             else:
-                await txn.commit(resource=False)
+                await txn.commit()
                 response.status = OpStatusWriter.Status.OK
             return response
 
     async def GetSynonyms(  # type: ignore
         self, request: KnowledgeBoxID, context=None
     ) -> GetSynonymsResponse:
         kbid = request
@@ -605,15 +604,15 @@
         async with self.proc.driver.transaction() as txn:
             kbobj = await self.proc.get_kb_obj(txn, kbid)
             if kbobj is None:
                 response.status = OpStatusWriter.Status.NOTFOUND
                 return response
             try:
                 await kbobj.set_synonyms(request.synonyms)
-                await txn.commit(resource=False)
+                await txn.commit()
                 response.status = OpStatusWriter.Status.OK
                 return response
             except Exception as e:
                 errors.capture_exception(e)
                 logger.exception("Errors setting synonyms")
                 response.status = OpStatusWriter.Status.ERROR
                 return response
@@ -627,15 +626,15 @@
         async with self.proc.driver.transaction() as txn:
             kbobj = await self.proc.get_kb_obj(txn, kbid)
             if kbobj is None:
                 response.status = OpStatusWriter.Status.NOTFOUND
                 return response
             try:
                 await kbobj.delete_synonyms()
-                await txn.commit(resource=False)
+                await txn.commit()
                 response.status = OpStatusWriter.Status.OK
                 return response
             except Exception as e:
                 errors.capture_exception(e)
                 logger.exception("Errors deleting synonyms")
                 response.status = OpStatusWriter.Status.ERROR
                 return response
@@ -646,17 +645,17 @@
         logger.info("Status Call")
         response = WriterStatusResponse()
         txn = await self.proc.driver.begin()
         async for (kbid, slug) in KnowledgeBoxObj.get_kbs(txn, slug="", count=-1):
             response.knowledgeboxes.append(slug)
 
         for partition in settings.partitions:
-            msgid = await self.proc.driver.last_seqid(partition)
-            if msgid is not None:
-                response.msgid[partition] = msgid
+            seq_id = await sequence_manager.get_last_seqid(self.proc.driver, partition)
+            if seq_id is not None:
+                response.msgid[partition] = seq_id
 
         await txn.abort()
         return response
 
     async def ListMembers(  # type: ignore
         self, request: ListMembersRequest, context=None
     ) -> ListMembersResponse:
```

## nucliadb/ingest/tests/fixtures.py

```diff
@@ -30,29 +30,30 @@
 
 import nats
 import pytest
 from grpc import aio  # type: ignore
 from nucliadb_protos.writer_pb2 import BrokerMessage
 from redis import asyncio as aioredis
 
-from nucliadb.ingest.consumer.service import ConsumerService
+from nucliadb.ingest.consumer import service as consumer_service
 from nucliadb.ingest.maindb.driver import Driver
 from nucliadb.ingest.maindb.local import LocalDriver
 from nucliadb.ingest.maindb.redis import RedisDriver
 from nucliadb.ingest.maindb.tikv import TiKVDriver
 from nucliadb.ingest.orm.knowledgebox import KnowledgeBox
 from nucliadb.ingest.orm.node import Node
 from nucliadb.ingest.orm.processor import Processor
 from nucliadb.ingest.service.writer import WriterServicer
 from nucliadb.ingest.settings import DriverConfig, settings
 from nucliadb.ingest.tests.vectors import V1, V2, V3
 from nucliadb_models.cluster import MemberType
 from nucliadb_protos import resources_pb2 as rpb
 from nucliadb_protos import utils_pb2 as upb
 from nucliadb_protos import writer_pb2_grpc
+from nucliadb_utils import const
 from nucliadb_utils.audit.basic import BasicAuditStorage
 from nucliadb_utils.audit.stream import StreamAuditStorage
 from nucliadb_utils.cache.redis import RedisPubsub
 from nucliadb_utils.cache.settings import settings as cache_settings
 from nucliadb_utils.cache.utility import Cache
 from nucliadb_utils.indexing import IndexingUtility
 from nucliadb_utils.settings import indexing_settings, transaction_settings
@@ -60,97 +61,118 @@
 from nucliadb_utils.store import MAIN
 from nucliadb_utils.utilities import (
     Utility,
     clean_utility,
     clear_global_cache,
     get_utility,
     set_utility,
+    start_nats_manager,
+    start_transaction_utility,
+    stop_nats_manager,
+    stop_transaction_utility,
 )
 
 logger = logging.getLogger(__name__)
 
 
 @pytest.fixture(scope="function")
 async def processor(maindb_driver, gcs_storage, cache, audit):
     proc = Processor(maindb_driver, gcs_storage, audit, cache, partition="1")
-    await proc.initialize()
     yield proc
-    await proc.finalize()
 
 
 @pytest.fixture(scope="function")
 async def stream_processor(maindb_driver, gcs_storage, cache, stream_audit):
     proc = Processor(maindb_driver, gcs_storage, stream_audit, cache, partition="1")
-    await proc.initialize()
     yield proc
-    await proc.finalize()
 
 
 @pytest.fixture(scope="function")
 async def local_files():
     storage_settings.local_testing_files = f"{dirname(__file__)}"
 
 
 @dataclass
 class IngestFixture:
     servicer: WriterServicer
-    consumer: ConsumerService
     channel: aio.Channel
     host: str
     serv: aio.Server
 
 
 @pytest.fixture(scope="function")
-async def grpc_servicer(redis, transaction_utility, gcs_storage, fake_node):
+async def redis_config(redis):
     settings.driver_redis_url = f"redis://{redis[0]}:{redis[1]}"
     cache_settings.cache_pubsub_redis_url = f"redis://{redis[0]}:{redis[1]}"
     default_driver = settings.driver
     default_driver_pubsub = cache_settings.cache_pubsub_driver
 
     cache_settings.cache_pubsub_driver = "redis"
     settings.driver = "redis"
-    settings.pull_time = 0
 
     storage_settings.local_testing_files = f"{dirname(__file__)}"
     driver = aioredis.from_url(f"redis://{redis[0]}:{redis[1]}")
     await driver.flushall()
 
+    yield
+
+    settings.driver_redis_url = None
+    cache_settings.cache_pubsub_redis_url = None
+    settings.driver = default_driver
+    cache_settings.cache_pubsub_driver = default_driver_pubsub
+    await driver.flushall()
+    await driver.close(close_connection_pool=True)
+
+    pubsub = get_utility(Utility.PUBSUB)
+    if pubsub is not None:
+        await pubsub.finalize()
+    clear_global_cache()
+
+
+@pytest.fixture(scope="function")
+async def ingest_consumers(
+    redis_config, transaction_utility, gcs_storage, fake_node, nats_manager
+):
+    ingest_consumers_finalizer = await consumer_service.start_ingest_consumers()
+
+    yield
+
+    await ingest_consumers_finalizer()
+
+
+@pytest.fixture(scope="function")
+async def ingest_processed_consumer(
+    redis_config, transaction_utility, gcs_storage, fake_node, nats_manager
+):
+    ingest_consumer_finalizer = await consumer_service.start_ingest_processed_consumer()
+
+    yield
+
+    await ingest_consumer_finalizer()
+
+
+@pytest.fixture(scope="function")
+async def grpc_servicer(redis_config, ingest_consumers, ingest_processed_consumer):
     servicer = WriterServicer()
     await servicer.initialize()
 
-    consumer = ConsumerService()
-    await consumer.start()
     server = aio.server()
     port = server.add_insecure_port("[::]:0")
     writer_pb2_grpc.add_WriterServicer_to_server(servicer, server)
     await server.start()
     _channel = aio.insecure_channel(f"127.0.0.1:{port}")
     yield IngestFixture(
         channel=_channel,
         serv=server,
         servicer=servicer,
         host=f"127.0.0.1:{port}",
-        consumer=consumer,
     )
     await servicer.finalize()
     await _channel.close()
     await server.stop(None)
-    await consumer.stop()
-
-    settings.driver_redis_url = None
-    cache_settings.cache_pubsub_redis_url = None
-    settings.driver = default_driver
-    cache_settings.cache_pubsub_driver = default_driver_pubsub
-    await driver.flushall()
-    await driver.close(close_connection_pool=True)
-
-    pubsub = get_utility(Utility.PUBSUB)
-    if pubsub is not None:
-        await pubsub.finalize()
-    clear_global_cache()
 
 
 @pytest.fixture(scope="function")
 async def local_driver() -> AsyncIterator[Driver]:
     path = mkdtemp()
     settings.driver = DriverConfig.LOCAL
     settings.driver_local_url = path
@@ -176,15 +198,15 @@
     await driver.initialize()
 
     yield driver
 
     txn = await driver.begin()
     async for key in txn.keys(""):
         await txn.delete(key)
-    await txn.commit(resource=False)
+    await txn.commit()
     await driver.finalize()
     settings.driver_tikv_url = []
     MAIN.pop("driver", None)
 
 
 @pytest.fixture(scope="function")
 async def redis_driver(redis: List[str]) -> AsyncIterator[RedisDriver]:
@@ -232,15 +254,15 @@
     yield che
     await che.finalize()
     await pubsub.finalize()
     set_utility(Utility.PUBSUB, None)
 
 
 @pytest.fixture(scope="function")
-async def fake_node(indexing_utility_ingest):
+async def fake_node(_natsd_reset, indexing_utility_ingest):
     uuid1 = str(uuid.uuid4())
     uuid2 = str(uuid.uuid4())
     await Node.set(
         uuid1,
         address="nohost:9999",
         type=MemberType.IO,
         shard_count=0,
@@ -252,39 +274,40 @@
         type=MemberType.IO,
         shard_count=0,
         dummy=True,
     )
     indexing_utility = IndexingUtility(
         nats_creds=indexing_settings.index_jetstream_auth,
         nats_servers=indexing_settings.index_jetstream_servers,
-        nats_target=indexing_settings.index_jetstream_target,
         dummy=True,
     )
 
     old_index_local = indexing_settings.index_local
     indexing_settings.index_local = False
     set_utility(Utility.INDEXING, indexing_utility)
     yield
     clean_utility(Utility.INDEXING)
     indexing_settings.index_local = old_index_local
-    await Node.destroy(uuid1)
-    await Node.destroy(uuid2)
+    if await Node.get(uuid1):
+        await Node.destroy(uuid1)
+    if await Node.get(uuid2):
+        await Node.destroy(uuid2)
 
 
 @pytest.fixture(scope="function")
 async def knowledgebox_ingest(gcs_storage, redis_driver: RedisDriver):
     kbid = str(uuid.uuid4())
     kbslug = str(uuid.uuid4())
     txn = await redis_driver.begin()
     await KnowledgeBox.create(txn, kbslug, kbid)
-    await txn.commit(resource=False)
+    await txn.commit()
     yield kbid
     txn = await redis_driver.begin()
     await KnowledgeBox.delete_kb(txn, kbslug, kbid)
-    await txn.commit(resource=False)
+    await txn.commit()
 
 
 @pytest.fixture(scope="function")
 async def audit():
     return BasicAuditStorage()
 
 
@@ -314,49 +337,69 @@
 
     try:
         await js.delete_stream(name="node")
     except nats.js.errors.NotFoundError:
         pass
 
     await js.add_stream(name="node", subjects=["node.*"])
-    indexing_settings.index_jetstream_target = "node.{node}"
     indexing_settings.index_jetstream_servers = [natsd]
-    indexing_settings.index_jetstream_stream = "node"
-    indexing_settings.index_jetstream_group = "node-{node}"
     await nc.drain()
     await nc.close()
 
     yield
 
 
 @pytest.fixture(scope="function")
-async def transaction_utility(natsd, event_loop):
+async def _natsd_reset(natsd, event_loop):
     nc = await nats.connect(servers=[natsd])
     js = nc.jetstream()
     try:
-        await js.delete_consumer("nucliadb", "nucliadb-1")
+        await js.delete_consumer(
+            const.Streams.INGEST.name,
+            const.Streams.INGEST.group.format(partition="1"),
+        )
+    except nats.js.errors.NotFoundError:
+        pass
+    try:
+        await js.delete_consumer(
+            const.Streams.INGEST_PROCESSED.name,
+            const.Streams.INGEST_PROCESSED.group,
+        )
     except nats.js.errors.NotFoundError:
         pass
 
     try:
         await js.delete_stream(name="nucliadb")
     except nats.js.errors.NotFoundError:
         pass
 
-    await js.add_stream(name="nucliadb", subjects=["nucliadb.1"])
-    transaction_settings.transaction_jetstream_target = "nucliadb.1"
-    transaction_settings.transaction_jetstream_servers = [natsd]
-    transaction_settings.transaction_jetstream_stream = "nucliadb"
-    transaction_settings.transaction_jetstream_group = "nucliadb-1"
+    await js.add_stream(
+        name="nucliadb",
+        subjects=[const.Streams.INGEST.subject.format(partition=">")],
+    )
     await nc.drain()
     await nc.close()
-
     yield
 
 
+@pytest.fixture(scope="function")
+async def nats_manager(natsd):
+    ncm = await start_nats_manager("service_name", [natsd], None)
+    yield ncm
+    await stop_nats_manager()
+
+
+@pytest.fixture(scope="function")
+async def transaction_utility(natsd):
+    transaction_settings.transaction_jetstream_servers = [natsd]
+    util = await start_transaction_utility()
+    yield util
+    await stop_transaction_utility()
+
+
 THUMBNAIL = rpb.CloudFile(
     uri="thumbnail.png",
     source=rpb.CloudFile.Source.LOCAL,
     bucket_name="/integration/orm/assets",
     size=getsize(f"{dirname(__file__)}/integration/orm/assets/thumbnail.png"),
     content_type="image/png",
     filename="thumbnail.png",
@@ -754,15 +797,15 @@
     field_obj = await test_resource.get_field("datetime1", type=rpb.FieldType.DATETIME)
     user_vectors = rpb.UserVectorsWrapper()
     user_vectors.vectors.vectors["vectorset1"].vectors["vector1"].vector.extend(
         (0.1, 0.2, 0.3)
     )
     await field_obj.set_user_vectors(user_vectors)
 
-    await txn.commit(resource=False)
+    await txn.commit()
     return test_resource
 
 
 @pytest.fixture(scope="function")
 def metrics_registry():
     import prometheus_client.registry  # type: ignore
```

## nucliadb/one/lifecycle.py

```diff
@@ -15,30 +15,35 @@
 # GNU Affero General Public License for more details.
 #
 # You should have received a copy of the GNU Affero General Public License
 # along with this program. If not, see <http://www.gnu.org/licenses/>.
 #
 import asyncio
 
-from nucliadb.ingest.app import initialize_consumer_and_grpc as initialize_ingest
+from nucliadb.ingest.app import initialize_grpc as initialize_ingest_grpc
+from nucliadb.ingest.app import initialize_pull_workers
+from nucliadb.ingest.settings import settings as ingest_settings
 from nucliadb.reader.lifecycle import finalize as finalize_reader
 from nucliadb.reader.lifecycle import initialize as initialize_reader
 from nucliadb.search.lifecycle import finalize as finalize_search
 from nucliadb.search.lifecycle import initialize as initialize_search
 from nucliadb.train.lifecycle import finalize as finalize_train
 from nucliadb.train.lifecycle import initialize as initialize_train
 from nucliadb.writer.lifecycle import finalize as finalize_writer
 from nucliadb.writer.lifecycle import initialize as initialize_writer
 from nucliadb_utils.utilities import finalize_utilities
 
 SYNC_FINALIZERS = []
 
 
 async def initialize():
-    finalizers = await initialize_ingest()
+    if ingest_settings.disable_pull_worker:
+        finalizers = await initialize_ingest_grpc()
+    else:
+        finalizers = await initialize_pull_workers()
     SYNC_FINALIZERS.extend(finalizers)
     await initialize_writer()
     await initialize_reader()
     await initialize_search()
     await initialize_train()
```

## nucliadb/one/tests/fixtures.py

```diff
@@ -34,39 +34,41 @@
 from nucliadb_models.resource import NucliaDBRoles
 from nucliadb_utils.utilities import clear_global_cache
 
 
 @pytest.fixture(scope="function")
 async def nucliadb_api(
     redis,
+    # order matters here because of config diffs between redis/nats pubsub
+    ingest_consumers,
     transaction_utility,
     indexing_utility_registered,
     test_settings_search: None,
     event_loop,
 ):  # type: ignore
     from nucliadb.ingest.orm import NODES
     from nucliadb.one.app import application
 
-    async def handler(req, exc):  # type: ignore
-        raise exc
-
     driver = aioredis.from_url(f"redis://{redis[0]}:{redis[1]}")
     await driver.flushall()
 
     # Little hack to raise exeptions from VersionedFastApi
+    async def handler(req, exc):  # type: ignore
+        raise exc
+
     for route in application.routes:
         if isinstance(route, Mount) and not isinstance(route.app, StaticFiles):
             route.app.middleware_stack.handler = handler  # type: ignore
 
     await application.router.startup()
 
     await asyncio.sleep(1)
     while len(NODES) < 2:
         print("awaiting cluster nodes - one fixtures.py")
-        await asyncio.sleep(4)
+        await asyncio.sleep(1)
 
     def make_client_fixture(
         roles: Optional[List[Enum]] = None,
         user: str = "",
         version: str = "1",
         root: bool = False,
     ) -> AsyncClient:
```

## nucliadb/search/tests/fixtures.py

```diff
@@ -31,25 +31,18 @@
 
 from nucliadb.ingest.cache import clear_ingest_cache
 from nucliadb.ingest.orm import NODES
 from nucliadb.ingest.orm.node import Node
 from nucliadb.ingest.tests.fixtures import broker_resource
 from nucliadb.ingest.utils import get_driver
 from nucliadb.search import API_PREFIX
+from nucliadb_utils.tests import free_port
 from nucliadb_utils.utilities import clear_global_cache
 
 
-def free_port() -> int:
-    import socket
-
-    sock = socket.socket()
-    sock.bind(("", 0))
-    return sock.getsockname()[1]
-
-
 @pytest.fixture(scope="function")
 def test_settings_search(gcs, redis, node, maindb_driver):  # type: ignore
     from nucliadb.ingest.settings import settings as ingest_settings
     from nucliadb_utils.cache.settings import settings as cache_settings
     from nucliadb_utils.settings import (
         FileBackendConfig,
         nuclia_settings,
@@ -69,15 +62,15 @@
     url = f"redis://{redis[0]}:{redis[1]}"
     cache_settings.cache_pubsub_driver = "redis"
     cache_settings.cache_pubsub_channel = "pubsub-nuclia"
     cache_settings.cache_pubsub_redis_url = url
 
     running_settings.debug = False
 
-    ingest_settings.pull_time = 0
+    ingest_settings.disable_pull_worker = True
 
     ingest_settings.nuclia_partitions = 1
 
     nuclia_settings.dummy_processing = True
     nuclia_settings.dummy_predict = True
 
     ingest_settings.grpc_port = free_port()
@@ -85,21 +78,15 @@
     nucliadb_settings.nucliadb_ingest = f"localhost:{ingest_settings.grpc_port}"
 
     extended_storage_settings.local_testing_files = f"{dirname(__file__)}"
 
 
 @pytest.mark.asyncio
 @pytest.fixture(scope="function")
-async def search_api(
-    redis,
-    transaction_utility,
-    indexing_utility_registered,
-    test_settings_search,
-    event_loop,
-):  # type: ignore
+async def search_api(test_settings_search, transaction_utility, redis):  # type: ignore
     from nucliadb.ingest.orm import NODES
     from nucliadb.search.app import application
 
     async def handler(req, exc):  # type: ignore
         raise exc
 
     driver = aioredis.from_url(f"redis://{redis[0]}:{redis[1]}")
```

## nucliadb/search/tests/node.py

```diff
@@ -28,14 +28,15 @@
 from grpc_health.v1.health_pb2 import HealthCheckRequest  # type: ignore
 from nucliadb_protos.nodewriter_pb2 import EmptyQuery, ShardId
 from nucliadb_protos.nodewriter_pb2_grpc import NodeWriterStub
 from pytest_docker_fixtures import images  # type: ignore
 from pytest_docker_fixtures.containers._base import BaseImage  # type: ignore
 
 from nucliadb.ingest.settings import settings
+from nucliadb_utils.tests import free_port
 
 logger = logging.getLogger(__name__)
 
 images.settings["nucliadb_node_reader"] = {
     "image": "eu.gcr.io/stashify-218417/node",
     "version": "main",
     "env": {
@@ -82,24 +83,23 @@
     },
 }
 
 images.settings["nucliadb_node_sidecar"] = {
     "image": "eu.gcr.io/stashify-218417/node_sidecar",
     "version": "main",
     "env": {
-        "INDEX_JETSTREAM_TARGET": "node.{node}",
-        "INDEX_JETSTREAM_GROUP": "node-{node}",
-        "INDEX_JETSTREAM_STREAM": "node",
         "INDEX_JETSTREAM_SERVERS": "[]",
         "CACHE_PUBSUB_NATS_URL": "",
         "HOST_KEY_PATH": "/data/node.key",
         "DATA_PATH": "/data",
         "SIDECAR_LISTEN_ADDRESS": "0.0.0.0:4447",
         "READER_LISTEN_ADDRESS": "0.0.0.0:4445",
         "WRITER_LISTEN_ADDRESS": "0.0.0.0:4446",
+        "PYTHONUNBUFFERED": "1",
+        "LOG_LEVEL": "DEBUG",
     },
     "options": {
         "command": [
             "node_sidecar",
         ],
         "ports": {"4447": None},
     },
@@ -121,22 +121,14 @@
         "command": [
             "/nucliadb_cluster/cluster_manager",
         ],
     },
 }
 
 
-def free_port() -> int:
-    import socket
-
-    sock = socket.socket()
-    sock.bind(("", 0))
-    return sock.getsockname()[1]
-
-
 def get_chitchat_port(container_obj, port):
     network = container_obj.attrs["NetworkSettings"]
     service_port = "{0}/udp".format(port)
     for netport in network["Ports"].keys():
         if netport == "6543/tcp":
             continue
 
@@ -207,22 +199,14 @@
 
     def get_image_options(self):
         options = super(nucliadbChitchatNode, self).get_image_options()
         return options
 
     def check(self):
         return True
-        # channel = insecure_channel(f"{self.host}:{self.get_port()}")
-        # stub = health_pb2_grpc.HealthStub(channel)
-        # pb = HealthCheckRequest(service="Chitchat")
-        # try:
-        #    result = stub.Check(pb)
-        #    return result.status == 1
-        # except:  # noqa
-        #    return False
 
 
 class nucliadbNodeSidecar(BaseImage):
     name = "nucliadb_node_sidecar"
     port = 4447
 
     def run(self, volume):
```

## nucliadb/tests/fixtures.py

```diff
@@ -30,33 +30,24 @@
 from nucliadb_protos.writer_pb2_grpc import WriterStub
 
 from nucliadb.config import config_nucliadb
 from nucliadb.run import run_async_nucliadb
 from nucliadb.settings import Settings
 from nucliadb.tests.utils import inject_message
 from nucliadb.writer import API_PREFIX
+from nucliadb_utils.tests import free_port
 from nucliadb_utils.utilities import (
     Utility,
     clean_utility,
     clear_global_cache,
     get_utility,
     set_utility,
 )
 
 
-def free_port() -> int:
-    import socket
-
-    sock = socket.socket()
-    sock.bind(("", 0))
-    port = sock.getsockname()[1]
-    sock.close()
-    return port
-
-
 @pytest.fixture(scope="function")
 async def dummy_processing():
     from nucliadb_utils.settings import nuclia_settings
 
     nuclia_settings.dummy_processing = True
```

## nucliadb/train/uploader.py

```diff
@@ -47,18 +47,17 @@
 class UploadServicer:
     async def initialize(self):
         storage = await get_storage(service_name=SERVICE_NAME)
         audit = get_audit()
         driver = await get_driver()
         cache = await get_cache()
         self.proc = Processor(driver=driver, storage=storage, audit=audit, cache=cache)
-        await self.proc.initialize()
 
     async def finalize(self):
-        await self.proc.finalize()
+        ...
 
     async def GetSentences(self, request: GetSentencesRequest, context=None):
         async for sentence in self.proc.kb_sentences(request):
             yield sentence
 
     async def GetParagraphs(self, request: GetParagraphsRequest, context=None):
         async for paragraph in self.proc.kb_paragraphs(request):
```

## nucliadb/train/tests/fixtures.py

```diff
@@ -38,14 +38,15 @@
 
 from nucliadb.ingest.orm.entities import EntitiesManager
 from nucliadb.ingest.orm.knowledgebox import KnowledgeBox
 from nucliadb.ingest.orm.processor import Processor
 from nucliadb.ingest.orm.resource import KB_RESOURCE_SLUG_BASE
 from nucliadb.settings import Settings
 from nucliadb.train.utils import start_nodes_manager, stop_nodes_manager
+from nucliadb_utils.tests import free_port
 from nucliadb_utils.utilities import (
     Utility,
     clear_global_cache,
     get_storage,
     set_utility,
 )
 
@@ -224,27 +225,19 @@
     labelset = LabelSet()
     labelset.title = "ls1"
     label = Label()
     label_title = "label1"
     label.title = label_title
     labelset.labels.append(label)
     await kb.set_labelset(label_title, labelset)
-    await txn.commit(resource=False)
+    await txn.commit()
 
     yield knowledgebox_ingest
 
 
-def free_port() -> int:
-    import socket
-
-    sock = socket.socket()
-    sock.bind(("", 0))
-    return sock.getsockname()[1]
-
-
 @pytest.fixture(scope="function")
 def test_settings_train(cache, gcs, fake_node, maindb_driver):  # type: ignore
     from nucliadb.train.settings import settings
     from nucliadb_utils.settings import (
         FileBackendConfig,
         running_settings,
         storage_settings,
```

## nucliadb/writer/lifecycle.py

```diff
@@ -21,21 +21,21 @@
 from nucliadb.ingest.utils import start_ingest, stop_ingest
 from nucliadb.writer import SERVICE_NAME
 from nucliadb.writer.tus import finalize as storage_finalize
 from nucliadb.writer.tus import initialize as storage_initialize
 from nucliadb.writer.utilities import get_processing
 from nucliadb_telemetry.utils import clean_telemetry, setup_telemetry
 from nucliadb_utils.partition import PartitionUtility
-from nucliadb_utils.settings import nuclia_settings, transaction_settings
-from nucliadb_utils.transaction import LocalTransactionUtility, TransactionUtility
+from nucliadb_utils.settings import nuclia_settings
 from nucliadb_utils.utilities import (
     Utility,
     finalize_utilities,
-    get_transaction_utility,
     set_utility,
+    start_transaction_utility,
+    stop_transaction_utility,
 )
 
 
 async def initialize():
     await setup_telemetry(SERVICE_NAME)
 
     await start_ingest(SERVICE_NAME)
@@ -45,31 +45,20 @@
     set_utility(
         Utility.PARTITION,
         PartitionUtility(
             partitions=nuclia_settings.nuclia_partitions,
             seed=nuclia_settings.nuclia_hash_seed,
         ),
     )
-    if transaction_settings.transaction_local:
-        transaction_utility = LocalTransactionUtility()
-    else:
-        transaction_utility = TransactionUtility(
-            nats_creds=transaction_settings.transaction_jetstream_auth,
-            nats_servers=transaction_settings.transaction_jetstream_servers,
-            nats_target=transaction_settings.transaction_jetstream_target,
-        )
-        await transaction_utility.initialize(SERVICE_NAME)
-    set_utility(Utility.TRANSACTION, transaction_utility)
+    await start_transaction_utility(SERVICE_NAME)
     await storage_initialize()
 
 
 async def finalize():
-    transaction = get_transaction_utility()
-    if transaction is not None:
-        await transaction.finalize()
+    await stop_transaction_utility()
 
     await stop_ingest()
     processing = get_processing()
     if processing is not None:
         await processing.finalize()
 
     await storage_finalize()
```

## nucliadb/writer/tests/fixtures.py

 * *Ordering differences only*

```diff
@@ -37,19 +37,19 @@
     storage_settings,
 )
 
 
 @pytest.fixture(scope="function")
 async def writer_api(
     redis,
+    grpc_servicer: IngestFixture,
     gcs_storage_writer,
     transaction_utility,
     processing_utility,
     tus_manager,
-    grpc_servicer: IngestFixture,
     event_loop,
 ) -> AsyncIterator[Callable[[List[Enum], str, str], AsyncClient]]:
     nucliadb_settings.nucliadb_ingest = grpc_servicer.host
     from nucliadb.writer.app import application
 
     def make_client_fixture(
         roles: Optional[List[Enum]] = None,
```

## nucliadb/writer/tests/test_files.py

```diff
@@ -27,14 +27,15 @@
 from nucliadb_protos.resources_pb2 import FieldType
 from nucliadb_protos.writer_pb2 import BrokerMessage, ResourceFieldId
 
 from nucliadb.writer.api.v1.router import KB_PREFIX, RSLUG_PREFIX
 from nucliadb.writer.api.v1.upload import maybe_b64decode
 from nucliadb.writer.tus import TUSUPLOAD, UPLOAD
 from nucliadb_models.resource import NucliaDBRoles
+from nucliadb_utils import const
 from nucliadb_utils.utilities import get_ingest, get_storage, get_transaction_utility
 
 ASSETS_PATH = os.path.dirname(__file__) + "/assets"
 
 
 @pytest.mark.asyncio
 async def test_knowledgebox_file_tus_options(
@@ -117,15 +118,17 @@
                 offset += len(data)
                 data = f.read(10000)
 
         assert resp.headers["Tus-Upload-Finished"] == "1"
 
     transaction = get_transaction_utility()
 
-    sub = await transaction.js.pull_subscribe("nucliadb.1", "auto")
+    sub = await transaction.js.pull_subscribe(
+        const.Streams.INGEST.subject.format(partition="1"), "auto"
+    )
     msgs = await sub.fetch(1)
 
     writer = BrokerMessage()
     writer.ParseFromString(msgs[0].data)
     await msgs[0].ack()
 
     path = resp.headers["ndb-field"]
@@ -175,15 +178,17 @@
                 },
             )
             assert resp.status_code == 201
 
     transaction = get_transaction_utility()
 
     assert transaction.js is not None
-    sub = await transaction.js.pull_subscribe("nucliadb.1", "auto")
+    sub = await transaction.js.pull_subscribe(
+        const.Streams.INGEST.subject.format(partition="1"), "auto"
+    )
     msgs = await sub.fetch(1)
     writer = BrokerMessage()
     writer.ParseFromString(msgs[0].data)
     await msgs[0].ack()
 
     body = resp.json()
     field = body["field_id"]
@@ -231,15 +236,17 @@
                 },
             )
             assert resp.status_code == 201
 
     transaction = get_transaction_utility()
 
     assert transaction.js is not None
-    sub = await transaction.js.pull_subscribe("nucliadb.1", "auto")
+    sub = await transaction.js.pull_subscribe(
+        const.Streams.INGEST.subject.format(partition="1"), "auto"
+    )
     msgs = await sub.fetch(1)
     writer = BrokerMessage()
     writer.ParseFromString(msgs[0].data)
     await msgs[0].ack()
 
     body = resp.json()
     field = body["field_id"]
@@ -318,15 +325,17 @@
                 offset += len(data)
                 data = f.read(10000)
 
         assert resp.headers["Tus-Upload-Finished"] == "1"
 
     transaction = get_transaction_utility()
 
-    sub = await transaction.js.pull_subscribe("nucliadb.1", "auto")
+    sub = await transaction.js.pull_subscribe(
+        const.Streams.INGEST.subject.format(partition="1"), "auto"
+    )
     msgs = await sub.fetch(2)
 
     writer = BrokerMessage()
     writer.ParseFromString(msgs[1].data)
     await msgs[1].ack()
 
     path = resp.headers["ndb-field"]
@@ -366,15 +375,17 @@
                     "content-type": "image/jpg",
                 },
             )
             assert resp.status_code == 201
 
     transaction = get_transaction_utility()
 
-    sub = await transaction.js.pull_subscribe("nucliadb.1", "auto")
+    sub = await transaction.js.pull_subscribe(
+        const.Streams.INGEST.subject.format(partition="1"), "auto"
+    )
     msgs = await sub.fetch(2)
     writer = BrokerMessage()
     writer.ParseFromString(msgs[1].data)
     await msgs[1].ack()
 
     body = resp.json()
     field = body["field_id"]
@@ -484,15 +495,17 @@
                 offset += len(data)
                 data = f.read(10000)
 
         assert resp.headers["Tus-Upload-Finished"] == "1"
 
     transaction = get_transaction_utility()
 
-    sub = await transaction.js.pull_subscribe("nucliadb.1", "auto")
+    sub = await transaction.js.pull_subscribe(
+        const.Streams.INGEST.subject.format(partition="1"), "auto"
+    )
     msgs = await sub.fetch(2)
 
     writer = BrokerMessage()
     writer.ParseFromString(msgs[1].data)
     await msgs[1].ack()
 
     path = resp.headers["ndb-field"]
@@ -602,15 +615,17 @@
                     "X-MD5": "7af0916dba8b70e29d99e72941923529",
                 },
             )
             assert resp.status_code == 201
 
     transaction = get_transaction_utility()
 
-    sub = await transaction.js.pull_subscribe("nucliadb.1", "auto")
+    sub = await transaction.js.pull_subscribe(
+        const.Streams.INGEST.subject.format(partition="1"), "auto"
+    )
     msgs = await sub.fetch(2)
 
     writer = BrokerMessage()
     writer.ParseFromString(msgs[-1].data)
     await msgs[-1].ack()
 
     body = resp.json()
```

## Comparing `nucliadb/ingest/maindb/exceptions.py` & `nucliadb/ingest/tests/integration/consumer/__init__.py`

 * *Files 6% similar despite different names*

```diff
@@ -12,10 +12,7 @@
 # This program is distributed in the hope that it will be useful,
 # but WITHOUT ANY WARRANTY; without even the implied warranty of
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
 # GNU Affero General Public License for more details.
 #
 # You should have received a copy of the GNU Affero General Public License
 # along with this program. If not, see <http://www.gnu.org/licenses/>.
-#
-class NoWorkerCommit(Exception):
-    pass
```

## Comparing `nucliadb/ingest/orm/processor.py` & `nucliadb/ingest/orm/processor/__init__.py`

 * *Files 4% similar despite different names*

```diff
@@ -37,14 +37,15 @@
 from nucliadb.ingest.orm.exceptions import (
     DeadletteredError,
     KnowledgeBoxConflict,
     KnowledgeBoxNotFound,
     SequenceOrderViolation,
 )
 from nucliadb.ingest.orm.knowledgebox import KnowledgeBox
+from nucliadb.ingest.orm.processor import sequence_manager
 from nucliadb.ingest.orm.resource import Resource
 from nucliadb.ingest.orm.shard import Shard, ShardCounter
 from nucliadb.ingest.orm.utils import get_node_klass, set_basic
 from nucliadb.ingest.settings import settings
 from nucliadb_telemetry import errors
 from nucliadb_utils import const
 from nucliadb_utils.audit.audit import AuditStorage
@@ -66,14 +67,26 @@
 AUDIT_TYPES: Dict[TxnAction, int] = {
     TxnAction.RESOURCE_CREATED: AuditRequest.AuditType.NEW,
     TxnAction.RESOURCE_MODIFIED: AuditRequest.AuditType.MODIFIED,
 }
 
 
 class Processor:
+    """
+    This class is responsible for processing messages from the broker
+    and attempts to manage sequencing correctly with a txn id implementation.
+
+    The "txn" in this implementation is oriented around the sequence id of
+    messages coming through the message broker.
+
+    Not all writes are going to have a transaction id. For example, writes
+    coming from processor can be coming through a different channel
+    and can not use the txn id
+    """
+
     messages: Dict[str, List[BrokerMessage]]
 
     def __init__(
         self,
         driver: Driver,
         storage: Storage,
         audit: Optional[AuditStorage] = None,
@@ -83,24 +96,14 @@
         self.messages = {}
         self.driver = driver
         self.storage = storage
         self.audit = audit
         self.partition = partition
         self.cache = cache
 
-    async def initialize(self):
-        await self.driver.initialize()
-        if self.cache is not None:
-            await self.cache.initialize()
-
-    async def finalize(self):
-        await self.driver.finalize()
-        if self.cache is not None:
-            await self.cache.finalize()
-
     @staticmethod
     def iterate_auditable_fields(resource_keys, message):
         """
         Generator that emits the combined list of field ids from both
         the existing resource and message that needs to be considered
         in the audit of fields.
         """
@@ -242,30 +245,30 @@
         if partition is None:
             raise AttributeError("Can't process message from unknown partition")
 
         # When running in transactional mode, we need to check that
         # that the current message doesn't violate the sequence order for the
         # current partition
         if transaction_check:
-            last_seqid = await self.driver.last_seqid(partition)
+            last_seqid = await sequence_manager.get_last_seqid(self.driver, partition)
             if last_seqid is not None and seqid <= last_seqid:
                 raise SequenceOrderViolation(last_seqid)
 
         audit_type: Optional[int] = None
         audit_fields = None
         audit_shard_counter: Optional[AuditShardCounter] = None
 
         if message.type == BrokerMessage.MessageType.DELETE:
             audit_fields = await self.collect_audit_fields(message)
-            await self.delete_resource(message, seqid, partition)
+            await self.delete_resource(message, seqid, partition, transaction_check)
             audit_type = AuditRequest.AuditType.DELETED
         elif message.type == BrokerMessage.MessageType.AUTOCOMMIT:
             audit_fields = await self.collect_audit_fields(message)
-            txn_result = await self.autocommit(message, seqid, partition)
-            if txn_result:
+            txn_result = await self.txn([message], seqid, partition, transaction_check)
+            if txn_result is not None:
                 audit_type = (
                     AUDIT_TYPES.get(txn_result.action)
                     if txn_result is not None
                     else None
                 )
                 audit_shard_counter = (
                     AuditShardCounter(
@@ -273,14 +276,19 @@
                         paragraphs=txn_result.counter.paragraphs,
                         fields=txn_result.counter.fields,
                     )
                     if txn_result.counter is not None
                     else None
                 )
         elif message.type == BrokerMessage.MessageType.MULTI:
+            # XXX Not supported right now
+            # MULTI, COMMIT and ROLLBACK are all not supported in transactional mode right now
+            # This concept is probably not tenable with current architecture because
+            # of how nats works and how we would need to manage rollbacks.
+            # XXX Should this be removed?
             await self.multi(message, seqid)
         elif message.type == BrokerMessage.MessageType.COMMIT:
             audit_fields = await self.collect_audit_fields(message)
             txn_result = await self.commit(message, seqid, partition)
             if txn_result:
                 audit_type = (
                     AUDIT_TYPES.get(txn_result.action)
@@ -317,15 +325,21 @@
     async def get_resource_uuid(self, kb: KnowledgeBox, message: BrokerMessage) -> str:
         if message.uuid is None:
             uuid = await kb.get_resource_uuid_by_slug(message.slug)
         else:
             uuid = message.uuid
         return uuid
 
-    async def delete_resource(self, message: BrokerMessage, seqid: int, partition: str):
+    async def delete_resource(
+        self,
+        message: BrokerMessage,
+        seqid: int,
+        partition: str,
+        transaction_check: bool = True,
+    ):
         txn = await self.driver.begin()
         kb = KnowledgeBox(txn, self.storage, self.cache, message.kbid)
 
         uuid = await self.get_resource_uuid(kb, message)
         shard_id = await kb.get_resource_shard_id(uuid)
         if shard_id is None:
             logger.warning(f"Resource {uuid} does not exist")
@@ -340,33 +354,38 @@
             except Exception as exc:
                 await txn.abort()
                 await self.notify_abort(
                     partition, seqid, message.multiid, message.kbid, message.uuid
                 )
                 raise exc
         if txn.open:
-            await txn.commit(partition, seqid)
+            if transaction_check:
+                await sequence_manager.set_last_seqid(txn, partition, seqid)
+            await txn.commit()
         await self.notify_commit(
             partition, seqid, message.multiid, message.kbid, message.uuid
         )
 
-    def generate_index(self, resource: Resource, messages: List[BrokerMessage]):
-        pass
-
     async def txn(
-        self, messages: List[BrokerMessage], seqid: int, partition: str
+        self,
+        messages: List[BrokerMessage],
+        seqid: int,
+        partition: str,
+        transaction_check: bool = True,
     ) -> Optional[TxnResult]:
         if len(messages) == 0:
             return None
 
         txn = await self.driver.begin()
         kbid = messages[0].kbid
         if not await KnowledgeBox.exist_kb(txn, kbid):
             logger.warning(f"KB {kbid} is deleted: skiping txn")
-            await txn.commit(partition, seqid)
+            if transaction_check:
+                await sequence_manager.set_last_seqid(txn, partition, seqid)
+            await txn.commit()
             return None
 
         multi = messages[0].multiid
         kb = KnowledgeBox(txn, self.storage, self.cache, kbid)
         uuid = await self.get_resource_uuid(kb, messages[0])
         resource: Optional[Resource] = None
         handled_exception = None
@@ -425,24 +444,26 @@
                         similarity = await kb.get_similarity()
                         shard = await node_klass.create_shard_by_kbid(
                             txn, kbid, similarity=similarity
                         )
                 else:
                     raise AttributeError("Shard is not available")
 
-                await txn.commit(partition, seqid)
+                if transaction_check:
+                    await sequence_manager.set_last_seqid(txn, partition, seqid)
+                await txn.commit()
 
                 # Slug may have conflicts as its not partitioned properly. We make it as short as possible
-                txn = await self.driver.begin()
-                resource.txn = txn
-                await resource.set_slug()
-                await txn.commit(resource=False)
+                # XXX Does this write need to happen every time?
+                async with self.driver.transaction() as slug_txn:
+                    resource.txn = slug_txn
+                    await resource.set_slug()
+                    await slug_txn.commit()
 
                 await self.notify_commit(partition, seqid, multi, kbid, uuid)
-
             elif resource and resource.modified is False:
                 await txn.abort()
                 await self.notify_abort(partition, seqid, multi, kbid, uuid)
                 logger.warning(f"This message did not modify the resource")
         except Exception as exc:
             # As we are in the middle of a transaction, we cannot let the exception raise directly
             # as we need to do some cleanup. The exception will be reraised at the end of the function
@@ -495,25 +516,22 @@
             )
             return
         txn = None
         try:
             async with self.driver.transaction() as txn:
                 resource.basic.metadata.status = PBMetadata.Status.ERROR
                 await set_basic(txn, resource.kb.kbid, resource.uuid, resource.basic)
-                await txn.commit(resource=False)
+                await txn.commit()
 
             await shard.add_resource(
                 resource.indexer.brain, seqid, partition=partition, kb=kbid
             )
         except Exception:
             logger.warning("Error while marking resource as error", exc_info=True)
 
-    async def autocommit(self, message: BrokerMessage, seqid: int, partition: str):
-        return await self.txn([message], seqid, partition)
-
     async def multi(self, message: BrokerMessage, seqid: int):
         self.messages.setdefault(message.multiid, []).append(message)
 
     async def commit(self, message: BrokerMessage, seqid: int, partition: str):
         if message.multiid not in self.messages:
             # Error
             logger.error(f"Closed multi {message.multiid}")
@@ -615,15 +633,20 @@
             action=Notification.ABORT,
         )
         await self.notify(
             const.PubSubChannels.RESOURCE_NOTIFY.format(kbid=kbid),
             message.SerializeToString(),
         )
 
+    async def notify(self, channel, payload: bytes):
+        if self.cache is not None and self.cache.pubsub is not None:
+            await self.cache.pubsub.publish(channel, payload)
+
     # KB tools
+    # XXX: Why are these utility functions here?
 
     async def get_kb_obj(
         self, txn: Transaction, kbid: KnowledgeBoxID
     ) -> Optional[KnowledgeBox]:
         uuid: Optional[str] = kbid.uuid
         if uuid == "":
             uuid = await KnowledgeBox.get_kb_uuid(txn, kbid.slug)
@@ -680,15 +703,15 @@
         async with self.driver.transaction() as txn:
             try:
                 uuid, failed = await KnowledgeBox.create(
                     txn, slug, config=config, uuid=forceuuid, similarity=similarity
                 )
                 if failed:
                     raise Exception("Failed to create KB")
-                await txn.commit(resource=False)
+                await txn.commit()
                 return uuid
             except KnowledgeBoxConflict:
                 raise
             except Exception as e:
                 errors.capture_exception(e)
                 raise e
 
@@ -697,15 +720,15 @@
     ) -> str:
         txn = await self.driver.begin()
         try:
             uuid = await KnowledgeBox.update(txn, kbid, slug, config=config)
         except Exception as e:
             await txn.abort()
             raise e
-        await txn.commit(resource=False)
+        await txn.commit()
         return uuid
 
     async def list_kb(self, prefix: str):
         txn = await self.driver.begin()
         async for kbid, slug in KnowledgeBox.get_kbs(txn, prefix):
             yield slug
         await txn.abort()
@@ -713,13 +736,9 @@
     async def delete_kb(self, kbid: str = "", slug: str = "") -> str:
         txn = await self.driver.begin()
         try:
             uuid = await KnowledgeBox.delete_kb(txn, kbid=kbid, slug=slug)
         except (AttributeError, KeyError, KnowledgeBoxNotFound) as exc:
             await txn.abort()
             raise exc
-        await txn.commit(resource=False)
+        await txn.commit()
         return uuid
-
-    async def notify(self, channel, payload: bytes):
-        if self.cache is not None and self.cache.pubsub is not None:
-            await self.cache.pubsub.publish(channel, payload)
```

## Comparing `nucliadb-2.8.5.post247.dist-info/METADATA` & `nucliadb-2.8.5.post249.dist-info/METADATA`

 * *Files 2% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: nucliadb
-Version: 2.8.5.post247
+Version: 2.8.5.post249
 Summary: UNKNOWN
 Home-page: https://nucliadb.com
 Author: NucliaDB Community
 Author-email: nucliadb@nuclia.com
 License: BSD
 Project-URL: Nuclia, https://nuclia.com
 Project-URL: Github, https://github.com/nuclia/nucliadb
@@ -54,17 +54,17 @@
 Requires-Dist: mmh3 (>=3.0.0)
 Requires-Dist: httpx (>=0.23.0)
 Requires-Dist: types-pkg-resources (>=0.1.3)
 Requires-Dist: grpc-stubs (>=1.24.7)
 Requires-Dist: aiodns (>=3.0.0)
 Requires-Dist: types-orjson
 Requires-Dist: nucliadb-telemetry (>=1.9.2)
-Requires-Dist: nucliadb-utils[cache,fastapi,storages] (==2.8.5-post247)
-Requires-Dist: nucliadb-protos (==2.8.5-post247)
-Requires-Dist: nucliadb-models (==2.8.5-post247)
+Requires-Dist: nucliadb-utils[cache,fastapi,storages] (==2.8.5-post249)
+Requires-Dist: nucliadb-protos (==2.8.5-post249)
+Requires-Dist: nucliadb-models (==2.8.5-post249)
 Requires-Dist: nucliadb-contributor-assets (~=1.0.0)
 Requires-Dist: tikv-client (>=0.0.3)
 Requires-Dist: multidict (>=6.0.4)
 Requires-Dist: deprecated (>=1.2.12)
 Requires-Dist: asgiref (>=3.3.2)
 Requires-Dist: jmespath (>=1.0.0)
 Requires-Dist: idna (>=3.3)
```

## Comparing `nucliadb-2.8.5.post247.dist-info/entry_points.txt` & `nucliadb-2.8.5.post249.dist-info/entry_points.txt`

 * *Files 7% similar despite different names*

```diff
@@ -2,14 +2,15 @@
 nucliadb = nucliadb.run:run
 nucliadb-dataset-upload = nucliadb.train.upload:run
 nucliadb-extract-openapi-reader = nucliadb.reader.openapi:command_extract_openapi
 nucliadb-extract-openapi-search = nucliadb.search.openapi:command_extract_openapi
 nucliadb-extract-openapi-writer = nucliadb.writer.openapi:command_extract_openapi
 nucliadb-ingest = nucliadb.ingest.app:run_consumer
 nucliadb-ingest-orm-grpc = nucliadb.ingest.app:run_orm_grpc
+nucliadb-ingest-processed-consumer = nucliadb.ingest.app:run_processed_consumer
 nucliadb-ingest-purge = nucliadb.ingest.purge:run
 nucliadb-purge = nucliadb.purge:purge
 nucliadb-reader = nucliadb.reader.run:run
 nucliadb-search = nucliadb.search.run:run
 nucliadb-train = nucliadb.train.run:run
 nucliadb-writer = nucliadb.writer.run:run
```

## Comparing `nucliadb-2.8.5.post247.dist-info/RECORD` & `nucliadb-2.8.5.post249.dist-info/RECORD`

 * *Files 6% similar despite different names*

```diff
@@ -1,103 +1,109 @@
 nucliadb/__init__.py,sha256=_abCmDJ_0ku483Os4UAjPX7Nywm39cQgAV_DiyjsKeQ,891
 nucliadb/app.py,sha256=stXecs1Vo4YRVnYOn5H6gAbD81X8K0KbfN72HlVXmCo,1027
-nucliadb/config.py,sha256=OS6cua8-UPOK5J5c1_zX6-GihXU-wRmA4O13SmNQ-Sc,4872
+nucliadb/config.py,sha256=wbxVgb8OxZZ6beagBYX2XEcW1HrCYE9aRfsFxnN8Psg,4846
 nucliadb/purge.py,sha256=NTb2r6LaW5mZxY500Dvhooxuhijngr3t-JxbtcWPmCo,1420
 nucliadb/py.typed,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 nucliadb/run.py,sha256=YyLvcZNw6xNocnrakZfyYhQzj5CdtnkPiR2oCCMU314,2522
 nucliadb/settings.py,sha256=YDtkhIXsc3GzpADSOEo2WZdcpowjCGhYnnAPU-sanMI,1913
 nucliadb/ingest/__init__.py,sha256=fsw3C38VP50km3R-nHL775LNGPpJ4JxqXJ2Ib1f5SqE,1011
-nucliadb/ingest/app.py,sha256=A-WvitVMcCwpbVpeZJ-dt2KATiMG_Cd7TWYKtNo1mEg,5581
+nucliadb/ingest/app.py,sha256=aMpD73HR4b3rJDXXrdcxYuH8EgZjVVbwYsGRnaeG6vQ,6021
 nucliadb/ingest/cache.py,sha256=XPmNNa6KP7P5Mp0Iivl3vIFFMz9rOs9POpHkzj9wpwU,995
 nucliadb/ingest/chitchat.py,sha256=qzArVK6QBOPYqUNNTeBAxzdV_I53ljnVoDvwesk5F5E,6567
 nucliadb/ingest/partitions.py,sha256=a3fXq3DwRiDjcQNBcUtDTra8prIf-r5_z0B69ll_pag,2425
 nucliadb/ingest/processing.py,sha256=v3QWgPLE6oGxCVq6cepmS_w5wPH_x1o0QwuVQNKlvfg,15823
-nucliadb/ingest/purge.py,sha256=6PyALuv7CA5SFe1Z3umRGgi6M36dVoFl9iFWhDWEihM,5336
+nucliadb/ingest/purge.py,sha256=n-CqZj3QlZ5VaJWPRWpnnIq2f3cIY6zEsFn9WKh1fYU,5308
 nucliadb/ingest/serialize.py,sha256=Pji7bacI8YraJe1l5njS7UZ8urSyzHgxd597Z9lWlRE,18976
-nucliadb/ingest/settings.py,sha256=9gzp9KucZIfqWX8snUXx1UP0jxKN9n-stY_4pMXPIMg,2973
+nucliadb/ingest/settings.py,sha256=ognLFuxAxk4ZFda3kefLJqE6wd4H25GGdjtkk01gZsM,3025
 nucliadb/ingest/txn_utils.py,sha256=qM5-531Yjjp_MRGlXNmTDkJVx2vmiFKMK6bho-rPSD8,2531
 nucliadb/ingest/utils.py,sha256=5rlBe_eQPdYiXdmIiKPZ7pvmnG-B9vcJXhGe3uOwMjc,4917
-nucliadb/ingest/consumer/__init__.py,sha256=7Bi0uZMbpYNrqPpWGATaWYd5wn_k5cfVSS_FGYmJspc,1087
-nucliadb/ingest/consumer/pull.py,sha256=_komENo7jSUgoHbuzGaNF7aGAtQqUwO9JG7mUJ0PY70,18549
-nucliadb/ingest/consumer/service.py,sha256=fEG7rwIuikUdZ3UkGnE3k35nqpzzud1r9J2LhCBHbmM,6425
+nucliadb/ingest/consumer/__init__.py,sha256=cp15ZcFnHvpcu_5-aK2A4uUyvuZVV_MJn4bIXMa20ks,835
+nucliadb/ingest/consumer/consumer.py,sha256=nhJSc0IaA-gf7laZyccYqVkbfBVUVhVI-p-CPz40e1A,10672
+nucliadb/ingest/consumer/pull.py,sha256=L1Hu9-0OUvN3WaJ-M1xihLslHdg80N91Lg4ZFHN-UmA,9055
+nucliadb/ingest/consumer/service.py,sha256=xTLRa8ZOwbLHbHV3yIgvhCroAzbBf5Fxi5T9OVtxRgI,5358
 nucliadb/ingest/fields/__init__.py,sha256=cp15ZcFnHvpcu_5-aK2A4uUyvuZVV_MJn4bIXMa20ks,835
 nucliadb/ingest/fields/base.py,sha256=B_YDbCMyULfQVqZAK5LAwPea1V5hpV8VTW_sw9Vca28,19273
 nucliadb/ingest/fields/conversation.py,sha256=QR1fesrRezXy-vRg9d20uedHB-9rxVkbJVriSKa2O6w,6495
 nucliadb/ingest/fields/date.py,sha256=jXMWfdCv87oVySDQORXhMZ1Zvpw_aOpcrYAfUSnL3uA,1223
 nucliadb/ingest/fields/exceptions.py,sha256=J0nqFK89OhckJ0GMPrT2vVAdIHpYwDK3UoYQXOHuA_M,1205
 nucliadb/ingest/fields/file.py,sha256=RtLlnDuT3bueO7V0gnm_i_P1lUCG9l6CZFky0fFCCgg,5159
 nucliadb/ingest/fields/generic.py,sha256=3bW323aCVapc_iFL4epcuYtY6L4tOsEQM5phCFYLnqU,1523
 nucliadb/ingest/fields/keywordset.py,sha256=mLpitqGiSH3IilHCEo2ZGg3laTOMoZ5qc_DVbV3UECA,1235
 nucliadb/ingest/fields/layout.py,sha256=clgBVGWArtkAEawDqCAu_hB9gVu5c6UT1Cf_5yrw47s,2250
 nucliadb/ingest/fields/link.py,sha256=6D1jlwX1ImU3RL1dVawXm2ChoB_s1_h5DOVGyW4q37M,4084
 nucliadb/ingest/fields/text.py,sha256=qMMH76gN--Ag1fPZ1I5G9ZPAi4U0i9jbqlrpYc3cMxg,1319
 nucliadb/ingest/maindb/__init__.py,sha256=cp15ZcFnHvpcu_5-aK2A4uUyvuZVV_MJn4bIXMa20ks,835
-nucliadb/ingest/maindb/driver.py,sha256=8OUkigq5HltfJkbE30YgAFp0pYQFclTeeAoOQ-GG8Mc,3088
-nucliadb/ingest/maindb/exceptions.py,sha256=elpq2rOB746AsuaLxi01JYTWxCKrA6eWryqUtuleQ20,877
+nucliadb/ingest/maindb/driver.py,sha256=3XV-JAXj6Xv3HA4eWB1RS1KzmdmZ8kp8sCCRMNpHyS4,2631
 nucliadb/ingest/maindb/keys.py,sha256=dxDqDWai3fLG15GhLwqkOisMqk_dt6ZYKYEGvjnYeRU,980
-nucliadb/ingest/maindb/local.py,sha256=1icC3gfjiUXwYegjNmb_lUIdHvbfJLioIJSYjodM4t4,7713
-nucliadb/ingest/maindb/pg.py,sha256=Y--CzE-_Pg1oh3uztHfJsN1j-LHXTBn60C1EGm0yyGA,6115
-nucliadb/ingest/maindb/redis.py,sha256=1XiAvGUIlQdUZo4_t2F7ERxnqng61iyrrUwJTDPMZjY,6807
-nucliadb/ingest/maindb/tikv.py,sha256=3w4u0S5OjwJKq8yzd0i4XnCHrdiCe_8dR0qQpTiWohE,7020
+nucliadb/ingest/maindb/local.py,sha256=VuWDCb1SqDcHMZhC6FHOvoyJJ4xw4UbKxuMWTgQmOzc,7076
+nucliadb/ingest/maindb/pg.py,sha256=eFEqoZ0H8-JJHIECQP-62JrsRqsu5U8azl5BEhjr9c0,5400
+nucliadb/ingest/maindb/redis.py,sha256=Ivl1W1dNaPprUMDMHMH0WLSG1p_h5hV6bX6fyp9kQNs,6146
+nucliadb/ingest/maindb/tikv.py,sha256=nLog3QQE5icm5IwLRpLyPpbCTw5N4DO8Ir9SlyghcE8,6313
 nucliadb/ingest/orm/__init__.py,sha256=pBhYYVbyix55e0fuGPUEgJB4tVZOO3j4ZekDfajemYk,3495
 nucliadb/ingest/orm/abc.py,sha256=OBikXZ6IQMyCvKruSQepzuFo3s2f5bHwjeoyaOjOZHg,6801
 nucliadb/ingest/orm/brain.py,sha256=oCNOGsHj4muPlIj-1mp6kAj1fdE-z3MGQ_bbiSGlZic,20650
 nucliadb/ingest/orm/entities.py,sha256=tyDVXUC0O0qTkvpp1IVhaTj8w2zeEypgLdMsVgihm8k,15408
 nucliadb/ingest/orm/exceptions.py,sha256=EeEfwcbr9TkDI9eAaE0I2OzV9DAqIgl-WmuWUxNJVVM,1448
 nucliadb/ingest/orm/grpc_node_binding.py,sha256=AKIh9t7ma12sF4CfBn4PukZ0XtBQQcCQddNcGcV9_Zc,12586
 nucliadb/ingest/orm/grpc_node_dummy.py,sha256=26yAiDanI7woiIJSjvrDlLyCarlMwykJ-m9R8KZ8F-E,4606
-nucliadb/ingest/orm/knowledgebox.py,sha256=IEAUkTEzi8xb0Des2QULZJnvV6iX-Q1s113bd_JKmPw,21289
+nucliadb/ingest/orm/knowledgebox.py,sha256=TFrlWOEfvTKdlYLbeqBLY9dD4KDMTet9UQ6euPK60oc,21247
 nucliadb/ingest/orm/labels.py,sha256=2caUR5M5L3_tw2Sp9XyevO-yXdNpGUUxrR0vpQnTsmo,1730
 nucliadb/ingest/orm/local_node.py,sha256=-YukxuAPEr8AsXJsGfqNl9E25wuHs4ljrwG1TXrizLU,4291
 nucliadb/ingest/orm/local_shard.py,sha256=tUHe9Ml11azFZwBfrjINuglom4wMADF2uWS1tnaOOLg,2890
 nucliadb/ingest/orm/node.py,sha256=E3tofkSKvbs4zPY2OXDnz97hlB1QpLYSiygjtItNJr4,11388
 nucliadb/ingest/orm/nodes_manager.py,sha256=XE521hT_gm1MrJvribLFsk_Zj_9vQFcs6Xl7bHntn3c,4312
-nucliadb/ingest/orm/processor.py,sha256=xbXBLxbIcMi8DJkyPmQUBWvY4AqJyK8ioXwBn0GY9QQ,27970
 nucliadb/ingest/orm/resource.py,sha256=I6dRU5-uYxD6yu-6XLKexCjZQaVVgPmHk4GQ1cVSE94,51379
 nucliadb/ingest/orm/shard.py,sha256=pa_k2AI5P2noFwIhSjZCIqJC_Fq4wMtFztQIQ9ivXho,5115
 nucliadb/ingest/orm/synonyms.py,sha256=BuqS8XxLLVP124zPLGISgrmQg94LdalaTHeOVp_6dIY,1739
 nucliadb/ingest/orm/utils.py,sha256=9vTugcLweai69WWinatWm1RTyukJEDDte3qXNLqS7pI,3340
-nucliadb/ingest/service/__init__.py,sha256=hB4-W0WSK7H67CCrje2V8LNI-ceFtfufNPXgTuATUMo,2817
+nucliadb/ingest/orm/processor/__init__.py,sha256=iislLzPeag-6uZr6o4f23gRUkbwxGZA-1GGPIRLdezo,28888
+nucliadb/ingest/orm/processor/sequence_manager.py,sha256=PGouu9Xp_zdhfCTtRLCEW3uJ2XvHNIckNXvUdgxc0OM,1694
+nucliadb/ingest/service/__init__.py,sha256=2naoXev5p8R6jNlSKTgWfMk3z8sNjRGgkoLfZy5XI8U,3113
 nucliadb/ingest/service/exceptions.py,sha256=cp15ZcFnHvpcu_5-aK2A4uUyvuZVV_MJn4bIXMa20ks,835
-nucliadb/ingest/service/writer.py,sha256=BTT8mdjAfNMREtkydIMhiseBtu9sETwZU3u7scNr4vI,34672
+nucliadb/ingest/service/writer.py,sha256=pZty0Cq5XY3iwV5ojvjD6RCU_F4uO2lk-LyeuGX2pl8,34487
 nucliadb/ingest/tests/__init__.py,sha256=cp15ZcFnHvpcu_5-aK2A4uUyvuZVV_MJn4bIXMa20ks,835
 nucliadb/ingest/tests/conftest.py,sha256=vu6f6UsfajjAZwBcbecc7xvRZpr7Yqj7qxalHYtgRtE,1096
-nucliadb/ingest/tests/fixtures.py,sha256=29HZ4-Fk4yjbrksDdwpdraU8RMO2BvJrInzh9EwxgmQ,25062
+nucliadb/ingest/tests/fixtures.py,sha256=UbPfayNe37x64u_PMcsjg6aV8RuyvCLVsUvq2AIsQrc,25857
 nucliadb/ingest/tests/tikv.py,sha256=MGwBL9ezcOOR8JwttouQ8Qj6534d742i2A3TAumdrM4,7549
 nucliadb/ingest/tests/vectors.py,sha256=CcNKx-E8LPpyvRyljbmb-Tn_wST9Juw2CBoogWrKiTk,62843
 nucliadb/ingest/tests/integration/__init__.py,sha256=cp15ZcFnHvpcu_5-aK2A4uUyvuZVV_MJn4bIXMa20ks,835
 nucliadb/ingest/tests/integration/test_chitchat.py,sha256=_sCN6d5Val9CZGT9tXCWXYHMs79n77qUbav7qqJavi8,1740
+nucliadb/ingest/tests/integration/consumer/__init__.py,sha256=itSI7dtTwFP55YMX4iK7JzdMHS5CQVUiB1XzQu4UBh8,833
+nucliadb/ingest/tests/integration/consumer/test_pull.py,sha256=8RqsI6QxjFGTfwkuT4kQgx9E-mOwXcW2PKe-K7a5Jjo,5206
+nucliadb/ingest/tests/integration/consumer/test_service.py,sha256=Pol7e7qLCnujLzxvuwfZBGgjCH8mkUbgezgdfYlYoBA,2751
 nucliadb/ingest/tests/integration/ingest/__init__.py,sha256=cp15ZcFnHvpcu_5-aK2A4uUyvuZVV_MJn4bIXMa20ks,835
 nucliadb/ingest/tests/integration/ingest/test_ingest.py,sha256=dTzOf9ZnnLgywLl4PKOlD3dKFyb_5EeKchvaPZt_bkA,27277
 nucliadb/ingest/tests/integration/ingest/test_processing_engine.py,sha256=EPXe105v5vHPHUuqHXnj74_AsSm_mAn52n1MjvR9P8w,2339
 nucliadb/ingest/tests/integration/ingest/test_relations.py,sha256=rIB4-LoWxrez66bIXGrIUwt-Lc4dzeJyIlgwkf1Jyn8,8606
 nucliadb/ingest/tests/unit/__init__.py,sha256=cp15ZcFnHvpcu_5-aK2A4uUyvuZVV_MJn4bIXMa20ks,835
 nucliadb/ingest/tests/unit/test_cache.py,sha256=zIUckaBdMFJ_gOoSCXmBFG0qJzenh0gQGs6DKAbqxCA,1179
 nucliadb/ingest/tests/unit/test_chitchat.py,sha256=y8uQbzU_55KgXuYazl07buzA-JHtunmzDMu5hbtGDbs,4246
 nucliadb/ingest/tests/unit/test_partitions.py,sha256=hN8ch_aHVas58-6q6B-__D-abNHJ4I--3vDpDVz4TS8,1432
 nucliadb/ingest/tests/unit/test_processing.py,sha256=h_gCWP8YBaMv8uxOGVlKFTMUQkhnXnbB0G2VQMniKGo,5538
 nucliadb/ingest/tests/unit/test_purge.py,sha256=Fsiq2Xb2QHarMV8Y09QDHEZ7tBMEXPvXYvUQ8U5dDG8,3414
 nucliadb/ingest/tests/unit/test_settings.py,sha256=DdCeFACJd6oMq1QP2Vfsdz604gLAielkXSSh6YruCrU,978
 nucliadb/ingest/tests/unit/test_txn_utils.py,sha256=NnpZkPe2sPacwB4mE-A-ijR4ZOBuxZON5Gton3HsM9s,1403
 nucliadb/ingest/tests/unit/test_utils.py,sha256=03u1kU3mKzKgkWZg1Jr8HPJsIOypWpQDGeQi8BBQs18,2895
+nucliadb/ingest/tests/unit/consumer/__init__.py,sha256=itSI7dtTwFP55YMX4iK7JzdMHS5CQVUiB1XzQu4UBh8,833
+nucliadb/ingest/tests/unit/consumer/test_pull.py,sha256=P6ZEM6bpxZ03jliUF5J8kk07eARDbK-bVrCtfViOkic,2528
 nucliadb/ingest/tests/unit/orm/__init__.py,sha256=cp15ZcFnHvpcu_5-aK2A4uUyvuZVV_MJn4bIXMa20ks,835
 nucliadb/ingest/tests/unit/orm/test_brain.py,sha256=aL-lDK-xp5ZL6LD7tCAAy2QyA9yn66PwK4dFv_3Csss,8991
 nucliadb/ingest/tests/unit/orm/test_cluster.py,sha256=SimYa7eb8QJLTisqEOXVVX-ZvtBPQw9I3yI__zpvhQM,2706
 nucliadb/ingest/tests/unit/orm/test_node.py,sha256=FxSx1tKScjqZtreHqrbFwWsyOTbRPy94s8p0AbfC5C8,4212
 nucliadb/ingest/tests/unit/orm/test_processor.py,sha256=ZFH6sZfVwSa5YPIMoeGxfIJ5pD6e5s2L9EaSWTuauxE,2812
 nucliadb/ingest/tests/unit/orm/test_resource.py,sha256=bzBLZ0s4xwz4RxC6iKFunduH_oPGyVJCJuc87cVLpYU,3772
 nucliadb/ingest/tests/unit/orm/test_shard.py,sha256=Aek2qfvE2XPT9a2zz4Tg9IdlfjSlmxwPgRQ33qwn1W8,1401
 nucliadb/models/__init__.py,sha256=cp15ZcFnHvpcu_5-aK2A4uUyvuZVV_MJn4bIXMa20ks,835
 nucliadb/models/responses.py,sha256=qnuOoc7TrVSUnpikfTwHLKez47_DE4mSFzpxrwtqijA,1599
 nucliadb/one/__init__.py,sha256=M4YAQYYehaKJpZUa__l6DGhK2VGRejMAn33tXZuVwA0,914
 nucliadb/one/app.py,sha256=KzBdw2Yvxcq1DtmzEe0PRpeNcpKhM4lE8TTZqlrYfKI,3539
-nucliadb/one/lifecycle.py,sha256=W8_2rR6R_Vi8PzXQaWyQPzD4Qfr6_J2odLxdUKMwtKU,2130
+nucliadb/one/lifecycle.py,sha256=hsJc45JXm5HgGV8FWQDAufk6JmOTYLePYauLA0zsV_k,2359
 nucliadb/one/tests/__init__.py,sha256=cp15ZcFnHvpcu_5-aK2A4uUyvuZVV_MJn4bIXMa20ks,835
 nucliadb/one/tests/conftest.py,sha256=qmJ2toIbFRAEyoHbv68-xl2XQjBuT0e3CuZ5ert21xs,1164
-nucliadb/one/tests/fixtures.py,sha256=4wblE8GPXzmfv9j05OAoBDbAMyxTr2zhjPlRotmrjLQ,3665
+nucliadb/one/tests/fixtures.py,sha256=f-BFAdH1oIfDdum1DHYa3pJryPuPRm90Ahqcob_Ogn0,3762
 nucliadb/one/tests/test_basic.py,sha256=tLBcofx01zABlnetZHD9QxZ7ysGmiT6QRJtYEOOjKBg,2561
 nucliadb/one/tests/test_delete_field.py,sha256=qXa2fgG-RYNBPneqQtX9HdroDSn2qR0ZULXQPQ9fClU,2492
 nucliadb/one/tests/test_fieldmetadata.py,sha256=-V5K3mJfBLcEAx4jLjskYIZlKChOL90eEM8WLFzPTeE,6087
 nucliadb/one/tests/test_services.py,sha256=XVXqcP62323FLNyJinemnmG5cGBWPNHX0FRJmX1G4mw,4594
 nucliadb/one/tests/test_upload_download.py,sha256=h8hRtbdGuUZuTB7dHTZsakzu7Y1C0dkTIAJpwEtQjHs,4067
 nucliadb/reader/__init__.py,sha256=TxsAOWhRnz9l8DuFy-Qfv0I5HrzrysaxtAzogg6FQB8,1328
 nucliadb/reader/app.py,sha256=O1EjL9LRuNhrMQSf6gJZ68L1jl-77bo3ZIhzPRL4ceA,3356
@@ -148,16 +154,16 @@
 nucliadb/search/search/paragraphs.py,sha256=sgUXa0IkO7pc1inDlOmbj1lxVaqsf5L-ALXunQpuf9U,11002
 nucliadb/search/search/query.py,sha256=RHHoBnT4Zp7A0mCFUkmel8lMfdTOcQyV6Vtg7O5xxVs,9905
 nucliadb/search/search/shards.py,sha256=sgyhpE8mCqlXaUB9PNb7Zt_MFKgvEso9CNWJXQKzFcE,2647
 nucliadb/search/search/synonyms.py,sha256=PTViRCiSA7o4JWXSHuGMb_khwWlKAMxNjwv7tbeQ9-I,2055
 nucliadb/search/search/utils.py,sha256=jPPags_EiZ6c5k6jysOQnpzFlwz0jJYeXYuBt2Vn9NU,2410
 nucliadb/search/tests/__init__.py,sha256=cp15ZcFnHvpcu_5-aK2A4uUyvuZVV_MJn4bIXMa20ks,835
 nucliadb/search/tests/conftest.py,sha256=h15XytM2zllGvGBjsMfIWmI63pXaQk8tAEzq-1Fy5ts,1172
-nucliadb/search/tests/fixtures.py,sha256=q7MQgJwrePoKH4SYALIZfrVf1GUioLzUUH0URKFIrVQ,7895
-nucliadb/search/tests/node.py,sha256=ImlOmHErZvquALXcgfwxerrEoD77aniZ0waawukc_O0,16291
+nucliadb/search/tests/fixtures.py,sha256=3Q628BCXFMfNFwa4KtWNVxUKK3ze8_2EEf1i4Spb5iw,7759
+nucliadb/search/tests/node.py,sha256=SI9cQuS9HviTfhp58pnr8P8JIqVUk_My6z_ZWEBQ2JI,15809
 nucliadb/search/tests/unit/__init__.py,sha256=itSI7dtTwFP55YMX4iK7JzdMHS5CQVUiB1XzQu4UBh8,833
 nucliadb/search/tests/unit/test_app.py,sha256=I44MFQVbiUBLNVxni3pudxiLXF6za_GU8r2B7R7XWcI,1560
 nucliadb/search/tests/unit/test_find_orderer.py,sha256=yaxhUfisIZ4r9sa0AbXmkgGLppgPwXoOFVDdB1lg1UE,1776
 nucliadb/search/tests/unit/test_openapi.py,sha256=Jx8RDeeDBq_DlJQ9dcyTF9xwSTNImHqlP96rbP1DoxY,1329
 nucliadb/search/tests/unit/test_predict.py,sha256=STuMOGMFde2GpNDvLlt8zzoJM-FdQCNNLy4LbEJoYBc,8495
 nucliadb/search/tests/unit/test_run.py,sha256=h9wnfLOTn3qzX7cn7nyfNcJj69wqX3IE6loBLUnW_o4,1258
 nucliadb/search/tests/unit/search/__init__.py,sha256=itSI7dtTwFP55YMX4iK7JzdMHS5CQVUiB1XzQu4UBh8,833
@@ -167,15 +173,15 @@
 nucliadb/search/tests/unit/search/requesters/__init__.py,sha256=itSI7dtTwFP55YMX4iK7JzdMHS5CQVUiB1XzQu4UBh8,833
 nucliadb/search/tests/unit/search/requesters/test_utils.py,sha256=BONZKZtRzFGgDBplOYNerLAuA9tmUJHrCzTesoejDQU,2528
 nucliadb/static/favicon.ico,sha256=96pKGp6Sx457JkTfjy1dtApMhkitixfU6invCUGAYOU,2285
 nucliadb/static/index.html,sha256=PEZfuEQFYnYACAL1ceN8xC0im8lBrUx838RkE8tbvgA,3833
 nucliadb/static/logo.svg,sha256=-wQqSvPGTdlKjUP6pHE6kiq005pgYjDzp9nPl0X71Mk,2639
 nucliadb/tests/__init__.py,sha256=cp15ZcFnHvpcu_5-aK2A4uUyvuZVV_MJn4bIXMa20ks,835
 nucliadb/tests/conftest.py,sha256=LZPZqJ0rflIyeiNeHGIZYLMTBCZr83r77BZsnRaSTtQ,1000
-nucliadb/tests/fixtures.py,sha256=A35nG39V791F7HubSqqAoLhj8RyYUDI1l2Z25neklME,11685
+nucliadb/tests/fixtures.py,sha256=iojxdXwe0_MoZ-eHUarT2gv84nMy1qJmV492IzRFzuY,11567
 nucliadb/tests/test_advanced_search.py,sha256=OHPlTHOqmQCRrALruQ5vs13t6Yo4Cc5-mhVf0E8lphI,7370
 nucliadb/tests/test_api.py,sha256=Nz8xe7xOtkPYRdiNMZ-Oo7jmP4BXOt4nCeEe6nxTgi8,14764
 nucliadb/tests/test_chat.py,sha256=gDjAKN6uRu5ItxApLz4ik_Xu_uHW5lIo3FL2KREbtEs,1290
 nucliadb/tests/test_conversation.py,sha256=Elhqcy-oraA_ozoYoo3Lo9AjKEy6-vupEax0nL8gpO4,3669
 nucliadb/tests/test_counters.py,sha256=DgS_zyzQIaNIsYfvD4iBJGLpnnj9gcUy06Er39VZjRE,2052
 nucliadb/tests/test_entities.py,sha256=nkMQ_NSEZXx0GW84ApphTR1onx1Go3IbNtwkQulVS_E,12302
 nucliadb/tests/test_entities_deprecated.py,sha256=23J8c2_MNe5onz_V7BWjv1SmQRbsDS_GgTol-4juYHc,13274
@@ -206,15 +212,15 @@
 nucliadb/train/lifecycle.py,sha256=aqGlusk-r20jUrlTxoaqJq2VXIK18CKAh-slhfs10P0,1638
 nucliadb/train/models.py,sha256=BmgmMjDsu_1Ih5JDAqo6whhume90q0ASJcDP9dkMQm8,1198
 nucliadb/train/nodes.py,sha256=YQ77IdkyCMCovPqxErL8Di9pduSL0kzN6pXvjrToxNM,8054
 nucliadb/train/run.py,sha256=XflKrGcNGjZnCODNQWAe2XvR9cVd8K7TVD5HEkS9EIY,1364
 nucliadb/train/servicer.py,sha256=eCWU3MBbdFzpevAvGmgVsWTU1eJ0jVmslkZeyn9tWzc,5755
 nucliadb/train/settings.py,sha256=eXe87TjqtGTa-bCKRPDIWdyb7qsaUW3VbLXV-zGBQZk,1415
 nucliadb/train/upload.py,sha256=vui0GXaP7Zcn6WVzUMlcSwqNX-Yot7eFynw6pSs3Vgw,3271
-nucliadb/train/uploader.py,sha256=pipcnZ_b8GF-39j-Rgpk1Jy8W-XOPyKvdZk5iOLrs8I,6531
+nucliadb/train/uploader.py,sha256=AarOaeSkxUGjlI8X2AXsZp4WAN4DoOExSSH7aB_sfHY,6471
 nucliadb/train/utils.py,sha256=xrqQr5BLHUf5rkNv2hKB7ebP1kkMnmxy296g1gETfH4,3077
 nucliadb/train/api/__init__.py,sha256=cp15ZcFnHvpcu_5-aK2A4uUyvuZVV_MJn4bIXMa20ks,835
 nucliadb/train/api/models.py,sha256=YFKrXktdiE6yAa4TSHSYXzUZjADjssi4VHVn0Vf0m_0,958
 nucliadb/train/api/utils.py,sha256=zYbDiKJSsPP8tC7O2T8bfKkb_RTCxrq9JIcnLOSZixQ,1479
 nucliadb/train/api/v1/__init__.py,sha256=P4vCIv93r_Cq1WFDDNjy_Wg7zBkzx0S4euXwfPy1LA4,928
 nucliadb/train/api/v1/check.py,sha256=r1r4r8KiF7CZs-cEiWZQ-ZlvV4hRmqySjMRjmW82wk0,2066
 nucliadb/train/api/v1/router.py,sha256=ukdxn5q1oMar6NSPobgJczWsSxLCHw6DYKlb3zwCiSo,910
@@ -224,15 +230,15 @@
 nucliadb/train/generators/field_classifier.py,sha256=4hiJ_bvH3HY6dn8jZgc6YCDdeqHFd8YWuSB7jfuuyNc,3289
 nucliadb/train/generators/paragraph_classifier.py,sha256=oZ5GtMfk_sRhy9ClCGc2vGuIfHzBza7279sQeRy60as,3594
 nucliadb/train/generators/sentence_classifier.py,sha256=uZJzTK9v0LntPmSGPeIwp38xsMX9wioa5AxXXef4w9s,4767
 nucliadb/train/generators/token_classifier.py,sha256=i2PQJhrp8uqA8ey666O7WGiLx1qAc5VOg7e1I8NmDcs,10256
 nucliadb/train/generators/utils.py,sha256=Q-Vqy07lvYz8EFvbiGOxi3HPpFRhcld9DbWmq9khaQE,2144
 nucliadb/train/tests/__init__.py,sha256=cp15ZcFnHvpcu_5-aK2A4uUyvuZVV_MJn4bIXMa20ks,835
 nucliadb/train/tests/conftest.py,sha256=MNH2umE3OKnJLXK3U6kZmpfW0GQcoZtwK6NfilXKXRs,1088
-nucliadb/train/tests/fixtures.py,sha256=OmOJ5nxKqaLO1eJoeFJVxQJqd0tNjtlyNouI7P4qvdk,9050
+nucliadb/train/tests/fixtures.py,sha256=hOHa6am5ASPepuJaCvTlilyhyw-GKvdQ6g4983Qy6_w,8951
 nucliadb/train/tests/test_field_classification.py,sha256=Sg3V8dlKt9WgVqAQ2OLVz6CkbqNwK_jxAim4Fk1KmLc,8132
 nucliadb/train/tests/test_get_entities.py,sha256=ndcEemTcITB70X_GxSIkUiAoNOnpTamfyPaXVtXmgKQ,2729
 nucliadb/train/tests/test_get_info.py,sha256=uWKFC8uDXsmdzUp0xgNpEEuf5Ge9dNPE5CSfdZSDz_o,1660
 nucliadb/train/tests/test_get_ontology.py,sha256=Xjr-eIYQLzNkqFU3nwANmDi4fwY09VymdikC3ibgM8A,1382
 nucliadb/train/tests/test_get_ontology_count.py,sha256=hyarvQOw5PyeYVJ7Z6v4I1Yagi0PwrEiIs615tsM4Z8,2201
 nucliadb/train/tests/test_list_fields.py,sha256=V6YS2ao09AiheI6GKaC9GVLUG_ypf-WrvId_mRdBJB8,1416
 nucliadb/train/tests/test_list_paragraphs.py,sha256=fvDh-vvgTj-XonTS8t9CDq0eDGgNl8iWw3E9OBmGK7c,2944
@@ -240,15 +246,15 @@
 nucliadb/train/tests/test_list_sentences.py,sha256=YqofeZgXeUX4KJVOJiaiU1mx2G5qhkAIMa_FXrSxJck,2863
 nucliadb/train/tests/test_paragraph_classification.py,sha256=uj5KSsZCYXlrTOT-gUpFypcsGpVR3cNiXhF2nyhiHX0,8129
 nucliadb/train/tests/test_sentence_classification.py,sha256=Pj5qW4orGk3x_D48S-DmWLsYSEaSOzq7uZexvfVxiFg,8349
 nucliadb/train/tests/test_token_classification.py,sha256=yGsIWuHxp49WynzKAeLTxkoG-Z0TEiReqoPlITQeCHU,10122
 nucliadb/writer/__init__.py,sha256=HkfMuQR3CbbPU3g-A85Ibt8iwSTTADhLc0-pi3F3hvk,1328
 nucliadb/writer/app.py,sha256=3OVzecTJgie8U4S1TUDoAl4E7dDrmo_we2jRc-ID1Hc,3331
 nucliadb/writer/exceptions.py,sha256=2dMvuoF68v3BZuyzaBEsbG6gusQqwLFcn47qm1zNdTc,972
-nucliadb/writer/lifecycle.py,sha256=ZIX3NOK1aWvvgYFEPTpRTFh1cCnQfkHviVNGTXfjdGg,2832
+nucliadb/writer/lifecycle.py,sha256=YxWwD8A-f65KfwG_i4zD_37z1rsmbSyGae7ndJBfRVg,2219
 nucliadb/writer/openapi.py,sha256=bpH-pzxdDRb9Dy0OcaB1U0ziuvIG416akVr-Dwz3ywM,2186
 nucliadb/writer/run.py,sha256=MimcqtaTLDvyOG-oRC5RJSYjld810aMEOrruM2ZLcrg,1366
 nucliadb/writer/settings.py,sha256=rphXdqI238b1bch0elcY3aY4qxQYe_wllnW7MPjmZyU,1062
 nucliadb/writer/utilities.py,sha256=AZ5qEny1Xm0IDsFtH13oJa2usvJZK8f0FdgF1LrnLCw,1036
 nucliadb/writer/api/__init__.py,sha256=cp15ZcFnHvpcu_5-aK2A4uUyvuZVV_MJn4bIXMa20ks,835
 nucliadb/writer/api/v1/__init__.py,sha256=50S5JnDp00NP8YKLlaWZ_ZDmJr7bioFteB400iKcel8,1021
 nucliadb/writer/api/v1/field.py,sha256=qGywhrPmr7jCb7RgXsJGPS_jw9Fdlp9FJe51Fa-7SUg,22313
@@ -264,17 +270,17 @@
 nucliadb/writer/resource/basic.py,sha256=LzErgj5WqdWabKJpz9zAIp--vjEhGRHmF2lepIxt-sg,9324
 nucliadb/writer/resource/field.py,sha256=gcLbEUQl5_bpVgMkmMVMi60v1W0z_qFTLD5payYUWas,15875
 nucliadb/writer/resource/origin.py,sha256=tnM8VW7vkrc_Sfql6QtDlxzuEsF_kJn4F56xjZvetfU,1708
 nucliadb/writer/resource/slug.py,sha256=xaYHmlooQTdaE8meuMTpbz11hVuOcMrAwculNf-uao4,1151
 nucliadb/writer/resource/vectors.py,sha256=-Z4vSwC632Prx6CBBE9X7Qx8QNkYUEXvn7j1KbZftz4,4991
 nucliadb/writer/tests/__init__.py,sha256=cp15ZcFnHvpcu_5-aK2A4uUyvuZVV_MJn4bIXMa20ks,835
 nucliadb/writer/tests/conftest.py,sha256=NytcRRhwL17WbxXlyDP3N0-Z_yIH9qshNGf4xvzg4j0,1144
-nucliadb/writer/tests/fixtures.py,sha256=KLUfH2mfT9nCkDBTrvb27RSddpCw3WbR6OQPTt15_WE,4204
+nucliadb/writer/tests/fixtures.py,sha256=n972eXzSXIz1ZMlyV58J-qOAg2c1OE0TPfRROLF87fo,4204
 nucliadb/writer/tests/test_fields.py,sha256=khX5ABBS18TQvVT2j47UrNC-4wId5VGGpECeEFv2MrM,15962
-nucliadb/writer/tests/test_files.py,sha256=teDQfDVALbNPZPDhsZEoBYW_i-4JEuI64Z2g1fSCBww,22233
+nucliadb/writer/tests/test_files.py,sha256=_2glesbLmcACTzwKkpcuN6RFtdw4vI-9vZ0-SQhRl9g,22630
 nucliadb/writer/tests/test_knowledgebox.py,sha256=W8wJ5Ik1NIIDwCeoDKqA6Wo5Vhvbe-VKTXT6q7f5Txs,1932
 nucliadb/writer/tests/test_reprocess_file_field.py,sha256=fcRFJfX7IXPhD3foCw9SiNTGVXR0CoV0oxNhtfo7XYk,4623
 nucliadb/writer/tests/test_resources.py,sha256=acHO29yYln4WguBjTbyqRbau4VQBiD1dzs0F02v4dUI,19059
 nucliadb/writer/tests/test_service.py,sha256=kau-mAhj6r3nPO1-zT0r_OJeU6uuZcn0l0ZB8Qcpbys,5345
 nucliadb/writer/tests/test_tus.py,sha256=-ggQckT2Te11wH58Q_SlUk23350OrxDkXzzlaeS8vDY,3596
 nucliadb/writer/tests/tus.py,sha256=zjffuaDkvNdFc4sbark5XB-Uxf74XZuE6AyyU6rzfrE,2028
 nucliadb/writer/tests/utils.py,sha256=eSyyTCMERC-EzeBrBAurSIZCpqgH67wc1wHZ1KjO1DM,1287
@@ -282,13 +288,13 @@
 nucliadb/writer/tus/dm.py,sha256=ULuP07lQOa4XDqLWwnfgNe8ReFsrxl3t4G9BWUY4uiY,4757
 nucliadb/writer/tus/exceptions.py,sha256=CmxYKnHXpXug25DYV4SpVAU47SGD-NVBd7pNTRbWHyk,2186
 nucliadb/writer/tus/gcs.py,sha256=DdnCTwtd3N87yaPUl-n3LJfUDdHVGav-w1LBOUnUNWg,13818
 nucliadb/writer/tus/local.py,sha256=BM2_uZwh3qd4CsGaIzNL4EBzv9lNjgtSP0cnLPdMJek,5811
 nucliadb/writer/tus/s3.py,sha256=5gpiYTGAJsLN2j55FBSq-E9kLbMn5tvNDZeNRzo3yj0,8571
 nucliadb/writer/tus/storage.py,sha256=Ba085-LkOjbHsYKh6u3NA40b1PSPzS20YHJqIa6kvG0,4682
 nucliadb/writer/tus/utils.py,sha256=40VRRKjKJgt-pYbWH9eX-jnQFze1_NkqI8ehe-wSZ8U,2580
-nucliadb-2.8.5.post247.dist-info/METADATA,sha256=RmwdLSzK3FWZP_-7Fs85pH-HVU3m9K5SsCPiwMLhXWM,2913
-nucliadb-2.8.5.post247.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
-nucliadb-2.8.5.post247.dist-info/entry_points.txt,sha256=iaPREOmF1t002PpqUQgCy10P5s9WbbZYONq7ierSuig,710
-nucliadb-2.8.5.post247.dist-info/top_level.txt,sha256=K5XbWCHfZ7wve-wIrOSTuE0y-jVJSKVS9ZTDJ4TKhKQ,9
-nucliadb-2.8.5.post247.dist-info/zip-safe,sha256=AbpHGcgLb-kRsJGnwFEktk7uzpZOCcBY74-YBdrKVGs,1
-nucliadb-2.8.5.post247.dist-info/RECORD,,
+nucliadb-2.8.5.post249.dist-info/METADATA,sha256=Xv_lgsEdRJm28WaSxw--U0_DUIO3bl77-J21veiKHNY,2913
+nucliadb-2.8.5.post249.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
+nucliadb-2.8.5.post249.dist-info/entry_points.txt,sha256=iMxmJxMdQ0sMN9yj0aD3NqHMpFyaikB_nlqjpwVtcnc,790
+nucliadb-2.8.5.post249.dist-info/top_level.txt,sha256=K5XbWCHfZ7wve-wIrOSTuE0y-jVJSKVS9ZTDJ4TKhKQ,9
+nucliadb-2.8.5.post249.dist-info/zip-safe,sha256=AbpHGcgLb-kRsJGnwFEktk7uzpZOCcBY74-YBdrKVGs,1
+nucliadb-2.8.5.post249.dist-info/RECORD,,
```

